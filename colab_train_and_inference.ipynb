{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "colab_train_and_inference.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWY2oa8nnVRZ",
        "colab_type": "code",
        "outputId": "3ecc73dc-fc0c-4606-bab5-8d62a7910a17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        }
      },
      "source": [
        "!rm -rf T2F\n",
        "#put the link to your repositiory so that model will be trained according to your config file\n",
        "!git clone https://github.com/sharmahr/Text-to-Face-Composition.git "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'T2F'...\n",
            "remote: Enumerating objects: 57, done.\u001b[K\n",
            "remote: Counting objects: 100% (57/57), done.\u001b[K\n",
            "remote: Compressing objects: 100% (45/45), done.\u001b[K\n",
            "remote: Total 348 (delta 24), reused 40 (delta 12), pack-reused 291\u001b[K\n",
            "Receiving objects: 100% (348/348), 509.58 MiB | 10.98 MiB/s, done.\n",
            "Resolving deltas: 100% (142/142), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VMmhCeu8nuD",
        "colab_type": "code",
        "outputId": "540aab11-b94b-4eca-996b-e6b65fc13162",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhrMrnyw8vcV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir /content/T2F/implementation/networks/InferSent/models"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dAFhD8wp9H7G",
        "colab_type": "code",
        "outputId": "e6dde5c5-40d3-46db-854b-0f261616cdf2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "!curl -Lo /content/T2F/implementation/networks/InferSent/models/infersent2.pkl https://dl.fbaipublicfiles.com/infersent/infersent2.pkl"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  146M  100  146M    0     0   9.9M      0  0:00:14  0:00:14 --:--:-- 12.6M\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ichunx7x-grh",
        "colab_type": "code",
        "outputId": "5a54c56b-d757-46ed-b3c8-c24ab4c7f7b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        }
      },
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.840B.300d.zip\n",
        "!unzip glove.840B.300d.zip\n",
        "!mv glove.840B.300d.txt /content/T2F/implementation/networks/InferSent/models/glove.840B.300d.txt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-09-11 09:28:14--  http://nlp.stanford.edu/data/glove.840B.300d.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.840B.300d.zip [following]\n",
            "--2019-09-11 09:28:15--  https://nlp.stanford.edu/data/glove.840B.300d.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.840B.300d.zip [following]\n",
            "--2019-09-11 09:28:15--  http://downloads.cs.stanford.edu/nlp/data/glove.840B.300d.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2176768927 (2.0G) [application/zip]\n",
            "Saving to: ‘glove.840B.300d.zip’\n",
            "\n",
            "glove.840B.300d.zip 100%[===================>]   2.03G  15.8MB/s    in 2m 11s  \n",
            "\n",
            "2019-09-11 09:30:27 (15.8 MB/s) - ‘glove.840B.300d.zip’ saved [2176768927/2176768927]\n",
            "\n",
            "Archive:  glove.840B.300d.zip\n",
            "  inflating: glove.840B.300d.txt     \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKjNB5E2-1hH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp /content/T2F/implementation/networks/InferSent/models/glove.840B.300d.txt /content/gdrive/My\\ Drive/T2F/glove.840B.300d.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8G62l7J_ajQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp -r T2F gdrive/My\\ Drive/T2F"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MM9OFSm8AG3y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp /content/T2F/implementation/networks/InferSent/models/glove.840B.300d.txt /content/gdrive/My\\ Drive/T2F/glove.840B.300d.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3KVSJXVAih4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp /content/T2F/implementation/networks/InferSent/models/infersent2.pkl /content/gdrive/My\\ Drive/T2F/infersent2.pkl"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1eEg_dKA-6Z",
        "colab_type": "code",
        "outputId": "a8c4120e-72d0-4371-fa8f-bd7d0912c326",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        }
      },
      "source": [
        "!wget http://vis-www.cs.umass.edu/lfw/lfw.tgz\n",
        "!tar -xf lfw.tgz"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-09-10 16:31:51--  http://vis-www.cs.umass.edu/lfw/lfw.tgz\n",
            "Resolving vis-www.cs.umass.edu (vis-www.cs.umass.edu)... 128.119.244.95\n",
            "Connecting to vis-www.cs.umass.edu (vis-www.cs.umass.edu)|128.119.244.95|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 180566744 (172M) [application/x-gzip]\n",
            "Saving to: ‘lfw.tgz’\n",
            "\n",
            "lfw.tgz             100%[===================>] 172.20M  57.7MB/s    in 3.0s    \n",
            "\n",
            "2019-09-10 16:31:54 (57.7 MB/s) - ‘lfw.tgz’ saved [180566744/180566744]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I52bUt8WBFq9",
        "colab_type": "code",
        "outputId": "6ccd865a-9bf3-4d84-be8a-23b7d366c106",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        }
      },
      "source": [
        "!pip install -r T2F/requirements.txt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow==1.7.0 in /usr/local/lib/python3.6/dist-packages (from -r T2F/requirements.txt (line 1)) (1.7.0)\n",
            "Requirement already satisfied: numpy==1.13.1 in /usr/local/lib/python3.6/dist-packages (from -r T2F/requirements.txt (line 2)) (1.13.1)\n",
            "Requirement already satisfied: Pillow==5.1.0 in /usr/local/lib/python3.6/dist-packages (from -r T2F/requirements.txt (line 3)) (5.1.0)\n",
            "Requirement already satisfied: easydict==1.7 in /usr/local/lib/python3.6/dist-packages (from -r T2F/requirements.txt (line 4)) (1.7)\n",
            "Requirement already satisfied: torch==0.4.0 in /usr/local/lib/python3.6/dist-packages (from -r T2F/requirements.txt (line 5)) (0.4.0)\n",
            "Requirement already satisfied: torchvision==0.2.1 in /usr/local/lib/python3.6/dist-packages (from -r T2F/requirements.txt (line 6)) (0.2.1)\n",
            "Requirement already satisfied: PyYAML==3.12 in /usr/local/lib/python3.6/dist-packages (from -r T2F/requirements.txt (line 7)) (3.12)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.7.0->-r T2F/requirements.txt (line 1)) (0.33.6)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.7.0->-r T2F/requirements.txt (line 1)) (0.8.0)\n",
            "Requirement already satisfied: protobuf>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.7.0->-r T2F/requirements.txt (line 1)) (3.7.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.7.0->-r T2F/requirements.txt (line 1)) (1.15.0)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.7.0->-r T2F/requirements.txt (line 1)) (0.8.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.7.0->-r T2F/requirements.txt (line 1)) (1.12.0)\n",
            "Requirement already satisfied: tensorboard<1.8.0,>=1.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.7.0->-r T2F/requirements.txt (line 1)) (1.7.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.7.0->-r T2F/requirements.txt (line 1)) (1.1.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.7.0->-r T2F/requirements.txt (line 1)) (0.2.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.4.0->tensorflow==1.7.0->-r T2F/requirements.txt (line 1)) (41.2.0)\n",
            "Requirement already satisfied: bleach==1.5.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.8.0,>=1.7.0->tensorflow==1.7.0->-r T2F/requirements.txt (line 1)) (1.5.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.8.0,>=1.7.0->tensorflow==1.7.0->-r T2F/requirements.txt (line 1)) (3.1.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.8.0,>=1.7.0->tensorflow==1.7.0->-r T2F/requirements.txt (line 1)) (0.15.5)\n",
            "Requirement already satisfied: html5lib==0.9999999 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.8.0,>=1.7.0->tensorflow==1.7.0->-r T2F/requirements.txt (line 1)) (0.9999999)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBhkXeqOE_s8",
        "colab_type": "code",
        "outputId": "b1131f2c-8f10-408b-978c-c0f631b26a22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        }
      },
      "source": [
        "!pip uninstall -y torch\n",
        "!pip install https://download.pytorch.org/whl/cu100/torch-1.0.0-cp36-cp36m-linux_x86_64.whl"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling torch-0.4.0:\n",
            "  Successfully uninstalled torch-0.4.0\n",
            "Collecting torch==1.0.0 from https://download.pytorch.org/whl/cu100/torch-1.0.0-cp36-cp36m-linux_x86_64.whl\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu100/torch-1.0.0-cp36-cp36m-linux_x86_64.whl (753.6MB)\n",
            "\u001b[K     |████████████████████████████████| 753.6MB 26kB/s \n",
            "\u001b[31mERROR: fastai 1.0.57 has requirement numpy>=1.15, but you'll have numpy 1.13.1 which is incompatible.\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch\n",
            "Successfully installed torch-1.0.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torch"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZaVdADhcBJkm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "sys.path.append('/content/T2F/implementation')\n",
        "sys.path.append('/content/T2F/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGLwh_7QBt7g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from train_network import main as main_train\n",
        "from train_network import get_config\n",
        "\n",
        "import argparse\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument(\"--config\", action=\"store\", type=str, default=\"/content/T2F/implementation/configs/2_colab.conf\",\n",
        "                    help=\"default configuration for the Network\")\n",
        "parser.add_argument(\"--start_depth\", action=\"store\", type=int, default=0,\n",
        "                    help=\"Starting depth for training the network\")\n",
        "parser.add_argument(\"--encoder_file\", action=\"store\", type=str, default=None,\n",
        "                    help=\"pretrained Encoder file (compatible with my code)\")\n",
        "parser.add_argument(\"--ca_file\", action=\"store\", type=str, default=None,\n",
        "                    help=\"pretrained Conditioning Augmentor file (compatible with my code)\")\n",
        "parser.add_argument(\"--generator_file\", action=\"store\", type=str, default=None,\n",
        "                    help=\"pretrained Generator file (compatible with my code)\")\n",
        "parser.add_argument(\"--discriminator_file\", action=\"store\", type=str, default=None,\n",
        "                    help=\"pretrained Discriminator file (compatible with my code)\")\n",
        "\n",
        "args = parser.parse_args([])\n",
        "config = get_config(args.config)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAcVy6VAB4tx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch as th\n",
        "\n",
        "class ConditionAugmentor(th.nn.Module):\n",
        "    \"\"\" Perform conditioning augmentation\n",
        "        from the paper -> https://arxiv.org/abs/1710.10916 (StackGAN++)\n",
        "        uses the reparameterization trick from VAE paper.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, input_size, latent_size, use_eql=True, device=th.device(\"cpu\")):\n",
        "        \"\"\"\n",
        "        constructor of the class\n",
        "        :param input_size: input size to the augmentor\n",
        "        :param latent_size: required output size\n",
        "        :param use_eql: boolean for whether to use equalized learning rate\n",
        "        :param device: device on which to run the Module\n",
        "        \"\"\"\n",
        "        super(ConditionAugmentor, self).__init__()\n",
        "\n",
        "        assert latent_size % 2 == 0, \"Latent manifold has odd number of dimensions\"\n",
        "\n",
        "        # state of the object\n",
        "        self.device = device\n",
        "        self.input_size = input_size\n",
        "        self.latent_size = latent_size\n",
        "\n",
        "        # required modules:\n",
        "        if use_eql:\n",
        "            from pro_gan_pytorch.CustomLayers import _equalized_linear\n",
        "            self.transformer = _equalized_linear(self.input_size, 2 * self.latent_size).to(device)\n",
        "        else:\n",
        "            self.transformer = th.nn.Linear(self.input_size, 2 * self.latent_size).to(device)\n",
        "\n",
        "    def forward(self, x, epsilon=1e-12):\n",
        "        \"\"\"\n",
        "        forward pass (computations)\n",
        "        :param x: input\n",
        "        :param epsilon: a small noise added for numerical stability\n",
        "        :return: c_not_hat, mus, sigmas => augmented text embeddings, means, stds\n",
        "        \"\"\"\n",
        "        from torch.nn.functional import relu\n",
        "\n",
        "        # apply the feed forward layer:\n",
        "        combined = self.transformer(x)\n",
        "\n",
        "        # use the reparameterization trick\n",
        "        mid_point = self.latent_size\n",
        "        mus, sigmas = combined[:, :mid_point], combined[:, mid_point:]\n",
        "\n",
        "        # mus don't need to be transformed, but sigmas cannot be negative.\n",
        "        # so, we'll apply a ReLU on top of sigmas\n",
        "        sigmas = relu(sigmas)  # hopefully the network will learn a good sigma mapping\n",
        "        sigmas = sigmas + epsilon  # small noise added for stability\n",
        "\n",
        "        epsilon = th.randn(*mus.shape).to(self.device)\n",
        "        c_not_hat = (epsilon * sigmas) + mus\n",
        "\n",
        "        return c_not_hat, mus, sigmas"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fazQkGWBB8RE",
        "colab_type": "code",
        "outputId": "9c9e64fb-df75-4032-8825-ce3a2612df53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "device = 'cuda'\n",
        "\n",
        "import data_processing.DataLoader as dl\n",
        "\n",
        "dataset = dl.RawTextFace2TextDataset(\n",
        "    annots_file=config.annotations_file,\n",
        "    img_dir=config.images_dir,\n",
        "    img_transform=dl.get_transform(config.img_dims)\n",
        ")\n",
        "from networks.TextEncoder import PretrainedEncoder\n",
        "# create a new session object for the pretrained encoder:\n",
        "text_encoder = PretrainedEncoder(\n",
        "    model_file=config.pretrained_encoder_file,\n",
        "    embedding_file=config.pretrained_embedding_file,\n",
        "    device=device\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocab size : 300000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CfHbtIVSB_3E",
        "colab_type": "code",
        "outputId": "48eb5d1b-1e4c-4cf3-9afa-9da40b2ab3c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "\n",
        "\n",
        "text_encoder = PretrainedEncoder(\n",
        "    model_file=config.pretrained_encoder_file,\n",
        "    embedding_file=config.pretrained_embedding_file,\n",
        "    device=device\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocab size : 300000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5MYUo1-dCHKt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "condition_augmenter = ConditionAugmentor(\n",
        "    input_size=config.hidden_size,\n",
        "    latent_size=config.ca_out_size,\n",
        "    use_eql=config.use_eql,\n",
        "    device='cuda'\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6UkJ_w5CND7",
        "colab_type": "code",
        "outputId": "32ab618c-4d10-4d3c-dc96-76d5c236e27e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "temp_data = dl.get_data_loader(dataset, 64, num_workers=3)\n",
        "fixed_captions, fixed_real_images = iter(temp_data).next()\n",
        "fixed_embeddings = text_encoder(fixed_captions)\n",
        "fixed_embeddings.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(64, 4096)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yya7kN5fCPjh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "condition_augmenter.train()\n",
        "\n",
        "# create fixed_input for debugging\n",
        "temp_data = dl.get_data_loader(dataset, 64, num_workers=3)\n",
        "fixed_captions, fixed_real_images = iter(temp_data).next()\n",
        "fixed_embeddings = text_encoder(fixed_captions)\n",
        "fixed_embeddings = th.from_numpy(fixed_embeddings).to(device)\n",
        "\n",
        "fixed_c_not_hats, _, _ = condition_augmenter(fixed_embeddings)\n",
        "\n",
        "fixed_noise = th.randn(len(fixed_captions),\n",
        "                       config.latent_size - fixed_c_not_hats.shape[-1]).to(device)\n",
        "\n",
        "fixed_gan_input = th.cat((fixed_c_not_hats, fixed_noise), dim=-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8dfgG6dCSpS",
        "colab_type": "code",
        "outputId": "ae68119b-fd4e-4ab3-d320-d76d858ad8fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "\n",
        "\n",
        "fixed_embeddings.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 4096])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOeh1cedCjmV",
        "colab_type": "code",
        "outputId": "a4e57ea6-78f2-4bd6-b40b-b998db464732",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 862
        }
      },
      "source": [
        "import torch\n",
        "torch.load('/content/T2F/implementation/networks/InferSent/models/infersent2.pkl')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('enc_lstm.weight_ih_l0',\n",
              "              tensor([[-0.0188, -0.0096, -0.0165,  ...,  0.0063,  0.0177,  0.0182],\n",
              "                      [ 0.0040, -0.0170,  0.0282,  ...,  0.0270, -0.0006, -0.0099],\n",
              "                      [-0.0333,  0.0013,  0.0235,  ...,  0.0239, -0.0444,  0.0009],\n",
              "                      ...,\n",
              "                      [ 0.0068, -0.0130, -0.0136,  ..., -0.0003,  0.0145, -0.0031],\n",
              "                      [-0.0075, -0.0210,  0.0135,  ...,  0.0149, -0.0059,  0.0018],\n",
              "                      [-0.0076,  0.0241, -0.0258,  ..., -0.0104,  0.0177,  0.0241]])),\n",
              "             ('enc_lstm.weight_hh_l0',\n",
              "              tensor([[ 2.4178e-02, -3.4815e-03, -1.5027e-02,  ...,  2.3643e-02,\n",
              "                       -4.6200e-03, -1.2944e-02],\n",
              "                      [ 2.1155e-02, -9.4947e-03,  2.8347e-02,  ..., -1.1898e-02,\n",
              "                       -1.6273e-02, -1.7331e-02],\n",
              "                      [ 1.6204e-02, -2.0330e-02, -6.8777e-03,  ..., -8.8209e-03,\n",
              "                       -1.4847e-02, -1.4684e-03],\n",
              "                      ...,\n",
              "                      [-1.4652e-02,  1.8830e-02, -1.7304e-02,  ..., -3.0782e-03,\n",
              "                        2.2650e-02, -3.0427e-03],\n",
              "                      [ 2.0105e-02,  1.5485e-02, -1.2704e-02,  ..., -5.0405e-03,\n",
              "                        4.3332e-03,  9.8781e-03],\n",
              "                      [ 1.2839e-02,  1.2623e-02,  2.7439e-02,  ...,  4.0228e-05,\n",
              "                        4.5512e-03,  1.6263e-02]])),\n",
              "             ('enc_lstm.bias_ih_l0',\n",
              "              tensor([-0.0611, -0.0055, -0.0385,  ..., -0.0347, -0.0104, -0.0246])),\n",
              "             ('enc_lstm.bias_hh_l0',\n",
              "              tensor([-0.0852, -0.0344, -0.0362,  ..., -0.0244, -0.0167, -0.0584])),\n",
              "             ('enc_lstm.weight_ih_l0_reverse',\n",
              "              tensor([[ 0.0149,  0.0063, -0.0095,  ...,  0.0191, -0.0228, -0.0023],\n",
              "                      [ 0.0053, -0.0351,  0.0062,  ..., -0.0176, -0.0210,  0.0186],\n",
              "                      [-0.0078, -0.0183, -0.0037,  ..., -0.0404, -0.0088,  0.0136],\n",
              "                      ...,\n",
              "                      [ 0.0017,  0.0079,  0.0176,  ...,  0.0165, -0.0082,  0.0047],\n",
              "                      [ 0.0163, -0.0105,  0.0024,  ..., -0.0031,  0.0013,  0.0086],\n",
              "                      [ 0.0180,  0.0215, -0.0032,  ...,  0.0184,  0.0044, -0.0037]])),\n",
              "             ('enc_lstm.weight_hh_l0_reverse',\n",
              "              tensor([[-0.0206,  0.0005, -0.0076,  ...,  0.0196, -0.0039,  0.0148],\n",
              "                      [ 0.0176, -0.0246,  0.0089,  ...,  0.0132,  0.0191, -0.0216],\n",
              "                      [-0.0119, -0.0183,  0.0064,  ...,  0.0153, -0.0011, -0.0028],\n",
              "                      ...,\n",
              "                      [ 0.0219, -0.0189,  0.0177,  ..., -0.0026, -0.0062,  0.0181],\n",
              "                      [ 0.0069, -0.0137,  0.0187,  ...,  0.0125, -0.0003,  0.0183],\n",
              "                      [ 0.0168,  0.0030,  0.0150,  ..., -0.0136,  0.0115,  0.0183]])),\n",
              "             ('enc_lstm.bias_ih_l0_reverse',\n",
              "              tensor([-0.0459, -0.0489, -0.0311,  ..., -0.0428, -0.0268, -0.0623])),\n",
              "             ('enc_lstm.bias_hh_l0_reverse',\n",
              "              tensor([-0.0369, -0.0386, -0.0591,  ..., -0.0653, -0.0569, -0.0519]))])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRSsWayzCnMq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir gdrive/My\\ Drive/T2F/training_runs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwK2ISxIC-pL",
        "colab_type": "code",
        "outputId": "29588d2f-7e22-49f3-b234-e6c3d59cb59c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "!mkdir gdrive/My\\ Drive/T2F/training_runs/generated_samples training_runs/losses training_runs/saved_models"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘training_runs/losses’: No such file or directory\n",
            "mkdir: cannot create directory ‘training_runs/saved_models’: No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRaCrXRLDFWt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir gdrive/My\\ Drive/T2F/training_runs/losses"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUOar7YKEEm_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir gdrive/My\\ Drive/T2F/training_runs/saved_models"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2O8FqtqYEKco",
        "colab_type": "code",
        "outputId": "1d993efa-9165-46ec-9025-cb9b5a742974",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from networks.TextEncoder import PretrainedEncoder\n",
        "# create a new session object for the pretrained encoder:\n",
        "text_encoder = PretrainedEncoder(\n",
        "    model_file='/content/T2F/implementation/networks/InferSent/models/infersent2.pkl',\n",
        "    embedding_file='/content/T2F/implementation/networks/InferSent/models/glove.840B.300d.txt',\n",
        "    device='cuda'\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocab size : 300000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3U_XS4cERu8",
        "colab_type": "code",
        "outputId": "060ba227-d28d-4f82-c69b-530264667930",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "main_train(args)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/T2F/implementation/configs/2_colab.conf\n",
            "Current Configuration: {'images_dir': '/content/lfw', 'processed_text_file': '/content/T2F/implementation/processed_annotations/processed_text.pkl', 'annotations_file': '/content/T2F/data/face2text_v0.1/clean.json', 'pretrained_encoder_file': '/content/gdrive/My Drive/T2F/infersent2.pkl', 'pretrained_embedding_file': '/content/gdrive/My Drive/T2F/glove.840B.300d.txt', 'log_dir': '/content/gdrive/My Drive/T2F/training_runs/2/losses/', 'sample_dir': '/content/gdrive/My Drive/T2F/training_runs/2/generated_samples/', 'save_dir': '/content/gdrive/My Drive/T2F/training_runs/2/saved_models/', 'captions_length': 100, 'img_dims': [64, 64], 'use_pretrained_encoder': True, 'hidden_size': 4096, 'ca_out_size': 128, 'compressed_latent_size': 32, 'use_eql': True, 'use_ema': True, 'ema_decay': 0.999, 'depth': 5, 'latent_size': 256, 'learning_rate': 0.001, 'beta_1': 0, 'beta_2': 0.99, 'eps': 1e-08, 'drift': 0.001, 'n_critic': 1, 'epochs': [120, 120, 120, 120, 120], 'fade_in_percentage': [50, 50, 50, 50, 50], 'batch_sizes': [64, 64, 64, 64, 32], 'loss_function': 'wgan-gp', 'num_workers': 3, 'feedback_factor': 1, 'checkpoint_factor': 10, 'use_matching_aware_discriminator': True}\n",
            "Vocab size : 300000\n",
            "Generator Config:\n",
            "Generator(\n",
            "  (initial_block): GenInitialBlock(\n",
            "    (conv_1): _equalized_deconv2d(\n",
            "      (deconv): ConvTranspose2d(256, 256, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
            "    )\n",
            "    (conv_2): _equalized_conv2d(\n",
            "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    )\n",
            "    (pixNorm): PixelwiseNorm()\n",
            "    (lrelu): LeakyReLU(negative_slope=0.2)\n",
            "  )\n",
            "  (layers): ModuleList(\n",
            "    (0): GenGeneralConvBlock(\n",
            "      (upsample): Upsample(scale_factor=2, mode=nearest)\n",
            "      (conv_1): _equalized_conv2d(\n",
            "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (conv_2): _equalized_conv2d(\n",
            "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (pixNorm): PixelwiseNorm()\n",
            "      (lrelu): LeakyReLU(negative_slope=0.2)\n",
            "    )\n",
            "    (1): GenGeneralConvBlock(\n",
            "      (upsample): Upsample(scale_factor=2, mode=nearest)\n",
            "      (conv_1): _equalized_conv2d(\n",
            "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (conv_2): _equalized_conv2d(\n",
            "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (pixNorm): PixelwiseNorm()\n",
            "      (lrelu): LeakyReLU(negative_slope=0.2)\n",
            "    )\n",
            "    (2): GenGeneralConvBlock(\n",
            "      (upsample): Upsample(scale_factor=2, mode=nearest)\n",
            "      (conv_1): _equalized_conv2d(\n",
            "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (conv_2): _equalized_conv2d(\n",
            "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (pixNorm): PixelwiseNorm()\n",
            "      (lrelu): LeakyReLU(negative_slope=0.2)\n",
            "    )\n",
            "    (3): GenGeneralConvBlock(\n",
            "      (upsample): Upsample(scale_factor=2, mode=nearest)\n",
            "      (conv_1): _equalized_conv2d(\n",
            "        (conv): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (conv_2): _equalized_conv2d(\n",
            "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (pixNorm): PixelwiseNorm()\n",
            "      (lrelu): LeakyReLU(negative_slope=0.2)\n",
            "    )\n",
            "  )\n",
            "  (rgb_converters): ModuleList(\n",
            "    (0): _equalized_conv2d(\n",
            "      (conv): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    )\n",
            "    (1): _equalized_conv2d(\n",
            "      (conv): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    )\n",
            "    (2): _equalized_conv2d(\n",
            "      (conv): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    )\n",
            "    (3): _equalized_conv2d(\n",
            "      (conv): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    )\n",
            "    (4): _equalized_conv2d(\n",
            "      (conv): Conv2d(128, 3, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    )\n",
            "  )\n",
            "  (temporaryUpsampler): Upsample(scale_factor=2, mode=nearest)\n",
            ")\n",
            "\n",
            "Discriminator Config:\n",
            "ConditionalDiscriminator(\n",
            "  (final_block): ConDisFinalBlock(\n",
            "    (batch_discriminator): MinibatchStdDev()\n",
            "    (compressor): _equalized_linear()\n",
            "    (conv_1): _equalized_conv2d(\n",
            "      (conv): Conv2d(257, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    )\n",
            "    (conv_2): _equalized_conv2d(\n",
            "      (conv): Conv2d(288, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    )\n",
            "    (conv_3): _equalized_conv2d(\n",
            "      (conv): Conv2d(256, 256, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
            "    )\n",
            "    (conv_4): _equalized_conv2d(\n",
            "      (conv): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    )\n",
            "    (lrelu): LeakyReLU(negative_slope=0.2)\n",
            "  )\n",
            "  (layers): ModuleList(\n",
            "    (0): DisGeneralConvBlock(\n",
            "      (conv_1): _equalized_conv2d(\n",
            "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (conv_2): _equalized_conv2d(\n",
            "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (downSampler): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "      (lrelu): LeakyReLU(negative_slope=0.2)\n",
            "    )\n",
            "    (1): DisGeneralConvBlock(\n",
            "      (conv_1): _equalized_conv2d(\n",
            "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (conv_2): _equalized_conv2d(\n",
            "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (downSampler): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "      (lrelu): LeakyReLU(negative_slope=0.2)\n",
            "    )\n",
            "    (2): DisGeneralConvBlock(\n",
            "      (conv_1): _equalized_conv2d(\n",
            "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (conv_2): _equalized_conv2d(\n",
            "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (downSampler): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "      (lrelu): LeakyReLU(negative_slope=0.2)\n",
            "    )\n",
            "    (3): DisGeneralConvBlock(\n",
            "      (conv_1): _equalized_conv2d(\n",
            "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (conv_2): _equalized_conv2d(\n",
            "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      )\n",
            "      (downSampler): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "      (lrelu): LeakyReLU(negative_slope=0.2)\n",
            "    )\n",
            "  )\n",
            "  (rgb_to_features): ModuleList(\n",
            "    (0): _equalized_conv2d(\n",
            "      (conv): Conv2d(3, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    )\n",
            "    (1): _equalized_conv2d(\n",
            "      (conv): Conv2d(3, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    )\n",
            "    (2): _equalized_conv2d(\n",
            "      (conv): Conv2d(3, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    )\n",
            "    (3): _equalized_conv2d(\n",
            "      (conv): Conv2d(3, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    )\n",
            "    (4): _equalized_conv2d(\n",
            "      (conv): Conv2d(3, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    )\n",
            "  )\n",
            "  (temporaryDownsampler): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            ")\n",
            "Starting the training process ... \n",
            "\n",
            "\n",
            "Currently working on Depth:  0\n",
            "Current resolution: 4 x 4\n",
            "\n",
            "Epoch: 1\n",
            "Elapsed [0:00:03.142820]  batch: 1  d_loss: 8.900857  g_loss: 0.016902  kl_los: 1920.030518\n",
            "Elapsed [0:00:10.075543]  batch: 20  d_loss: 5.128726  g_loss: 1.504413  kl_los: 884.348816\n",
            "Time taken for epoch: 10.245 secs\n",
            "\n",
            "Epoch: 2\n",
            "Elapsed [0:00:12.373543]  batch: 1  d_loss: 5.091328  g_loss: 1.818269  kl_los: 842.091553\n",
            "Elapsed [0:00:18.875821]  batch: 20  d_loss: -1.636189  g_loss: 7.042101  kl_los: 418.870087\n",
            "Time taken for epoch: 8.819 secs\n",
            "\n",
            "Epoch: 3\n",
            "Elapsed [0:00:21.496204]  batch: 1  d_loss: -1.751577  g_loss: 7.771679  kl_los: 416.580200\n",
            "Elapsed [0:00:27.806211]  batch: 20  d_loss: -17.772442  g_loss: 21.437420  kl_los: 345.919861\n",
            "Time taken for epoch: 8.905 secs\n",
            "\n",
            "Epoch: 4\n",
            "Elapsed [0:00:30.089412]  batch: 1  d_loss: -19.577169  g_loss: 23.681736  kl_los: 322.575134\n",
            "Elapsed [0:00:36.541502]  batch: 20  d_loss: -47.841095  g_loss: 54.962624  kl_los: 270.566132\n",
            "Time taken for epoch: 8.752 secs\n",
            "\n",
            "Epoch: 5\n",
            "Elapsed [0:00:38.931723]  batch: 1  d_loss: -49.129829  g_loss: 57.111565  kl_los: 281.854706\n",
            "Elapsed [0:00:45.410583]  batch: 20  d_loss: -113.359352  g_loss: 142.011612  kl_los: 241.874542\n",
            "Time taken for epoch: 8.852 secs\n",
            "\n",
            "Epoch: 6\n",
            "Elapsed [0:00:47.651346]  batch: 1  d_loss: -117.063499  g_loss: 147.591614  kl_los: 249.591156\n",
            "Elapsed [0:00:54.196884]  batch: 20  d_loss: -205.808807  g_loss: 311.978516  kl_los: 218.851944\n",
            "Time taken for epoch: 8.789 secs\n",
            "\n",
            "Epoch: 7\n",
            "Elapsed [0:00:56.489546]  batch: 1  d_loss: -204.340729  g_loss: 321.588196  kl_los: 222.066101\n",
            "Elapsed [0:01:03.078108]  batch: 20  d_loss: -241.218292  g_loss: 443.612549  kl_los: 189.542343\n",
            "Time taken for epoch: 8.881 secs\n",
            "\n",
            "Epoch: 8\n",
            "Elapsed [0:01:05.388436]  batch: 1  d_loss: -241.763535  g_loss: 448.268280  kl_los: 192.014282\n",
            "Elapsed [0:01:11.981397]  batch: 20  d_loss: -247.502106  g_loss: 490.621185  kl_los: 173.755310\n",
            "Time taken for epoch: 8.902 secs\n",
            "\n",
            "Epoch: 9\n",
            "Elapsed [0:01:14.226418]  batch: 1  d_loss: -245.790039  g_loss: 488.074829  kl_los: 176.948792\n",
            "Elapsed [0:01:20.698649]  batch: 20  d_loss: -246.610291  g_loss: 503.383514  kl_los: 154.795761\n",
            "Time taken for epoch: 8.756 secs\n",
            "\n",
            "Epoch: 10\n",
            "Elapsed [0:01:23.168524]  batch: 1  d_loss: -247.972046  g_loss: 495.155701  kl_los: 163.882767\n",
            "Elapsed [0:01:29.573333]  batch: 20  d_loss: -246.689133  g_loss: 495.149841  kl_los: 150.536606\n",
            "Time taken for epoch: 8.832 secs\n",
            "\n",
            "Epoch: 11\n",
            "Elapsed [0:01:32.196556]  batch: 1  d_loss: -246.595200  g_loss: 491.699097  kl_los: 160.051102\n",
            "Elapsed [0:01:38.670529]  batch: 20  d_loss: -247.698990  g_loss: 489.140320  kl_los: 153.133591\n",
            "Time taken for epoch: 8.921 secs\n",
            "\n",
            "Epoch: 12\n",
            "Elapsed [0:01:41.081934]  batch: 1  d_loss: -246.652542  g_loss: 495.199341  kl_los: 154.399826\n",
            "Elapsed [0:01:47.586729]  batch: 20  d_loss: -250.454880  g_loss: 500.302429  kl_los: 138.287567\n",
            "Time taken for epoch: 8.900 secs\n",
            "\n",
            "Epoch: 13\n",
            "Elapsed [0:01:49.754371]  batch: 1  d_loss: -247.655975  g_loss: 497.655731  kl_los: 142.692261\n",
            "Elapsed [0:01:56.318305]  batch: 20  d_loss: -248.083008  g_loss: 496.430634  kl_los: 134.396515\n",
            "Time taken for epoch: 8.795 secs\n",
            "\n",
            "Epoch: 14\n",
            "Elapsed [0:01:58.717540]  batch: 1  d_loss: -247.391220  g_loss: 496.739105  kl_los: 136.182755\n",
            "Elapsed [0:02:05.262555]  batch: 20  d_loss: -248.300308  g_loss: 494.154724  kl_los: 136.180115\n",
            "Time taken for epoch: 8.888 secs\n",
            "\n",
            "Epoch: 15\n",
            "Elapsed [0:02:07.450315]  batch: 1  d_loss: -246.770004  g_loss: 497.202606  kl_los: 137.137222\n",
            "Elapsed [0:02:13.908553]  batch: 20  d_loss: -249.612900  g_loss: 502.214142  kl_los: 135.657791\n",
            "Time taken for epoch: 8.650 secs\n",
            "\n",
            "Epoch: 16\n",
            "Elapsed [0:02:16.192313]  batch: 1  d_loss: -251.406143  g_loss: 503.818237  kl_los: 128.845779\n",
            "Elapsed [0:02:22.661819]  batch: 20  d_loss: -247.901779  g_loss: 505.614502  kl_los: 119.294342\n",
            "Time taken for epoch: 8.749 secs\n",
            "\n",
            "Epoch: 17\n",
            "Elapsed [0:02:25.127778]  batch: 1  d_loss: -248.371887  g_loss: 504.822296  kl_los: 124.167969\n",
            "Elapsed [0:02:31.572263]  batch: 20  d_loss: -247.922943  g_loss: 495.671661  kl_los: 119.853447\n",
            "Time taken for epoch: 8.915 secs\n",
            "\n",
            "Epoch: 18\n",
            "Elapsed [0:02:34.071083]  batch: 1  d_loss: -250.636002  g_loss: 498.595886  kl_los: 119.738785\n",
            "Elapsed [0:02:40.369350]  batch: 20  d_loss: -251.929367  g_loss: 505.593536  kl_los: 114.227875\n",
            "Time taken for epoch: 8.791 secs\n",
            "\n",
            "Epoch: 19\n",
            "Elapsed [0:02:42.693008]  batch: 1  d_loss: -250.570358  g_loss: 502.465515  kl_los: 114.175201\n",
            "Elapsed [0:02:49.265658]  batch: 20  d_loss: -249.969849  g_loss: 507.741821  kl_los: 110.840858\n",
            "Time taken for epoch: 8.892 secs\n",
            "\n",
            "Epoch: 20\n",
            "Elapsed [0:02:51.461189]  batch: 1  d_loss: -249.204071  g_loss: 512.567810  kl_los: 122.320389\n",
            "Elapsed [0:02:57.958724]  batch: 20  d_loss: -251.313721  g_loss: 501.048218  kl_los: 111.754440\n",
            "Time taken for epoch: 8.727 secs\n",
            "\n",
            "Epoch: 21\n",
            "Elapsed [0:03:00.549538]  batch: 1  d_loss: -250.892776  g_loss: 501.075684  kl_los: 110.274490\n",
            "Elapsed [0:03:06.980282]  batch: 20  d_loss: -250.182724  g_loss: 502.725220  kl_los: 107.412155\n",
            "Time taken for epoch: 8.824 secs\n",
            "\n",
            "Epoch: 22\n",
            "Elapsed [0:03:09.254170]  batch: 1  d_loss: -250.678024  g_loss: 499.270172  kl_los: 107.359550\n",
            "Elapsed [0:03:15.893480]  batch: 20  d_loss: -250.096481  g_loss: 503.882202  kl_los: 104.573524\n",
            "Time taken for epoch: 8.863 secs\n",
            "\n",
            "Epoch: 23\n",
            "Elapsed [0:03:18.463217]  batch: 1  d_loss: -250.829941  g_loss: 503.689575  kl_los: 104.846153\n",
            "Elapsed [0:03:24.857434]  batch: 20  d_loss: -250.912933  g_loss: 507.475677  kl_los: 108.561790\n",
            "Time taken for epoch: 8.968 secs\n",
            "\n",
            "Epoch: 24\n",
            "Elapsed [0:03:27.111935]  batch: 1  d_loss: -253.261337  g_loss: 510.082245  kl_los: 101.890152\n",
            "Elapsed [0:03:33.612570]  batch: 20  d_loss: -251.934067  g_loss: 502.550598  kl_los: 105.408638\n",
            "Time taken for epoch: 8.765 secs\n",
            "\n",
            "Epoch: 25\n",
            "Elapsed [0:03:35.987550]  batch: 1  d_loss: -248.945908  g_loss: 501.787994  kl_los: 101.951500\n",
            "Elapsed [0:03:42.456079]  batch: 20  d_loss: -250.287643  g_loss: 501.791443  kl_los: 100.270836\n",
            "Time taken for epoch: 8.836 secs\n",
            "\n",
            "Epoch: 26\n",
            "Elapsed [0:03:44.986240]  batch: 1  d_loss: -251.668640  g_loss: 501.394684  kl_los: 98.603256\n",
            "Elapsed [0:03:51.293494]  batch: 20  d_loss: -251.791046  g_loss: 502.516113  kl_los: 99.819550\n",
            "Time taken for epoch: 8.868 secs\n",
            "\n",
            "Epoch: 27\n",
            "Elapsed [0:03:53.678432]  batch: 1  d_loss: -251.491898  g_loss: 507.638245  kl_los: 101.459778\n",
            "Elapsed [0:04:00.212536]  batch: 20  d_loss: -250.554810  g_loss: 505.540802  kl_los: 94.403473\n",
            "Time taken for epoch: 8.884 secs\n",
            "\n",
            "Epoch: 28\n",
            "Elapsed [0:04:02.592912]  batch: 1  d_loss: -251.262833  g_loss: 502.235229  kl_los: 97.567856\n",
            "Elapsed [0:04:09.071190]  batch: 20  d_loss: -251.341614  g_loss: 500.932068  kl_los: 93.818497\n",
            "Time taken for epoch: 8.883 secs\n",
            "\n",
            "Epoch: 29\n",
            "Elapsed [0:04:11.435822]  batch: 1  d_loss: -250.467606  g_loss: 503.305511  kl_los: 93.779518\n",
            "Elapsed [0:04:17.881560]  batch: 20  d_loss: -249.800476  g_loss: 499.480286  kl_los: 92.674599\n",
            "Time taken for epoch: 8.787 secs\n",
            "\n",
            "Epoch: 30\n",
            "Elapsed [0:04:20.363431]  batch: 1  d_loss: -250.298355  g_loss: 504.772217  kl_los: 92.056900\n",
            "Elapsed [0:04:26.815053]  batch: 20  d_loss: -250.157852  g_loss: 496.800079  kl_los: 96.614082\n",
            "Time taken for epoch: 8.933 secs\n",
            "\n",
            "Epoch: 31\n",
            "Elapsed [0:04:29.268941]  batch: 1  d_loss: -249.729980  g_loss: 502.310974  kl_los: 93.703285\n",
            "Elapsed [0:04:36.021336]  batch: 20  d_loss: -248.662628  g_loss: 497.936035  kl_los: 91.468575\n",
            "Time taken for epoch: 9.006 secs\n",
            "\n",
            "Epoch: 32\n",
            "Elapsed [0:04:38.358274]  batch: 1  d_loss: -250.566132  g_loss: 502.612793  kl_los: 96.086784\n",
            "Elapsed [0:04:44.904134]  batch: 20  d_loss: -250.752991  g_loss: 504.412262  kl_los: 89.401848\n",
            "Time taken for epoch: 8.877 secs\n",
            "\n",
            "Epoch: 33\n",
            "Elapsed [0:04:47.162609]  batch: 1  d_loss: -250.733856  g_loss: 502.882568  kl_los: 89.810684\n",
            "Elapsed [0:04:53.619435]  batch: 20  d_loss: -252.033981  g_loss: 502.648041  kl_los: 90.813492\n",
            "Time taken for epoch: 8.713 secs\n",
            "\n",
            "Epoch: 34\n",
            "Elapsed [0:04:55.866472]  batch: 1  d_loss: -249.993988  g_loss: 500.581909  kl_los: 91.295792\n",
            "Elapsed [0:05:02.429157]  batch: 20  d_loss: -248.200729  g_loss: 497.946198  kl_los: 88.860786\n",
            "Time taken for epoch: 8.864 secs\n",
            "\n",
            "Epoch: 35\n",
            "Elapsed [0:05:04.490665]  batch: 1  d_loss: -248.077881  g_loss: 502.783173  kl_los: 90.278931\n",
            "Elapsed [0:05:10.939346]  batch: 20  d_loss: -251.171021  g_loss: 501.423462  kl_los: 89.075172\n",
            "Time taken for epoch: 8.453 secs\n",
            "\n",
            "Epoch: 36\n",
            "Elapsed [0:05:13.305607]  batch: 1  d_loss: -249.422501  g_loss: 501.509277  kl_los: 87.948868\n",
            "Elapsed [0:05:19.747412]  batch: 20  d_loss: -249.927246  g_loss: 498.495636  kl_los: 91.481926\n",
            "Time taken for epoch: 8.883 secs\n",
            "\n",
            "Epoch: 37\n",
            "Elapsed [0:05:22.178087]  batch: 1  d_loss: -250.265350  g_loss: 503.671051  kl_los: 89.408936\n",
            "Elapsed [0:05:28.659145]  batch: 20  d_loss: -249.957901  g_loss: 501.559937  kl_los: 87.259216\n",
            "Time taken for epoch: 8.869 secs\n",
            "\n",
            "Epoch: 38\n",
            "Elapsed [0:05:31.054038]  batch: 1  d_loss: -250.072678  g_loss: 499.541443  kl_los: 87.506981\n",
            "Elapsed [0:05:37.609199]  batch: 20  d_loss: -249.424210  g_loss: 498.777435  kl_los: 87.799850\n",
            "Time taken for epoch: 8.923 secs\n",
            "\n",
            "Epoch: 39\n",
            "Elapsed [0:05:39.965149]  batch: 1  d_loss: -248.436447  g_loss: 504.354553  kl_los: 87.717194\n",
            "Elapsed [0:05:46.444696]  batch: 20  d_loss: -250.627747  g_loss: 504.608734  kl_los: 86.516907\n",
            "Time taken for epoch: 8.832 secs\n",
            "\n",
            "Epoch: 40\n",
            "Elapsed [0:05:48.789529]  batch: 1  d_loss: -249.259750  g_loss: 498.444580  kl_los: 87.485733\n",
            "Elapsed [0:05:55.209888]  batch: 20  d_loss: -249.286209  g_loss: 498.407837  kl_los: 85.129189\n",
            "Time taken for epoch: 8.790 secs\n",
            "\n",
            "Epoch: 41\n",
            "Elapsed [0:05:57.775725]  batch: 1  d_loss: -247.484406  g_loss: 505.092468  kl_los: 86.261032\n",
            "Elapsed [0:06:04.308470]  batch: 20  d_loss: -248.555679  g_loss: 506.172913  kl_los: 85.839371\n",
            "Time taken for epoch: 8.877 secs\n",
            "\n",
            "Epoch: 42\n",
            "Elapsed [0:06:06.608451]  batch: 1  d_loss: -249.227097  g_loss: 498.567627  kl_los: 87.494614\n",
            "Elapsed [0:06:13.166681]  batch: 20  d_loss: -249.442703  g_loss: 499.044189  kl_los: 84.582825\n",
            "Time taken for epoch: 8.861 secs\n",
            "\n",
            "Epoch: 43\n",
            "Elapsed [0:06:15.571541]  batch: 1  d_loss: -250.174026  g_loss: 501.619873  kl_los: 93.259094\n",
            "Elapsed [0:06:21.922060]  batch: 20  d_loss: -251.012207  g_loss: 502.243683  kl_los: 85.232796\n",
            "Time taken for epoch: 8.729 secs\n",
            "\n",
            "Epoch: 44\n",
            "Elapsed [0:06:24.475872]  batch: 1  d_loss: -248.501633  g_loss: 504.348541  kl_los: 89.295914\n",
            "Elapsed [0:06:30.779186]  batch: 20  d_loss: -249.764053  g_loss: 503.537109  kl_los: 84.467659\n",
            "Time taken for epoch: 8.854 secs\n",
            "\n",
            "Epoch: 45\n",
            "Elapsed [0:06:33.021611]  batch: 1  d_loss: -250.048233  g_loss: 501.928467  kl_los: 86.008820\n",
            "Elapsed [0:06:39.588012]  batch: 20  d_loss: -249.638245  g_loss: 506.508148  kl_los: 85.452766\n",
            "Time taken for epoch: 8.810 secs\n",
            "\n",
            "Epoch: 46\n",
            "Elapsed [0:06:41.904443]  batch: 1  d_loss: -249.809021  g_loss: 498.970337  kl_los: 84.686386\n",
            "Elapsed [0:06:48.445856]  batch: 20  d_loss: -249.634689  g_loss: 502.326233  kl_los: 83.706848\n",
            "Time taken for epoch: 8.931 secs\n",
            "\n",
            "Epoch: 47\n",
            "Elapsed [0:06:50.755162]  batch: 1  d_loss: -249.546890  g_loss: 500.915100  kl_los: 85.348892\n",
            "Elapsed [0:06:57.254710]  batch: 20  d_loss: -248.399689  g_loss: 498.428009  kl_los: 85.012421\n",
            "Time taken for epoch: 8.734 secs\n",
            "\n",
            "Epoch: 48\n",
            "Elapsed [0:06:59.518018]  batch: 1  d_loss: -249.486206  g_loss: 500.297394  kl_los: 84.416512\n",
            "Elapsed [0:07:06.045509]  batch: 20  d_loss: -247.822983  g_loss: 502.122498  kl_los: 83.621017\n",
            "Time taken for epoch: 8.799 secs\n",
            "\n",
            "Epoch: 49\n",
            "Elapsed [0:07:08.255605]  batch: 1  d_loss: -249.264664  g_loss: 499.120026  kl_los: 84.690018\n",
            "Elapsed [0:07:14.853890]  batch: 20  d_loss: -249.453247  g_loss: 500.218353  kl_los: 83.676201\n",
            "Time taken for epoch: 8.821 secs\n",
            "\n",
            "Epoch: 50\n",
            "Elapsed [0:07:17.218087]  batch: 1  d_loss: -249.755127  g_loss: 500.081421  kl_los: 84.112579\n",
            "Elapsed [0:07:23.705289]  batch: 20  d_loss: -249.473969  g_loss: 496.348419  kl_los: 83.826012\n",
            "Time taken for epoch: 8.871 secs\n",
            "\n",
            "Epoch: 51\n",
            "Elapsed [0:07:26.451035]  batch: 1  d_loss: -247.160980  g_loss: 507.568024  kl_los: 86.280823\n",
            "Elapsed [0:07:32.927434]  batch: 20  d_loss: -250.101212  g_loss: 501.376343  kl_los: 83.630638\n",
            "Time taken for epoch: 8.823 secs\n",
            "\n",
            "Epoch: 52\n",
            "Elapsed [0:07:35.417080]  batch: 1  d_loss: -249.521912  g_loss: 501.284119  kl_los: 83.938339\n",
            "Elapsed [0:07:41.990826]  batch: 20  d_loss: -249.842300  g_loss: 502.439514  kl_los: 83.842766\n",
            "Time taken for epoch: 9.057 secs\n",
            "\n",
            "Epoch: 53\n",
            "Elapsed [0:07:44.387729]  batch: 1  d_loss: -249.616806  g_loss: 500.754272  kl_los: 83.714783\n",
            "Elapsed [0:07:50.896512]  batch: 20  d_loss: -249.617432  g_loss: 501.246002  kl_los: 84.353127\n",
            "Time taken for epoch: 8.900 secs\n",
            "\n",
            "Epoch: 54\n",
            "Elapsed [0:07:53.203874]  batch: 1  d_loss: -250.046753  g_loss: 500.988739  kl_los: 83.237839\n",
            "Elapsed [0:07:59.677572]  batch: 20  d_loss: -249.355392  g_loss: 500.918549  kl_los: 82.812897\n",
            "Time taken for epoch: 8.789 secs\n",
            "\n",
            "Epoch: 55\n",
            "Elapsed [0:08:01.713516]  batch: 1  d_loss: -249.871307  g_loss: 501.981232  kl_los: 83.539192\n",
            "Elapsed [0:08:08.168564]  batch: 20  d_loss: -248.800430  g_loss: 498.474884  kl_los: 83.094109\n",
            "Time taken for epoch: 8.490 secs\n",
            "\n",
            "Epoch: 56\n",
            "Elapsed [0:08:10.394455]  batch: 1  d_loss: -250.055328  g_loss: 501.189453  kl_los: 83.116455\n",
            "Elapsed [0:08:16.881974]  batch: 20  d_loss: -249.864792  g_loss: 503.841980  kl_los: 83.594841\n",
            "Time taken for epoch: 8.709 secs\n",
            "\n",
            "Epoch: 57\n",
            "Elapsed [0:08:19.537550]  batch: 1  d_loss: -248.477509  g_loss: 496.318909  kl_los: 82.613831\n",
            "Elapsed [0:08:26.044612]  batch: 20  d_loss: -249.036301  g_loss: 502.467041  kl_los: 83.047401\n",
            "Time taken for epoch: 9.167 secs\n",
            "\n",
            "Epoch: 58\n",
            "Elapsed [0:08:28.417087]  batch: 1  d_loss: -249.235672  g_loss: 500.274414  kl_los: 83.190872\n",
            "Elapsed [0:08:34.856500]  batch: 20  d_loss: -250.169128  g_loss: 502.148956  kl_los: 83.083038\n",
            "Time taken for epoch: 8.810 secs\n",
            "\n",
            "Epoch: 59\n",
            "Elapsed [0:08:37.222012]  batch: 1  d_loss: -248.659286  g_loss: 499.156006  kl_los: 82.725143\n",
            "Elapsed [0:08:43.625913]  batch: 20  d_loss: -249.458359  g_loss: 501.310730  kl_los: 82.693176\n",
            "Time taken for epoch: 8.772 secs\n",
            "\n",
            "Epoch: 60\n",
            "Elapsed [0:08:45.983431]  batch: 1  d_loss: -248.802094  g_loss: 500.406433  kl_los: 82.755539\n",
            "Elapsed [0:08:52.574674]  batch: 20  d_loss: -249.050293  g_loss: 502.187836  kl_los: 83.563591\n",
            "Time taken for epoch: 8.945 secs\n",
            "\n",
            "Epoch: 61\n",
            "Elapsed [0:08:54.702692]  batch: 1  d_loss: -249.484955  g_loss: 498.966492  kl_los: 82.450211\n",
            "Elapsed [0:09:01.308566]  batch: 20  d_loss: -250.280457  g_loss: 499.889801  kl_los: 82.443695\n",
            "Time taken for epoch: 8.521 secs\n",
            "\n",
            "Epoch: 62\n",
            "Elapsed [0:09:03.937399]  batch: 1  d_loss: -245.340820  g_loss: 506.886414  kl_los: 82.798309\n",
            "Elapsed [0:09:10.502151]  batch: 20  d_loss: -249.356064  g_loss: 501.515167  kl_los: 82.400284\n",
            "Time taken for epoch: 9.174 secs\n",
            "\n",
            "Epoch: 63\n",
            "Elapsed [0:09:12.908899]  batch: 1  d_loss: -248.876999  g_loss: 500.243286  kl_los: 82.552048\n",
            "Elapsed [0:09:19.505080]  batch: 20  d_loss: -248.107468  g_loss: 503.259583  kl_los: 82.632278\n",
            "Time taken for epoch: 8.994 secs\n",
            "\n",
            "Epoch: 64\n",
            "Elapsed [0:09:21.999349]  batch: 1  d_loss: -248.175293  g_loss: 497.070618  kl_los: 82.153000\n",
            "Elapsed [0:09:28.513391]  batch: 20  d_loss: -248.751068  g_loss: 500.707703  kl_los: 82.676750\n",
            "Time taken for epoch: 9.007 secs\n",
            "\n",
            "Epoch: 65\n",
            "Elapsed [0:09:30.855594]  batch: 1  d_loss: -249.377426  g_loss: 503.383698  kl_los: 82.553421\n",
            "Elapsed [0:09:37.318190]  batch: 20  d_loss: -249.084320  g_loss: 505.045959  kl_los: 82.423332\n",
            "Time taken for epoch: 8.809 secs\n",
            "\n",
            "Epoch: 66\n",
            "Elapsed [0:09:39.698802]  batch: 1  d_loss: -248.209259  g_loss: 495.810333  kl_los: 82.672531\n",
            "Elapsed [0:09:46.247177]  batch: 20  d_loss: -249.973007  g_loss: 501.060699  kl_los: 81.969292\n",
            "Time taken for epoch: 8.926 secs\n",
            "\n",
            "Epoch: 67\n",
            "Elapsed [0:09:48.615446]  batch: 1  d_loss: -246.783005  g_loss: 500.637054  kl_los: 82.402702\n",
            "Elapsed [0:09:55.040306]  batch: 20  d_loss: -249.757675  g_loss: 500.437775  kl_los: 82.047836\n",
            "Time taken for epoch: 8.811 secs\n",
            "\n",
            "Epoch: 68\n",
            "Elapsed [0:09:57.346678]  batch: 1  d_loss: -248.321228  g_loss: 502.898376  kl_los: 82.126625\n",
            "Elapsed [0:10:03.898712]  batch: 20  d_loss: -250.330826  g_loss: 501.168854  kl_los: 82.013863\n",
            "Time taken for epoch: 8.833 secs\n",
            "\n",
            "Epoch: 69\n",
            "Elapsed [0:10:06.223756]  batch: 1  d_loss: -248.316605  g_loss: 498.135071  kl_los: 82.025055\n",
            "Elapsed [0:10:12.712662]  batch: 20  d_loss: -248.749084  g_loss: 499.093384  kl_los: 82.157173\n",
            "Time taken for epoch: 8.883 secs\n",
            "\n",
            "Epoch: 70\n",
            "Elapsed [0:10:15.247699]  batch: 1  d_loss: -247.811020  g_loss: 502.961395  kl_los: 82.171768\n",
            "Elapsed [0:10:21.867417]  batch: 20  d_loss: -248.843643  g_loss: 499.561401  kl_los: 81.871910\n",
            "Time taken for epoch: 9.092 secs\n",
            "\n",
            "Epoch: 71\n",
            "Elapsed [0:10:24.865986]  batch: 1  d_loss: -248.904480  g_loss: 498.294159  kl_los: 82.010910\n",
            "Elapsed [0:10:31.259757]  batch: 20  d_loss: -250.156540  g_loss: 502.660675  kl_los: 81.824440\n",
            "Time taken for epoch: 9.200 secs\n",
            "\n",
            "Epoch: 72\n",
            "Elapsed [0:10:33.900732]  batch: 1  d_loss: -249.364944  g_loss: 500.167542  kl_los: 82.013222\n",
            "Elapsed [0:10:40.479653]  batch: 20  d_loss: -249.422028  g_loss: 499.985229  kl_los: 81.905411\n",
            "Time taken for epoch: 9.222 secs\n",
            "\n",
            "Epoch: 73\n",
            "Elapsed [0:10:42.739471]  batch: 1  d_loss: -249.167862  g_loss: 502.760712  kl_los: 82.197464\n",
            "Elapsed [0:10:49.426743]  batch: 20  d_loss: -249.201599  g_loss: 498.010986  kl_los: 81.885765\n",
            "Time taken for epoch: 8.928 secs\n",
            "\n",
            "Epoch: 74\n",
            "Elapsed [0:10:51.759228]  batch: 1  d_loss: -249.631439  g_loss: 499.836121  kl_los: 82.039444\n",
            "Elapsed [0:10:58.308195]  batch: 20  d_loss: -249.366409  g_loss: 500.016876  kl_los: 81.811523\n",
            "Time taken for epoch: 8.903 secs\n",
            "\n",
            "Epoch: 75\n",
            "Elapsed [0:11:00.852461]  batch: 1  d_loss: -249.402969  g_loss: 501.702515  kl_los: 81.991928\n",
            "Elapsed [0:11:07.390937]  batch: 20  d_loss: -248.115540  g_loss: 503.151642  kl_los: 82.899506\n",
            "Time taken for epoch: 9.114 secs\n",
            "\n",
            "Epoch: 76\n",
            "Elapsed [0:11:09.609805]  batch: 1  d_loss: -249.064651  g_loss: 499.178345  kl_los: 81.986603\n",
            "Elapsed [0:11:16.135628]  batch: 20  d_loss: -249.352295  g_loss: 503.381378  kl_los: 81.999344\n",
            "Time taken for epoch: 8.716 secs\n",
            "\n",
            "Epoch: 77\n",
            "Elapsed [0:11:18.651316]  batch: 1  d_loss: -249.116043  g_loss: 498.257141  kl_los: 81.901581\n",
            "Elapsed [0:11:25.081285]  batch: 20  d_loss: -249.731842  g_loss: 501.862457  kl_los: 81.736923\n",
            "Time taken for epoch: 8.924 secs\n",
            "\n",
            "Epoch: 78\n",
            "Elapsed [0:11:27.564123]  batch: 1  d_loss: -248.899734  g_loss: 500.170898  kl_los: 81.838799\n",
            "Elapsed [0:11:33.996145]  batch: 20  d_loss: -248.589767  g_loss: 498.931610  kl_los: 81.718330\n",
            "Time taken for epoch: 8.913 secs\n",
            "\n",
            "Epoch: 79\n",
            "Elapsed [0:11:36.436550]  batch: 1  d_loss: -249.848724  g_loss: 503.247498  kl_los: 81.734619\n",
            "Elapsed [0:11:42.799766]  batch: 20  d_loss: -248.435486  g_loss: 497.593445  kl_los: 81.907494\n",
            "Time taken for epoch: 8.797 secs\n",
            "\n",
            "Epoch: 80\n",
            "Elapsed [0:11:45.121748]  batch: 1  d_loss: -249.328201  g_loss: 501.159058  kl_los: 81.810814\n",
            "Elapsed [0:11:51.634543]  batch: 20  d_loss: -248.450455  g_loss: 497.741547  kl_los: 81.787224\n",
            "Time taken for epoch: 8.830 secs\n",
            "\n",
            "Epoch: 81\n",
            "Elapsed [0:11:54.324821]  batch: 1  d_loss: -249.459396  g_loss: 501.903442  kl_los: 81.761002\n",
            "Elapsed [0:12:00.719627]  batch: 20  d_loss: -248.088135  g_loss: 501.886017  kl_los: 81.876854\n",
            "Time taken for epoch: 8.931 secs\n",
            "\n",
            "Epoch: 82\n",
            "Elapsed [0:12:03.265225]  batch: 1  d_loss: -249.431107  g_loss: 499.869873  kl_los: 81.768524\n",
            "Elapsed [0:12:09.649505]  batch: 20  d_loss: -249.761200  g_loss: 501.325531  kl_los: 81.714783\n",
            "Time taken for epoch: 8.897 secs\n",
            "\n",
            "Epoch: 83\n",
            "Elapsed [0:12:11.983389]  batch: 1  d_loss: -249.186462  g_loss: 502.173798  kl_los: 81.715805\n",
            "Elapsed [0:12:18.456651]  batch: 20  d_loss: -247.716705  g_loss: 497.204956  kl_los: 81.803886\n",
            "Time taken for epoch: 8.797 secs\n",
            "\n",
            "Epoch: 84\n",
            "Elapsed [0:12:20.915207]  batch: 1  d_loss: -249.105606  g_loss: 500.456970  kl_los: 81.808083\n",
            "Elapsed [0:12:27.440509]  batch: 20  d_loss: -248.449661  g_loss: 498.988281  kl_los: 82.235817\n",
            "Time taken for epoch: 8.984 secs\n",
            "\n",
            "Epoch: 85\n",
            "Elapsed [0:12:29.651460]  batch: 1  d_loss: -249.460861  g_loss: 502.390839  kl_los: 81.739693\n",
            "Elapsed [0:12:36.174812]  batch: 20  d_loss: -248.693954  g_loss: 499.298340  kl_los: 81.823357\n",
            "Time taken for epoch: 8.737 secs\n",
            "\n",
            "Epoch: 86\n",
            "Elapsed [0:12:38.509849]  batch: 1  d_loss: -249.486755  g_loss: 502.403290  kl_los: 81.707581\n",
            "Elapsed [0:12:44.963556]  batch: 20  d_loss: -248.957672  g_loss: 501.011719  kl_los: 81.739746\n",
            "Time taken for epoch: 8.785 secs\n",
            "\n",
            "Epoch: 87\n",
            "Elapsed [0:12:47.080472]  batch: 1  d_loss: -249.392197  g_loss: 500.779022  kl_los: 81.679840\n",
            "Elapsed [0:12:53.600516]  batch: 20  d_loss: -248.661789  g_loss: 493.992706  kl_los: 81.785126\n",
            "Time taken for epoch: 8.639 secs\n",
            "\n",
            "Epoch: 88\n",
            "Elapsed [0:12:55.930927]  batch: 1  d_loss: -244.736511  g_loss: 508.055847  kl_los: 81.742310\n",
            "Elapsed [0:13:02.479130]  batch: 20  d_loss: -249.017502  g_loss: 501.068329  kl_los: 81.724495\n",
            "Time taken for epoch: 8.879 secs\n",
            "\n",
            "Epoch: 89\n",
            "Elapsed [0:13:04.885567]  batch: 1  d_loss: -249.606445  g_loss: 500.268005  kl_los: 81.822113\n",
            "Elapsed [0:13:11.199045]  batch: 20  d_loss: -248.485031  g_loss: 498.693848  kl_los: 81.682281\n",
            "Time taken for epoch: 8.746 secs\n",
            "\n",
            "Epoch: 90\n",
            "Elapsed [0:13:13.207538]  batch: 1  d_loss: -248.956848  g_loss: 500.579163  kl_los: 81.723053\n",
            "Elapsed [0:13:19.695151]  batch: 20  d_loss: -249.396362  g_loss: 500.456940  kl_los: 82.105339\n",
            "Time taken for epoch: 8.500 secs\n",
            "\n",
            "Epoch: 91\n",
            "Elapsed [0:13:22.369833]  batch: 1  d_loss: -248.500534  g_loss: 503.376953  kl_los: 81.735069\n",
            "Elapsed [0:13:28.834088]  batch: 20  d_loss: -248.740433  g_loss: 497.043213  kl_los: 81.712311\n",
            "Time taken for epoch: 8.906 secs\n",
            "\n",
            "Epoch: 92\n",
            "Elapsed [0:13:30.960801]  batch: 1  d_loss: -248.115509  g_loss: 500.400391  kl_los: 81.700470\n",
            "Elapsed [0:13:37.734741]  batch: 20  d_loss: -249.337662  g_loss: 504.838562  kl_los: 81.744438\n",
            "Time taken for epoch: 8.901 secs\n",
            "\n",
            "Epoch: 93\n",
            "Elapsed [0:13:40.099466]  batch: 1  d_loss: -248.174469  g_loss: 496.517975  kl_los: 81.736328\n",
            "Elapsed [0:13:46.563118]  batch: 20  d_loss: -247.382462  g_loss: 497.965912  kl_los: 81.796509\n",
            "Time taken for epoch: 8.839 secs\n",
            "\n",
            "Epoch: 94\n",
            "Elapsed [0:13:48.853064]  batch: 1  d_loss: -248.941254  g_loss: 497.730286  kl_los: 81.690948\n",
            "Elapsed [0:13:55.413165]  batch: 20  d_loss: -248.487534  g_loss: 499.720398  kl_los: 81.670990\n",
            "Time taken for epoch: 8.840 secs\n",
            "\n",
            "Epoch: 95\n",
            "Elapsed [0:13:57.587018]  batch: 1  d_loss: -247.299713  g_loss: 505.798126  kl_los: 81.681961\n",
            "Elapsed [0:14:04.270235]  batch: 20  d_loss: -248.494202  g_loss: 506.036743  kl_los: 81.695976\n",
            "Time taken for epoch: 8.901 secs\n",
            "\n",
            "Epoch: 96\n",
            "Elapsed [0:14:06.522935]  batch: 1  d_loss: -248.262421  g_loss: 496.850098  kl_los: 81.748489\n",
            "Elapsed [0:14:13.055993]  batch: 20  d_loss: -249.497543  g_loss: 501.127197  kl_los: 81.644478\n",
            "Time taken for epoch: 8.743 secs\n",
            "\n",
            "Epoch: 97\n",
            "Elapsed [0:14:15.340651]  batch: 1  d_loss: -248.974182  g_loss: 499.087891  kl_los: 81.714729\n",
            "Elapsed [0:14:21.825622]  batch: 20  d_loss: -249.044327  g_loss: 499.958435  kl_los: 81.749969\n",
            "Time taken for epoch: 8.779 secs\n",
            "\n",
            "Epoch: 98\n",
            "Elapsed [0:14:24.142901]  batch: 1  d_loss: -249.447235  g_loss: 502.615662  kl_los: 81.713684\n",
            "Elapsed [0:14:30.578192]  batch: 20  d_loss: -248.498825  g_loss: 503.685455  kl_los: 81.663177\n",
            "Time taken for epoch: 8.754 secs\n",
            "\n",
            "Epoch: 99\n",
            "Elapsed [0:14:32.916258]  batch: 1  d_loss: -245.188965  g_loss: 491.681213  kl_los: 81.660995\n",
            "Elapsed [0:14:39.392388]  batch: 20  d_loss: -249.538696  g_loss: 501.606171  kl_los: 81.624924\n",
            "Time taken for epoch: 8.802 secs\n",
            "\n",
            "Epoch: 100\n",
            "Elapsed [0:14:41.753265]  batch: 1  d_loss: -248.881638  g_loss: 502.402618  kl_los: 81.655540\n",
            "Elapsed [0:14:48.222085]  batch: 20  d_loss: -247.719849  g_loss: 497.657410  kl_los: 81.681541\n",
            "Time taken for epoch: 8.836 secs\n",
            "\n",
            "Epoch: 101\n",
            "Elapsed [0:14:50.929189]  batch: 1  d_loss: -249.348160  g_loss: 501.010071  kl_los: 81.644089\n",
            "Elapsed [0:14:57.410446]  batch: 20  d_loss: -248.541626  g_loss: 500.717316  kl_los: 81.696205\n",
            "Time taken for epoch: 8.986 secs\n",
            "\n",
            "Epoch: 102\n",
            "Elapsed [0:14:59.869303]  batch: 1  d_loss: -248.360016  g_loss: 496.891113  kl_los: 81.660049\n",
            "Elapsed [0:15:06.399111]  batch: 20  d_loss: -248.533401  g_loss: 502.206390  kl_los: 81.666061\n",
            "Time taken for epoch: 8.986 secs\n",
            "\n",
            "Epoch: 103\n",
            "Elapsed [0:15:08.675555]  batch: 1  d_loss: -249.336182  g_loss: 499.745605  kl_los: 81.660484\n",
            "Elapsed [0:15:15.163824]  batch: 20  d_loss: -248.276779  g_loss: 499.840515  kl_los: 81.677803\n",
            "Time taken for epoch: 8.765 secs\n",
            "\n",
            "Epoch: 104\n",
            "Elapsed [0:15:17.194108]  batch: 1  d_loss: -248.581238  g_loss: 500.685822  kl_los: 81.662476\n",
            "Elapsed [0:15:23.811548]  batch: 20  d_loss: -248.288528  g_loss: 498.552368  kl_los: 81.651924\n",
            "Time taken for epoch: 8.634 secs\n",
            "\n",
            "Epoch: 105\n",
            "Elapsed [0:15:26.209833]  batch: 1  d_loss: -247.912872  g_loss: 500.514221  kl_los: 81.657478\n",
            "Elapsed [0:15:32.715255]  batch: 20  d_loss: -249.548798  g_loss: 502.758179  kl_los: 81.702324\n",
            "Time taken for epoch: 8.907 secs\n",
            "\n",
            "Epoch: 106\n",
            "Elapsed [0:15:34.992796]  batch: 1  d_loss: -248.752472  g_loss: 496.911194  kl_los: 81.644508\n",
            "Elapsed [0:15:41.513837]  batch: 20  d_loss: -247.186432  g_loss: 505.542236  kl_los: 81.675980\n",
            "Time taken for epoch: 8.843 secs\n",
            "\n",
            "Epoch: 107\n",
            "Elapsed [0:15:43.855745]  batch: 1  d_loss: -248.491089  g_loss: 498.136810  kl_los: 81.648224\n",
            "Elapsed [0:15:50.323801]  batch: 20  d_loss: -247.793076  g_loss: 501.940033  kl_los: 81.654266\n",
            "Time taken for epoch: 8.802 secs\n",
            "\n",
            "Epoch: 108\n",
            "Elapsed [0:15:52.680803]  batch: 1  d_loss: -249.081299  g_loss: 498.724731  kl_los: 81.662300\n",
            "Elapsed [0:15:59.211706]  batch: 20  d_loss: -248.395370  g_loss: 497.607117  kl_los: 81.628288\n",
            "Time taken for epoch: 8.857 secs\n",
            "\n",
            "Epoch: 109\n",
            "Elapsed [0:16:01.469609]  batch: 1  d_loss: -248.367935  g_loss: 501.266479  kl_los: 81.669273\n",
            "Elapsed [0:16:07.999620]  batch: 20  d_loss: -248.499664  g_loss: 496.533905  kl_los: 81.665283\n",
            "Time taken for epoch: 8.808 secs\n",
            "\n",
            "Epoch: 110\n",
            "Elapsed [0:16:10.395609]  batch: 1  d_loss: -247.507217  g_loss: 498.860168  kl_los: 81.672440\n",
            "Elapsed [0:16:17.056801]  batch: 20  d_loss: -249.762314  g_loss: 501.570679  kl_los: 81.691696\n",
            "Time taken for epoch: 9.070 secs\n",
            "\n",
            "Epoch: 111\n",
            "Elapsed [0:16:19.673516]  batch: 1  d_loss: -246.651825  g_loss: 497.499176  kl_los: 81.694481\n",
            "Elapsed [0:16:26.130212]  batch: 20  d_loss: -247.941376  g_loss: 500.572540  kl_los: 81.665283\n",
            "Time taken for epoch: 8.867 secs\n",
            "\n",
            "Epoch: 112\n",
            "Elapsed [0:16:28.487468]  batch: 1  d_loss: -247.538300  g_loss: 497.167786  kl_los: 81.664711\n",
            "Elapsed [0:16:34.948326]  batch: 20  d_loss: -248.363861  g_loss: 498.488281  kl_los: 81.673378\n",
            "Time taken for epoch: 8.804 secs\n",
            "\n",
            "Epoch: 113\n",
            "Elapsed [0:16:37.371570]  batch: 1  d_loss: -248.177109  g_loss: 498.440552  kl_los: 81.672501\n",
            "Elapsed [0:16:43.894048]  batch: 20  d_loss: -248.518219  g_loss: 500.195831  kl_los: 81.649063\n",
            "Time taken for epoch: 8.949 secs\n",
            "\n",
            "Epoch: 114\n",
            "Elapsed [0:16:46.326711]  batch: 1  d_loss: -248.328827  g_loss: 499.236084  kl_los: 81.698288\n",
            "Elapsed [0:16:52.720832]  batch: 20  d_loss: -248.498642  g_loss: 497.569122  kl_los: 81.667763\n",
            "Time taken for epoch: 8.818 secs\n",
            "\n",
            "Epoch: 115\n",
            "Elapsed [0:16:55.153370]  batch: 1  d_loss: -247.892685  g_loss: 500.426636  kl_los: 81.680008\n",
            "Elapsed [0:17:01.605177]  batch: 20  d_loss: -247.904236  g_loss: 497.826050  kl_los: 81.684761\n",
            "Time taken for epoch: 8.883 secs\n",
            "\n",
            "Epoch: 116\n",
            "Elapsed [0:17:03.988428]  batch: 1  d_loss: -248.064560  g_loss: 500.028320  kl_los: 81.678192\n",
            "Elapsed [0:17:10.503077]  batch: 20  d_loss: -248.825638  g_loss: 501.785919  kl_los: 81.652512\n",
            "Time taken for epoch: 8.920 secs\n",
            "\n",
            "Epoch: 117\n",
            "Elapsed [0:17:12.851576]  batch: 1  d_loss: -248.042526  g_loss: 495.561462  kl_los: 81.671043\n",
            "Elapsed [0:17:19.193788]  batch: 20  d_loss: -248.215210  g_loss: 497.782471  kl_los: 81.654579\n",
            "Time taken for epoch: 8.684 secs\n",
            "\n",
            "Epoch: 118\n",
            "Elapsed [0:17:21.602636]  batch: 1  d_loss: -248.119843  g_loss: 500.842529  kl_los: 81.658508\n",
            "Elapsed [0:17:28.040562]  batch: 20  d_loss: -248.637268  g_loss: 498.336700  kl_los: 81.629814\n",
            "Time taken for epoch: 8.824 secs\n",
            "\n",
            "Epoch: 119\n",
            "Elapsed [0:17:30.174644]  batch: 1  d_loss: -248.678452  g_loss: 501.843170  kl_los: 81.648621\n",
            "Elapsed [0:17:36.778922]  batch: 20  d_loss: -249.160263  g_loss: 496.218811  kl_los: 81.674927\n",
            "Time taken for epoch: 8.758 secs\n",
            "\n",
            "Epoch: 120\n",
            "Elapsed [0:17:39.251403]  batch: 1  d_loss: -245.980286  g_loss: 504.129333  kl_los: 81.717720\n",
            "Elapsed [0:17:45.602868]  batch: 20  d_loss: -247.468552  g_loss: 494.858978  kl_los: 81.629440\n",
            "Time taken for epoch: 8.843 secs\n",
            "\n",
            "\n",
            "Currently working on Depth:  1\n",
            "Current resolution: 8 x 8\n",
            "\n",
            "Epoch: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2351: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/upsampling.py:129: UserWarning: nn.Upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.{} is deprecated. Use nn.functional.interpolate instead.\".format(self.name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Elapsed [0:17:49.221668]  batch: 1  d_loss: -243.473846  g_loss: 502.325562  kl_los: 81.636200\n",
            "Elapsed [0:17:58.387445]  batch: 20  d_loss: -244.364105  g_loss: 500.658691  kl_los: 81.616898\n",
            "Time taken for epoch: 12.474 secs\n",
            "\n",
            "Epoch: 2\n",
            "Elapsed [0:18:00.840828]  batch: 1  d_loss: -244.993652  g_loss: 502.031311  kl_los: 81.650551\n",
            "Elapsed [0:18:09.515210]  batch: 20  d_loss: -242.658997  g_loss: 499.468994  kl_los: 81.730125\n",
            "Time taken for epoch: 11.063 secs\n",
            "\n",
            "Epoch: 3\n",
            "Elapsed [0:18:11.988715]  batch: 1  d_loss: -244.560303  g_loss: 502.381409  kl_los: 81.657227\n",
            "Elapsed [0:18:20.826132]  batch: 20  d_loss: -242.783264  g_loss: 503.613647  kl_los: 81.715378\n",
            "Time taken for epoch: 11.312 secs\n",
            "\n",
            "Epoch: 4\n",
            "Elapsed [0:18:23.336486]  batch: 1  d_loss: -245.472534  g_loss: 501.761993  kl_los: 81.727219\n",
            "Elapsed [0:18:32.077005]  batch: 20  d_loss: -243.209564  g_loss: 498.340515  kl_los: 81.780739\n",
            "Time taken for epoch: 11.251 secs\n",
            "\n",
            "Epoch: 5\n",
            "Elapsed [0:18:34.555416]  batch: 1  d_loss: -244.441162  g_loss: 506.424011  kl_los: 81.763359\n",
            "Elapsed [0:18:43.333688]  batch: 20  d_loss: -245.860138  g_loss: 501.763489  kl_los: 81.805946\n",
            "Time taken for epoch: 11.263 secs\n",
            "\n",
            "Epoch: 6\n",
            "Elapsed [0:18:46.105590]  batch: 1  d_loss: -245.423615  g_loss: 499.487915  kl_los: 81.829765\n",
            "Elapsed [0:18:54.675770]  batch: 20  d_loss: -245.914154  g_loss: 506.392395  kl_los: 81.799919\n",
            "Time taken for epoch: 11.337 secs\n",
            "\n",
            "Epoch: 7\n",
            "Elapsed [0:18:57.210655]  batch: 1  d_loss: -248.307663  g_loss: 503.327240  kl_los: 81.809402\n",
            "Elapsed [0:19:05.894094]  batch: 20  d_loss: -252.082443  g_loss: 509.767761  kl_los: 81.825508\n",
            "Time taken for epoch: 11.223 secs\n",
            "\n",
            "Epoch: 8\n",
            "Elapsed [0:19:08.484809]  batch: 1  d_loss: -246.488556  g_loss: 507.251831  kl_los: 81.902969\n",
            "Elapsed [0:19:17.358535]  batch: 20  d_loss: -249.306061  g_loss: 504.160645  kl_los: 81.837822\n",
            "Time taken for epoch: 11.462 secs\n",
            "\n",
            "Epoch: 9\n",
            "Elapsed [0:19:19.847937]  batch: 1  d_loss: -247.255676  g_loss: 500.310730  kl_los: 81.826721\n",
            "Elapsed [0:19:28.601676]  batch: 20  d_loss: -247.116226  g_loss: 500.194763  kl_los: 81.751282\n",
            "Time taken for epoch: 11.255 secs\n",
            "\n",
            "Epoch: 10\n",
            "Elapsed [0:19:31.030419]  batch: 1  d_loss: -245.987228  g_loss: 502.926758  kl_los: 81.778366\n",
            "Elapsed [0:19:39.849762]  batch: 20  d_loss: -249.634903  g_loss: 502.375885  kl_los: 81.729927\n",
            "Time taken for epoch: 11.247 secs\n",
            "\n",
            "Epoch: 11\n",
            "Elapsed [0:19:42.465641]  batch: 1  d_loss: -249.109131  g_loss: 503.885376  kl_los: 81.733994\n",
            "Elapsed [0:19:51.328829]  batch: 20  d_loss: -251.756836  g_loss: 509.396729  kl_los: 81.721169\n",
            "Time taken for epoch: 11.356 secs\n",
            "\n",
            "Epoch: 12\n",
            "Elapsed [0:19:53.650006]  batch: 1  d_loss: -248.266815  g_loss: 502.674316  kl_los: 81.740829\n",
            "Elapsed [0:20:02.452860]  batch: 20  d_loss: -251.055450  g_loss: 500.793335  kl_los: 81.729919\n",
            "Time taken for epoch: 11.081 secs\n",
            "\n",
            "Epoch: 13\n",
            "Elapsed [0:20:05.052796]  batch: 1  d_loss: -244.604462  g_loss: 506.040161  kl_los: 81.751160\n",
            "Elapsed [0:20:13.819908]  batch: 20  d_loss: -249.456863  g_loss: 503.485168  kl_los: 81.720818\n",
            "Time taken for epoch: 11.339 secs\n",
            "\n",
            "Epoch: 14\n",
            "Elapsed [0:20:16.410014]  batch: 1  d_loss: -248.876877  g_loss: 501.257568  kl_los: 81.741745\n",
            "Elapsed [0:20:25.154422]  batch: 20  d_loss: -251.870010  g_loss: 501.667480  kl_los: 81.756088\n",
            "Time taken for epoch: 11.344 secs\n",
            "\n",
            "Epoch: 15\n",
            "Elapsed [0:20:27.682506]  batch: 1  d_loss: -247.568192  g_loss: 509.890961  kl_los: 81.734879\n",
            "Elapsed [0:20:36.527786]  batch: 20  d_loss: -248.636337  g_loss: 502.639740  kl_los: 81.734344\n",
            "Time taken for epoch: 11.360 secs\n",
            "\n",
            "Epoch: 16\n",
            "Elapsed [0:20:38.848488]  batch: 1  d_loss: -253.332031  g_loss: 507.349121  kl_los: 81.740128\n",
            "Elapsed [0:20:47.697383]  batch: 20  d_loss: -250.654755  g_loss: 504.361816  kl_los: 81.706505\n",
            "Time taken for epoch: 11.168 secs\n",
            "\n",
            "Epoch: 17\n",
            "Elapsed [0:20:50.087555]  batch: 1  d_loss: -251.724411  g_loss: 504.722534  kl_los: 81.717239\n",
            "Elapsed [0:20:59.054651]  batch: 20  d_loss: -246.890900  g_loss: 501.521362  kl_los: 81.704208\n",
            "Time taken for epoch: 11.387 secs\n",
            "\n",
            "Epoch: 18\n",
            "Elapsed [0:21:01.553880]  batch: 1  d_loss: -252.117966  g_loss: 505.562988  kl_los: 81.714050\n",
            "Elapsed [0:21:10.269196]  batch: 20  d_loss: -246.495239  g_loss: 494.825439  kl_los: 81.666229\n",
            "Time taken for epoch: 11.189 secs\n",
            "\n",
            "Epoch: 19\n",
            "Elapsed [0:21:12.773620]  batch: 1  d_loss: -246.132889  g_loss: 498.470520  kl_los: 81.690315\n",
            "Elapsed [0:21:21.430486]  batch: 20  d_loss: -250.428635  g_loss: 503.383789  kl_los: 81.713356\n",
            "Time taken for epoch: 11.161 secs\n",
            "\n",
            "Epoch: 20\n",
            "Elapsed [0:21:24.014720]  batch: 1  d_loss: -250.890732  g_loss: 505.373291  kl_los: 81.772049\n",
            "Elapsed [0:21:32.769836]  batch: 20  d_loss: -252.769775  g_loss: 510.645203  kl_los: 81.663940\n",
            "Time taken for epoch: 11.337 secs\n",
            "\n",
            "Epoch: 21\n",
            "Elapsed [0:21:35.757056]  batch: 1  d_loss: -246.608917  g_loss: 494.530334  kl_los: 81.683289\n",
            "Elapsed [0:21:44.424151]  batch: 20  d_loss: -247.165375  g_loss: 506.994720  kl_los: 81.685570\n",
            "Time taken for epoch: 11.455 secs\n",
            "\n",
            "Epoch: 22\n",
            "Elapsed [0:21:47.127586]  batch: 1  d_loss: -249.942856  g_loss: 505.963745  kl_los: 81.676392\n",
            "Elapsed [0:21:55.829210]  batch: 20  d_loss: -246.362305  g_loss: 499.993927  kl_los: 81.654510\n",
            "Time taken for epoch: 11.410 secs\n",
            "\n",
            "Epoch: 23\n",
            "Elapsed [0:21:58.456183]  batch: 1  d_loss: -249.464035  g_loss: 510.617188  kl_los: 81.694809\n",
            "Elapsed [0:22:07.086393]  batch: 20  d_loss: -247.493378  g_loss: 498.544983  kl_los: 81.686943\n",
            "Time taken for epoch: 11.263 secs\n",
            "\n",
            "Epoch: 24\n",
            "Elapsed [0:22:09.709169]  batch: 1  d_loss: -248.305542  g_loss: 504.627075  kl_los: 81.674881\n",
            "Elapsed [0:22:18.388535]  batch: 20  d_loss: -251.233292  g_loss: 512.380066  kl_los: 81.631561\n",
            "Time taken for epoch: 11.300 secs\n",
            "\n",
            "Epoch: 25\n",
            "Elapsed [0:22:20.885628]  batch: 1  d_loss: -249.622330  g_loss: 499.000427  kl_los: 81.677292\n",
            "Elapsed [0:22:29.631197]  batch: 20  d_loss: -252.851837  g_loss: 510.380859  kl_los: 81.699844\n",
            "Time taken for epoch: 11.287 secs\n",
            "\n",
            "Epoch: 26\n",
            "Elapsed [0:22:32.453942]  batch: 1  d_loss: -251.321228  g_loss: 511.036560  kl_los: 81.648697\n",
            "Elapsed [0:22:41.281784]  batch: 20  d_loss: -248.613083  g_loss: 509.826660  kl_los: 81.622635\n",
            "Time taken for epoch: 11.606 secs\n",
            "\n",
            "Epoch: 27\n",
            "Elapsed [0:22:43.738932]  batch: 1  d_loss: -250.708023  g_loss: 509.704895  kl_los: 81.627594\n",
            "Elapsed [0:22:52.577820]  batch: 20  d_loss: -253.407928  g_loss: 508.246063  kl_los: 81.639694\n",
            "Time taken for epoch: 11.297 secs\n",
            "\n",
            "Epoch: 28\n",
            "Elapsed [0:22:55.138709]  batch: 1  d_loss: -245.432953  g_loss: 506.901093  kl_los: 81.658081\n",
            "Elapsed [0:23:03.865273]  batch: 20  d_loss: -247.045654  g_loss: 497.907928  kl_los: 81.656738\n",
            "Time taken for epoch: 11.287 secs\n",
            "\n",
            "Epoch: 29\n",
            "Elapsed [0:23:06.279001]  batch: 1  d_loss: -247.719803  g_loss: 507.963928  kl_los: 81.673683\n",
            "Elapsed [0:23:15.109100]  batch: 20  d_loss: -252.059448  g_loss: 501.904663  kl_los: 81.640640\n",
            "Time taken for epoch: 11.244 secs\n",
            "\n",
            "Epoch: 30\n",
            "Elapsed [0:23:17.729805]  batch: 1  d_loss: -252.661072  g_loss: 505.959961  kl_los: 81.642708\n",
            "Elapsed [0:23:26.422559]  batch: 20  d_loss: -251.575546  g_loss: 504.542572  kl_los: 81.656555\n",
            "Time taken for epoch: 11.309 secs\n",
            "\n",
            "Epoch: 31\n",
            "Elapsed [0:23:29.102254]  batch: 1  d_loss: -251.798462  g_loss: 510.772919  kl_los: 81.641251\n",
            "Elapsed [0:23:37.946870]  batch: 20  d_loss: -250.485840  g_loss: 502.216522  kl_los: 81.633720\n",
            "Time taken for epoch: 11.340 secs\n",
            "\n",
            "Epoch: 32\n",
            "Elapsed [0:23:40.583673]  batch: 1  d_loss: -252.021301  g_loss: 511.733643  kl_los: 81.627441\n",
            "Elapsed [0:23:49.411227]  batch: 20  d_loss: -250.843323  g_loss: 511.005402  kl_los: 81.617668\n",
            "Time taken for epoch: 11.462 secs\n",
            "\n",
            "Epoch: 33\n",
            "Elapsed [0:23:51.877544]  batch: 1  d_loss: -252.490814  g_loss: 508.956909  kl_los: 81.619804\n",
            "Elapsed [0:24:00.751895]  batch: 20  d_loss: -251.379410  g_loss: 500.660767  kl_los: 81.755188\n",
            "Time taken for epoch: 11.343 secs\n",
            "\n",
            "Epoch: 34\n",
            "Elapsed [0:24:03.174896]  batch: 1  d_loss: -248.955154  g_loss: 506.308044  kl_los: 81.668030\n",
            "Elapsed [0:24:11.916997]  batch: 20  d_loss: -251.839371  g_loss: 507.517670  kl_los: 81.638519\n",
            "Time taken for epoch: 11.169 secs\n",
            "\n",
            "Epoch: 35\n",
            "Elapsed [0:24:14.535233]  batch: 1  d_loss: -250.019028  g_loss: 499.691010  kl_los: 81.658615\n",
            "Elapsed [0:24:23.210821]  batch: 20  d_loss: -249.040237  g_loss: 510.812592  kl_los: 81.608704\n",
            "Time taken for epoch: 11.288 secs\n",
            "\n",
            "Epoch: 36\n",
            "Elapsed [0:24:25.861011]  batch: 1  d_loss: -250.602798  g_loss: 515.650024  kl_los: 81.623184\n",
            "Elapsed [0:24:34.611518]  batch: 20  d_loss: -251.657440  g_loss: 510.880035  kl_los: 81.680069\n",
            "Time taken for epoch: 11.400 secs\n",
            "\n",
            "Epoch: 37\n",
            "Elapsed [0:24:37.267838]  batch: 1  d_loss: -247.153275  g_loss: 495.850891  kl_los: 81.705376\n",
            "Elapsed [0:24:46.124067]  batch: 20  d_loss: -253.594711  g_loss: 506.791626  kl_los: 81.685860\n",
            "Time taken for epoch: 11.513 secs\n",
            "\n",
            "Epoch: 38\n",
            "Elapsed [0:24:48.566919]  batch: 1  d_loss: -247.825287  g_loss: 512.954529  kl_los: 81.691544\n",
            "Elapsed [0:24:57.442478]  batch: 20  d_loss: -254.716675  g_loss: 509.629395  kl_los: 81.657127\n",
            "Time taken for epoch: 11.315 secs\n",
            "\n",
            "Epoch: 39\n",
            "Elapsed [0:25:00.024126]  batch: 1  d_loss: -249.268372  g_loss: 505.662994  kl_los: 81.662445\n",
            "Elapsed [0:25:08.865754]  batch: 20  d_loss: -248.356064  g_loss: 512.726501  kl_los: 81.639465\n",
            "Time taken for epoch: 11.421 secs\n",
            "\n",
            "Epoch: 40\n",
            "Elapsed [0:25:11.307524]  batch: 1  d_loss: -246.614807  g_loss: 501.453186  kl_los: 81.693008\n",
            "Elapsed [0:25:20.212582]  batch: 20  d_loss: -252.405807  g_loss: 504.472931  kl_los: 81.638176\n",
            "Time taken for epoch: 11.348 secs\n",
            "\n",
            "Epoch: 41\n",
            "Elapsed [0:25:23.027997]  batch: 1  d_loss: -254.887329  g_loss: 509.925140  kl_los: 81.628181\n",
            "Elapsed [0:25:31.844585]  batch: 20  d_loss: -244.834076  g_loss: 508.585938  kl_los: 81.684883\n",
            "Time taken for epoch: 11.450 secs\n",
            "\n",
            "Epoch: 42\n",
            "Elapsed [0:25:34.347116]  batch: 1  d_loss: -253.082047  g_loss: 509.056580  kl_los: 81.695007\n",
            "Elapsed [0:25:43.168717]  batch: 20  d_loss: -251.008698  g_loss: 502.610718  kl_los: 81.723160\n",
            "Time taken for epoch: 11.318 secs\n",
            "\n",
            "Epoch: 43\n",
            "Elapsed [0:25:45.840789]  batch: 1  d_loss: -250.050705  g_loss: 506.167694  kl_los: 81.739632\n",
            "Elapsed [0:25:54.495361]  batch: 20  d_loss: -241.964294  g_loss: 495.567078  kl_los: 81.695396\n",
            "Time taken for epoch: 11.318 secs\n",
            "\n",
            "Epoch: 44\n",
            "Elapsed [0:25:56.888526]  batch: 1  d_loss: -249.176636  g_loss: 528.003052  kl_los: 81.695518\n",
            "Elapsed [0:26:05.781432]  batch: 20  d_loss: -251.623535  g_loss: 501.917328  kl_los: 81.680832\n",
            "Time taken for epoch: 11.289 secs\n",
            "\n",
            "Epoch: 45\n",
            "Elapsed [0:26:08.263541]  batch: 1  d_loss: -253.382248  g_loss: 512.231201  kl_los: 81.678925\n",
            "Elapsed [0:26:16.970774]  batch: 20  d_loss: -252.430328  g_loss: 507.308197  kl_los: 81.669968\n",
            "Time taken for epoch: 11.242 secs\n",
            "\n",
            "Epoch: 46\n",
            "Elapsed [0:26:19.649257]  batch: 1  d_loss: -253.499298  g_loss: 512.822998  kl_los: 81.685249\n",
            "Elapsed [0:26:28.414237]  batch: 20  d_loss: -254.897568  g_loss: 514.931763  kl_los: 81.638351\n",
            "Time taken for epoch: 11.388 secs\n",
            "\n",
            "Epoch: 47\n",
            "Elapsed [0:26:30.935064]  batch: 1  d_loss: -246.795959  g_loss: 499.027252  kl_los: 81.647186\n",
            "Elapsed [0:26:39.765251]  batch: 20  d_loss: -252.013016  g_loss: 503.307678  kl_los: 81.697090\n",
            "Time taken for epoch: 11.356 secs\n",
            "\n",
            "Epoch: 48\n",
            "Elapsed [0:26:42.403117]  batch: 1  d_loss: -255.018188  g_loss: 508.654022  kl_los: 81.677391\n",
            "Elapsed [0:26:51.195496]  batch: 20  d_loss: -254.898697  g_loss: 502.367554  kl_los: 81.717705\n",
            "Time taken for epoch: 11.458 secs\n",
            "\n",
            "Epoch: 49\n",
            "Elapsed [0:26:53.489367]  batch: 1  d_loss: -249.580383  g_loss: 516.930908  kl_los: 81.702988\n",
            "Elapsed [0:27:02.314557]  batch: 20  d_loss: -254.217361  g_loss: 506.896851  kl_los: 81.779045\n",
            "Time taken for epoch: 11.086 secs\n",
            "\n",
            "Epoch: 50\n",
            "Elapsed [0:27:04.920851]  batch: 1  d_loss: -253.884781  g_loss: 515.114624  kl_los: 81.746185\n",
            "Elapsed [0:27:13.738516]  batch: 20  d_loss: -243.043121  g_loss: 507.985931  kl_los: 81.842453\n",
            "Time taken for epoch: 11.427 secs\n",
            "\n",
            "Epoch: 51\n",
            "Elapsed [0:27:16.539525]  batch: 1  d_loss: -254.097946  g_loss: 517.627319  kl_los: 81.851433\n",
            "Elapsed [0:27:25.287305]  batch: 20  d_loss: -253.873993  g_loss: 508.106140  kl_los: 81.905136\n",
            "Time taken for epoch: 11.345 secs\n",
            "\n",
            "Epoch: 52\n",
            "Elapsed [0:27:27.493646]  batch: 1  d_loss: -254.299149  g_loss: 509.446838  kl_los: 81.863678\n",
            "Elapsed [0:27:36.319027]  batch: 20  d_loss: -254.060577  g_loss: 517.320251  kl_los: 81.746880\n",
            "Time taken for epoch: 11.037 secs\n",
            "\n",
            "Epoch: 53\n",
            "Elapsed [0:27:39.139365]  batch: 1  d_loss: -253.860291  g_loss: 511.137024  kl_los: 81.779213\n",
            "Elapsed [0:27:47.872477]  batch: 20  d_loss: -252.914948  g_loss: 526.024719  kl_los: 81.781898\n",
            "Time taken for epoch: 11.553 secs\n",
            "\n",
            "Epoch: 54\n",
            "Elapsed [0:27:50.401940]  batch: 1  d_loss: -243.578552  g_loss: 490.630981  kl_los: 81.785736\n",
            "Elapsed [0:27:59.303503]  batch: 20  d_loss: -254.761810  g_loss: 515.614563  kl_los: 81.813187\n",
            "Time taken for epoch: 11.429 secs\n",
            "\n",
            "Epoch: 55\n",
            "Elapsed [0:28:01.496787]  batch: 1  d_loss: -258.101501  g_loss: 523.550537  kl_los: 81.838257\n",
            "Elapsed [0:28:10.250008]  batch: 20  d_loss: -251.813080  g_loss: 504.931183  kl_los: 82.001289\n",
            "Time taken for epoch: 10.949 secs\n",
            "\n",
            "Epoch: 56\n",
            "Elapsed [0:28:12.662178]  batch: 1  d_loss: -253.163010  g_loss: 509.733765  kl_los: 81.970886\n",
            "Elapsed [0:28:21.575682]  batch: 20  d_loss: -254.129166  g_loss: 510.006104  kl_los: 81.751656\n",
            "Time taken for epoch: 11.322 secs\n",
            "\n",
            "Epoch: 57\n",
            "Elapsed [0:28:24.109708]  batch: 1  d_loss: -254.019226  g_loss: 505.963562  kl_los: 81.802193\n",
            "Elapsed [0:28:33.020088]  batch: 20  d_loss: -250.852325  g_loss: 499.346832  kl_los: 81.774117\n",
            "Time taken for epoch: 11.446 secs\n",
            "\n",
            "Epoch: 58\n",
            "Elapsed [0:28:35.642850]  batch: 1  d_loss: -249.375290  g_loss: 521.870483  kl_los: 81.819443\n",
            "Elapsed [0:28:44.253032]  batch: 20  d_loss: -253.570496  g_loss: 511.035400  kl_los: 81.823112\n",
            "Time taken for epoch: 11.231 secs\n",
            "\n",
            "Epoch: 59\n",
            "Elapsed [0:28:46.848527]  batch: 1  d_loss: -255.715469  g_loss: 520.646362  kl_los: 81.825951\n",
            "Elapsed [0:28:55.708634]  batch: 20  d_loss: -253.615646  g_loss: 505.742249  kl_los: 81.823189\n",
            "Time taken for epoch: 11.462 secs\n",
            "\n",
            "Epoch: 60\n",
            "Elapsed [0:28:58.215632]  batch: 1  d_loss: -252.704407  g_loss: 509.839905  kl_los: 81.843040\n",
            "Elapsed [0:29:07.045925]  batch: 20  d_loss: -255.118484  g_loss: 507.284424  kl_los: 81.816872\n",
            "Time taken for epoch: 11.332 secs\n",
            "\n",
            "Epoch: 61\n",
            "Elapsed [0:29:09.749843]  batch: 1  d_loss: -254.989532  g_loss: 514.545776  kl_los: 81.836182\n",
            "Elapsed [0:29:18.573592]  batch: 20  d_loss: -257.312927  g_loss: 514.384949  kl_los: 81.898186\n",
            "Time taken for epoch: 11.330 secs\n",
            "\n",
            "Epoch: 62\n",
            "Elapsed [0:29:21.141833]  batch: 1  d_loss: -256.626556  g_loss: 525.791504  kl_los: 81.941406\n",
            "Elapsed [0:29:30.004324]  batch: 20  d_loss: -254.915710  g_loss: 513.508545  kl_los: 81.824921\n",
            "Time taken for epoch: 11.431 secs\n",
            "\n",
            "Epoch: 63\n",
            "Elapsed [0:29:32.299753]  batch: 1  d_loss: -257.930725  g_loss: 511.548492  kl_los: 81.811531\n",
            "Elapsed [0:29:41.138196]  batch: 20  d_loss: -256.506409  g_loss: 516.668579  kl_los: 81.957024\n",
            "Time taken for epoch: 11.137 secs\n",
            "\n",
            "Epoch: 64\n",
            "Elapsed [0:29:43.658989]  batch: 1  d_loss: -247.124542  g_loss: 501.189270  kl_los: 81.841553\n",
            "Elapsed [0:29:52.517526]  batch: 20  d_loss: -255.645737  g_loss: 515.744873  kl_los: 81.790886\n",
            "Time taken for epoch: 11.374 secs\n",
            "\n",
            "Epoch: 65\n",
            "Elapsed [0:29:55.040140]  batch: 1  d_loss: -255.614090  g_loss: 516.565674  kl_los: 81.834785\n",
            "Elapsed [0:30:03.757573]  batch: 20  d_loss: -253.894974  g_loss: 510.325897  kl_los: 81.837105\n",
            "Time taken for epoch: 11.240 secs\n",
            "\n",
            "Epoch: 66\n",
            "Elapsed [0:30:06.356012]  batch: 1  d_loss: -254.130173  g_loss: 526.402161  kl_los: 81.843796\n",
            "Elapsed [0:30:15.093740]  batch: 20  d_loss: -257.584717  g_loss: 524.150757  kl_los: 81.906937\n",
            "Time taken for epoch: 11.353 secs\n",
            "\n",
            "Epoch: 67\n",
            "Elapsed [0:30:17.636856]  batch: 1  d_loss: -251.890045  g_loss: 501.487183  kl_los: 81.975235\n",
            "Elapsed [0:30:26.416627]  batch: 20  d_loss: -255.105499  g_loss: 506.712891  kl_los: 81.898705\n",
            "Time taken for epoch: 11.335 secs\n",
            "\n",
            "Epoch: 68\n",
            "Elapsed [0:30:29.076419]  batch: 1  d_loss: -254.873444  g_loss: 517.361816  kl_los: 81.879456\n",
            "Elapsed [0:30:37.889632]  batch: 20  d_loss: -253.988617  g_loss: 517.301575  kl_los: 81.873550\n",
            "Time taken for epoch: 11.442 secs\n",
            "\n",
            "Epoch: 69\n",
            "Elapsed [0:30:40.467988]  batch: 1  d_loss: -253.665207  g_loss: 505.405670  kl_los: 81.853386\n",
            "Elapsed [0:30:49.284245]  batch: 20  d_loss: -252.578400  g_loss: 510.112000  kl_los: 81.874214\n",
            "Time taken for epoch: 11.403 secs\n",
            "\n",
            "Epoch: 70\n",
            "Elapsed [0:30:51.700563]  batch: 1  d_loss: -248.406174  g_loss: 505.989502  kl_los: 81.869705\n",
            "Elapsed [0:31:00.455831]  batch: 20  d_loss: -253.765594  g_loss: 506.373047  kl_los: 81.914551\n",
            "Time taken for epoch: 11.165 secs\n",
            "\n",
            "Epoch: 71\n",
            "Elapsed [0:31:03.143694]  batch: 1  d_loss: -254.162781  g_loss: 524.132202  kl_los: 81.935112\n",
            "Elapsed [0:31:11.927227]  batch: 20  d_loss: -255.938675  g_loss: 506.003632  kl_los: 81.781685\n",
            "Time taken for epoch: 11.288 secs\n",
            "\n",
            "Epoch: 72\n",
            "Elapsed [0:31:14.598121]  batch: 1  d_loss: -255.951645  g_loss: 511.919983  kl_los: 81.821159\n",
            "Elapsed [0:31:23.385687]  batch: 20  d_loss: -256.013367  g_loss: 507.560425  kl_los: 81.803177\n",
            "Time taken for epoch: 11.449 secs\n",
            "\n",
            "Epoch: 73\n",
            "Elapsed [0:31:26.025551]  batch: 1  d_loss: -252.307693  g_loss: 511.280579  kl_los: 81.818275\n",
            "Elapsed [0:31:34.772508]  batch: 20  d_loss: -256.703186  g_loss: 510.397797  kl_los: 81.815414\n",
            "Time taken for epoch: 11.386 secs\n",
            "\n",
            "Epoch: 74\n",
            "Elapsed [0:31:37.295711]  batch: 1  d_loss: -252.828217  g_loss: 511.741608  kl_los: 81.807724\n",
            "Elapsed [0:31:46.059670]  batch: 20  d_loss: -252.505280  g_loss: 501.900879  kl_los: 81.780022\n",
            "Time taken for epoch: 11.285 secs\n",
            "\n",
            "Epoch: 75\n",
            "Elapsed [0:31:48.542898]  batch: 1  d_loss: -254.380905  g_loss: 512.984009  kl_los: 81.834747\n",
            "Elapsed [0:31:57.422754]  batch: 20  d_loss: -254.504593  g_loss: 503.912964  kl_los: 81.823845\n",
            "Time taken for epoch: 11.365 secs\n",
            "\n",
            "Epoch: 76\n",
            "Elapsed [0:31:59.964735]  batch: 1  d_loss: -253.921906  g_loss: 512.330139  kl_los: 81.895737\n",
            "Elapsed [0:32:08.853144]  batch: 20  d_loss: -257.797272  g_loss: 512.376221  kl_los: 81.746613\n",
            "Time taken for epoch: 11.425 secs\n",
            "\n",
            "Epoch: 77\n",
            "Elapsed [0:32:11.584483]  batch: 1  d_loss: -255.957397  g_loss: 508.066040  kl_los: 81.750473\n",
            "Elapsed [0:32:20.333178]  batch: 20  d_loss: -249.695694  g_loss: 517.506470  kl_los: 81.815277\n",
            "Time taken for epoch: 11.524 secs\n",
            "\n",
            "Epoch: 78\n",
            "Elapsed [0:32:22.504361]  batch: 1  d_loss: -255.885315  g_loss: 520.639893  kl_los: 81.787354\n",
            "Elapsed [0:32:31.264645]  batch: 20  d_loss: -251.830948  g_loss: 518.724976  kl_los: 81.720161\n",
            "Time taken for epoch: 10.929 secs\n",
            "\n",
            "Epoch: 79\n",
            "Elapsed [0:32:33.782481]  batch: 1  d_loss: -253.542694  g_loss: 505.330658  kl_los: 81.726036\n",
            "Elapsed [0:32:42.618132]  batch: 20  d_loss: -257.758179  g_loss: 508.763733  kl_los: 81.738060\n",
            "Time taken for epoch: 11.318 secs\n",
            "\n",
            "Epoch: 80\n",
            "Elapsed [0:32:45.214585]  batch: 1  d_loss: -253.684723  g_loss: 517.169067  kl_los: 81.763321\n",
            "Elapsed [0:32:53.973225]  batch: 20  d_loss: -255.664322  g_loss: 515.475708  kl_los: 81.787262\n",
            "Time taken for epoch: 11.419 secs\n",
            "\n",
            "Epoch: 81\n",
            "Elapsed [0:32:56.638442]  batch: 1  d_loss: -256.487610  g_loss: 520.389404  kl_los: 81.745956\n",
            "Elapsed [0:33:05.401939]  batch: 20  d_loss: -251.758575  g_loss: 514.418274  kl_los: 81.726189\n",
            "Time taken for epoch: 11.140 secs\n",
            "\n",
            "Epoch: 82\n",
            "Elapsed [0:33:07.926509]  batch: 1  d_loss: -254.905502  g_loss: 511.901093  kl_los: 81.703316\n",
            "Elapsed [0:33:16.715028]  batch: 20  d_loss: -256.023499  g_loss: 509.906311  kl_los: 81.737144\n",
            "Time taken for epoch: 11.314 secs\n",
            "\n",
            "Epoch: 83\n",
            "Elapsed [0:33:19.319363]  batch: 1  d_loss: -253.702835  g_loss: 502.970612  kl_los: 81.712471\n",
            "Elapsed [0:33:28.073364]  batch: 20  d_loss: -256.691864  g_loss: 524.999329  kl_los: 81.717545\n",
            "Time taken for epoch: 11.362 secs\n",
            "\n",
            "Epoch: 84\n",
            "Elapsed [0:33:30.441307]  batch: 1  d_loss: -249.952301  g_loss: 496.818176  kl_los: 81.706100\n",
            "Elapsed [0:33:39.370498]  batch: 20  d_loss: -252.604660  g_loss: 507.037781  kl_los: 81.711662\n",
            "Time taken for epoch: 11.289 secs\n",
            "\n",
            "Epoch: 85\n",
            "Elapsed [0:33:41.933357]  batch: 1  d_loss: -253.487762  g_loss: 507.263977  kl_los: 81.714111\n",
            "Elapsed [0:33:50.712934]  batch: 20  d_loss: -253.054550  g_loss: 516.330566  kl_los: 81.715988\n",
            "Time taken for epoch: 11.347 secs\n",
            "\n",
            "Epoch: 86\n",
            "Elapsed [0:33:53.209168]  batch: 1  d_loss: -252.955017  g_loss: 504.552673  kl_los: 81.689217\n",
            "Elapsed [0:34:02.015041]  batch: 20  d_loss: -256.311951  g_loss: 521.565247  kl_los: 81.711327\n",
            "Time taken for epoch: 11.304 secs\n",
            "\n",
            "Epoch: 87\n",
            "Elapsed [0:34:04.477602]  batch: 1  d_loss: -254.473434  g_loss: 504.210785  kl_los: 81.716003\n",
            "Elapsed [0:34:13.341491]  batch: 20  d_loss: -256.833923  g_loss: 512.682373  kl_los: 81.717834\n",
            "Time taken for epoch: 11.323 secs\n",
            "\n",
            "Epoch: 88\n",
            "Elapsed [0:34:15.730755]  batch: 1  d_loss: -254.664215  g_loss: 506.029907  kl_los: 81.723015\n",
            "Elapsed [0:34:24.584254]  batch: 20  d_loss: -256.113220  g_loss: 515.938477  kl_los: 81.704681\n",
            "Time taken for epoch: 11.254 secs\n",
            "\n",
            "Epoch: 89\n",
            "Elapsed [0:34:27.078318]  batch: 1  d_loss: -254.901184  g_loss: 518.766418  kl_los: 81.700813\n",
            "Elapsed [0:34:35.840039]  batch: 20  d_loss: -255.490860  g_loss: 504.870209  kl_los: 81.676262\n",
            "Time taken for epoch: 11.240 secs\n",
            "\n",
            "Epoch: 90\n",
            "Elapsed [0:34:38.359133]  batch: 1  d_loss: -254.127213  g_loss: 507.139191  kl_los: 81.705704\n",
            "Elapsed [0:34:47.238129]  batch: 20  d_loss: -253.169006  g_loss: 522.689941  kl_los: 81.652824\n",
            "Time taken for epoch: 11.423 secs\n",
            "\n",
            "Epoch: 91\n",
            "Elapsed [0:34:50.135539]  batch: 1  d_loss: -255.403259  g_loss: 519.114624  kl_los: 81.655411\n",
            "Elapsed [0:34:58.988264]  batch: 20  d_loss: -257.619934  g_loss: 515.062622  kl_los: 81.658585\n",
            "Time taken for epoch: 11.514 secs\n",
            "\n",
            "Epoch: 92\n",
            "Elapsed [0:35:01.525218]  batch: 1  d_loss: -255.543732  g_loss: 514.845154  kl_los: 81.678581\n",
            "Elapsed [0:35:10.306730]  batch: 20  d_loss: -254.979340  g_loss: 508.226837  kl_los: 81.622551\n",
            "Time taken for epoch: 11.290 secs\n",
            "\n",
            "Epoch: 93\n",
            "Elapsed [0:35:12.662795]  batch: 1  d_loss: -253.912292  g_loss: 517.248535  kl_los: 81.641708\n",
            "Elapsed [0:35:21.477030]  batch: 20  d_loss: -255.334991  g_loss: 510.324402  kl_los: 81.632126\n",
            "Time taken for epoch: 11.167 secs\n",
            "\n",
            "Epoch: 94\n",
            "Elapsed [0:35:24.224338]  batch: 1  d_loss: -252.063461  g_loss: 515.278992  kl_los: 81.645859\n",
            "Elapsed [0:35:33.013526]  batch: 20  d_loss: -252.197662  g_loss: 505.737366  kl_los: 81.614731\n",
            "Time taken for epoch: 11.552 secs\n",
            "\n",
            "Epoch: 95\n",
            "Elapsed [0:35:35.516545]  batch: 1  d_loss: -252.149094  g_loss: 505.768372  kl_los: 81.630997\n",
            "Elapsed [0:35:44.388304]  batch: 20  d_loss: -256.062866  g_loss: 517.837463  kl_los: 81.630714\n",
            "Time taken for epoch: 11.361 secs\n",
            "\n",
            "Epoch: 96\n",
            "Elapsed [0:35:46.923757]  batch: 1  d_loss: -253.367035  g_loss: 504.752625  kl_los: 81.639862\n",
            "Elapsed [0:35:55.771146]  batch: 20  d_loss: -255.301163  g_loss: 511.730347  kl_los: 81.629799\n",
            "Time taken for epoch: 11.386 secs\n",
            "\n",
            "Epoch: 97\n",
            "Elapsed [0:35:58.283218]  batch: 1  d_loss: -255.526062  g_loss: 515.168701  kl_los: 81.646042\n",
            "Elapsed [0:36:07.034704]  batch: 20  d_loss: -256.152039  g_loss: 511.262939  kl_los: 81.603729\n",
            "Time taken for epoch: 11.260 secs\n",
            "\n",
            "Epoch: 98\n",
            "Elapsed [0:36:09.737772]  batch: 1  d_loss: -253.652008  g_loss: 503.401764  kl_los: 81.623932\n",
            "Elapsed [0:36:18.542323]  batch: 20  d_loss: -254.592941  g_loss: 510.892120  kl_los: 81.602112\n",
            "Time taken for epoch: 11.505 secs\n",
            "\n",
            "Epoch: 99\n",
            "Elapsed [0:36:21.123166]  batch: 1  d_loss: -251.558426  g_loss: 514.257690  kl_los: 81.619827\n",
            "Elapsed [0:36:29.932342]  batch: 20  d_loss: -253.541946  g_loss: 507.130646  kl_los: 81.609406\n",
            "Time taken for epoch: 11.390 secs\n",
            "\n",
            "Epoch: 100\n",
            "Elapsed [0:36:32.381842]  batch: 1  d_loss: -253.507904  g_loss: 511.225281  kl_los: 81.624222\n",
            "Elapsed [0:36:41.284614]  batch: 20  d_loss: -257.268158  g_loss: 507.736053  kl_los: 81.613800\n",
            "Time taken for epoch: 11.353 secs\n",
            "\n",
            "Epoch: 101\n",
            "Elapsed [0:36:44.126596]  batch: 1  d_loss: -251.111618  g_loss: 514.134094  kl_los: 81.628098\n",
            "Elapsed [0:36:52.796561]  batch: 20  d_loss: -250.708191  g_loss: 516.716797  kl_los: 81.650764\n",
            "Time taken for epoch: 11.344 secs\n",
            "\n",
            "Epoch: 102\n",
            "Elapsed [0:36:55.614553]  batch: 1  d_loss: -254.825638  g_loss: 508.538025  kl_los: 81.654037\n",
            "Elapsed [0:37:04.410887]  batch: 20  d_loss: -254.294922  g_loss: 504.728882  kl_los: 81.624702\n",
            "Time taken for epoch: 11.574 secs\n",
            "\n",
            "Epoch: 103\n",
            "Elapsed [0:37:06.968306]  batch: 1  d_loss: -253.364929  g_loss: 511.971741  kl_los: 81.612297\n",
            "Elapsed [0:37:15.684145]  batch: 20  d_loss: -254.940231  g_loss: 520.703857  kl_los: 81.600220\n",
            "Time taken for epoch: 11.269 secs\n",
            "\n",
            "Epoch: 104\n",
            "Elapsed [0:37:18.055165]  batch: 1  d_loss: -253.106506  g_loss: 507.731689  kl_los: 81.623596\n",
            "Elapsed [0:37:26.967978]  batch: 20  d_loss: -254.461914  g_loss: 514.197998  kl_los: 81.602715\n",
            "Time taken for epoch: 11.287 secs\n",
            "\n",
            "Epoch: 105\n",
            "Elapsed [0:37:29.639687]  batch: 1  d_loss: -253.148575  g_loss: 509.059143  kl_los: 81.602554\n",
            "Elapsed [0:37:38.491862]  batch: 20  d_loss: -253.496582  g_loss: 500.686493  kl_los: 81.632027\n",
            "Time taken for epoch: 11.521 secs\n",
            "\n",
            "Epoch: 106\n",
            "Elapsed [0:37:40.859655]  batch: 1  d_loss: -247.927490  g_loss: 517.650513  kl_los: 81.628403\n",
            "Elapsed [0:37:49.529645]  batch: 20  d_loss: -252.544647  g_loss: 504.068787  kl_los: 81.613808\n",
            "Time taken for epoch: 11.042 secs\n",
            "\n",
            "Epoch: 107\n",
            "Elapsed [0:37:52.327495]  batch: 1  d_loss: -253.078781  g_loss: 512.106689  kl_los: 81.638824\n",
            "Elapsed [0:38:00.942299]  batch: 20  d_loss: -253.089676  g_loss: 500.386719  kl_los: 81.631577\n",
            "Time taken for epoch: 11.414 secs\n",
            "\n",
            "Epoch: 108\n",
            "Elapsed [0:38:03.470126]  batch: 1  d_loss: -253.330841  g_loss: 518.685425  kl_los: 81.607162\n",
            "Elapsed [0:38:12.197326]  batch: 20  d_loss: -251.745392  g_loss: 505.712433  kl_los: 81.592018\n",
            "Time taken for epoch: 11.252 secs\n",
            "\n",
            "Epoch: 109\n",
            "Elapsed [0:38:14.758638]  batch: 1  d_loss: -254.840637  g_loss: 512.247925  kl_los: 81.591873\n",
            "Elapsed [0:38:23.554125]  batch: 20  d_loss: -254.824570  g_loss: 513.347961  kl_los: 81.595703\n",
            "Time taken for epoch: 11.356 secs\n",
            "\n",
            "Epoch: 110\n",
            "Elapsed [0:38:26.250692]  batch: 1  d_loss: -248.918182  g_loss: 504.912842  kl_los: 81.594559\n",
            "Elapsed [0:38:35.057296]  batch: 20  d_loss: -256.194458  g_loss: 512.979065  kl_los: 81.580475\n",
            "Time taken for epoch: 11.506 secs\n",
            "\n",
            "Epoch: 111\n",
            "Elapsed [0:38:37.462337]  batch: 1  d_loss: -255.569122  g_loss: 511.489838  kl_los: 81.605286\n",
            "Elapsed [0:38:46.165283]  batch: 20  d_loss: -256.178345  g_loss: 510.601471  kl_los: 81.590805\n",
            "Time taken for epoch: 10.950 secs\n",
            "\n",
            "Epoch: 112\n",
            "Elapsed [0:38:49.127328]  batch: 1  d_loss: -254.396545  g_loss: 506.936462  kl_los: 81.592224\n",
            "Elapsed [0:38:57.910271]  batch: 20  d_loss: -255.127594  g_loss: 507.830261  kl_los: 81.685051\n",
            "Time taken for epoch: 11.693 secs\n",
            "\n",
            "Epoch: 113\n",
            "Elapsed [0:39:00.342556]  batch: 1  d_loss: -250.321732  g_loss: 515.484009  kl_los: 81.629005\n",
            "Elapsed [0:39:09.293158]  batch: 20  d_loss: -254.584366  g_loss: 502.294647  kl_los: 81.639107\n",
            "Time taken for epoch: 11.384 secs\n",
            "\n",
            "Epoch: 114\n",
            "Elapsed [0:39:11.781482]  batch: 1  d_loss: -253.740585  g_loss: 515.844543  kl_los: 81.635315\n",
            "Elapsed [0:39:20.636156]  batch: 20  d_loss: -254.309799  g_loss: 508.055542  kl_los: 81.586517\n",
            "Time taken for epoch: 11.351 secs\n",
            "\n",
            "Epoch: 115\n",
            "Elapsed [0:39:23.113698]  batch: 1  d_loss: -253.875229  g_loss: 508.658875  kl_los: 81.590698\n",
            "Elapsed [0:39:31.860860]  batch: 20  d_loss: -252.937424  g_loss: 510.091217  kl_los: 81.596703\n",
            "Time taken for epoch: 11.218 secs\n",
            "\n",
            "Epoch: 116\n",
            "Elapsed [0:39:34.463240]  batch: 1  d_loss: -249.100983  g_loss: 519.712646  kl_los: 81.592178\n",
            "Elapsed [0:39:43.170712]  batch: 20  d_loss: -255.019409  g_loss: 510.674438  kl_los: 81.583191\n",
            "Time taken for epoch: 11.349 secs\n",
            "\n",
            "Epoch: 117\n",
            "Elapsed [0:39:45.660643]  batch: 1  d_loss: -252.480118  g_loss: 521.602905  kl_los: 81.584702\n",
            "Elapsed [0:39:54.584667]  batch: 20  d_loss: -256.847412  g_loss: 518.961853  kl_los: 81.598015\n",
            "Time taken for epoch: 11.374 secs\n",
            "\n",
            "Epoch: 118\n",
            "Elapsed [0:39:57.149462]  batch: 1  d_loss: -252.240112  g_loss: 500.256226  kl_los: 81.616089\n",
            "Elapsed [0:40:05.857263]  batch: 20  d_loss: -256.093445  g_loss: 521.975525  kl_los: 81.596283\n",
            "Time taken for epoch: 11.268 secs\n",
            "\n",
            "Epoch: 119\n",
            "Elapsed [0:40:08.361769]  batch: 1  d_loss: -254.031357  g_loss: 506.422241  kl_los: 81.607628\n",
            "Elapsed [0:40:17.256706]  batch: 20  d_loss: -255.211777  g_loss: 505.895569  kl_los: 81.579163\n",
            "Time taken for epoch: 11.439 secs\n",
            "\n",
            "Epoch: 120\n",
            "Elapsed [0:40:20.000925]  batch: 1  d_loss: -255.950897  g_loss: 506.808014  kl_los: 81.607208\n",
            "Elapsed [0:40:28.751754]  batch: 20  d_loss: -254.361710  g_loss: 504.693695  kl_los: 81.587738\n",
            "Time taken for epoch: 11.496 secs\n",
            "\n",
            "\n",
            "Currently working on Depth:  2\n",
            "Current resolution: 16 x 16\n",
            "\n",
            "Epoch: 1\n",
            "Elapsed [0:40:32.623231]  batch: 1  d_loss: -250.125107  g_loss: 518.726440  kl_los: 81.590096\n",
            "Elapsed [0:40:46.507064]  batch: 20  d_loss: -269.287964  g_loss: 547.258728  kl_los: 81.622154\n",
            "Time taken for epoch: 17.500 secs\n",
            "\n",
            "Epoch: 2\n",
            "Elapsed [0:40:48.683205]  batch: 1  d_loss: -258.673523  g_loss: 537.342407  kl_los: 81.622261\n",
            "Elapsed [0:41:01.912252]  batch: 20  d_loss: -285.701111  g_loss: 598.356445  kl_los: 81.697548\n",
            "Time taken for epoch: 15.414 secs\n",
            "\n",
            "Epoch: 3\n",
            "Elapsed [0:41:04.827245]  batch: 1  d_loss: -271.888153  g_loss: 560.007935  kl_los: 81.683830\n",
            "Elapsed [0:41:18.046164]  batch: 20  d_loss: -278.110901  g_loss: 576.035522  kl_los: 81.672935\n",
            "Time taken for epoch: 16.127 secs\n",
            "\n",
            "Epoch: 4\n",
            "Elapsed [0:41:20.834567]  batch: 1  d_loss: -266.927368  g_loss: 539.704224  kl_los: 81.718414\n",
            "Elapsed [0:41:34.141776]  batch: 20  d_loss: -269.416199  g_loss: 536.280518  kl_los: 81.655746\n",
            "Time taken for epoch: 16.112 secs\n",
            "\n",
            "Epoch: 5\n",
            "Elapsed [0:41:37.012696]  batch: 1  d_loss: -259.079834  g_loss: 529.227966  kl_los: 81.690155\n",
            "Elapsed [0:41:50.284473]  batch: 20  d_loss: -280.343750  g_loss: 548.973694  kl_los: 81.670250\n",
            "Time taken for epoch: 16.149 secs\n",
            "\n",
            "Epoch: 6\n",
            "Elapsed [0:41:53.030900]  batch: 1  d_loss: -254.073471  g_loss: 506.365204  kl_los: 81.677322\n",
            "Elapsed [0:42:06.251524]  batch: 20  d_loss: -267.294556  g_loss: 543.081909  kl_los: 81.743607\n",
            "Time taken for epoch: 15.957 secs\n",
            "\n",
            "Epoch: 7\n",
            "Elapsed [0:42:09.000215]  batch: 1  d_loss: -260.003601  g_loss: 516.406067  kl_los: 81.780357\n",
            "Elapsed [0:42:22.316532]  batch: 20  d_loss: -285.978363  g_loss: 573.722046  kl_los: 81.761345\n",
            "Time taken for epoch: 16.062 secs\n",
            "\n",
            "Epoch: 8\n",
            "Elapsed [0:42:25.140646]  batch: 1  d_loss: -255.465302  g_loss: 519.072388  kl_los: 81.864532\n",
            "Elapsed [0:42:38.365786]  batch: 20  d_loss: -283.626526  g_loss: 552.654236  kl_los: 81.777802\n",
            "Time taken for epoch: 16.051 secs\n",
            "\n",
            "Epoch: 9\n",
            "Elapsed [0:42:41.350273]  batch: 1  d_loss: -254.228073  g_loss: 521.777588  kl_los: 81.778717\n",
            "Elapsed [0:42:54.672598]  batch: 20  d_loss: -279.801270  g_loss: 566.715332  kl_los: 81.839546\n",
            "Time taken for epoch: 16.325 secs\n",
            "\n",
            "Epoch: 10\n",
            "Elapsed [0:42:57.530722]  batch: 1  d_loss: -257.411682  g_loss: 518.289612  kl_los: 81.858734\n",
            "Elapsed [0:43:10.781793]  batch: 20  d_loss: -276.015259  g_loss: 576.675171  kl_los: 81.789452\n",
            "Time taken for epoch: 16.082 secs\n",
            "\n",
            "Epoch: 11\n",
            "Elapsed [0:43:13.660650]  batch: 1  d_loss: -297.924377  g_loss: 595.406128  kl_los: 81.807800\n",
            "Elapsed [0:43:26.932317]  batch: 20  d_loss: -251.437180  g_loss: 520.543152  kl_los: 81.828583\n",
            "Time taken for epoch: 15.961 secs\n",
            "\n",
            "Epoch: 12\n",
            "Elapsed [0:43:29.771094]  batch: 1  d_loss: -256.168884  g_loss: 506.604614  kl_los: 81.827240\n",
            "Elapsed [0:43:43.007971]  batch: 20  d_loss: -270.213165  g_loss: 580.148560  kl_los: 81.830696\n",
            "Time taken for epoch: 16.088 secs\n",
            "\n",
            "Epoch: 13\n",
            "Elapsed [0:43:45.681201]  batch: 1  d_loss: -278.481750  g_loss: 551.182007  kl_los: 81.882019\n",
            "Elapsed [0:43:58.905092]  batch: 20  d_loss: -264.234100  g_loss: 520.905029  kl_los: 81.854744\n",
            "Time taken for epoch: 15.901 secs\n",
            "\n",
            "Epoch: 14\n",
            "Elapsed [0:44:01.627324]  batch: 1  d_loss: -272.162140  g_loss: 543.969788  kl_los: 81.862999\n",
            "Elapsed [0:44:14.801211]  batch: 20  d_loss: -277.101318  g_loss: 550.664001  kl_los: 81.862740\n",
            "Time taken for epoch: 15.898 secs\n",
            "\n",
            "Epoch: 15\n",
            "Elapsed [0:44:17.209511]  batch: 1  d_loss: -268.405701  g_loss: 539.751038  kl_los: 81.966316\n",
            "Elapsed [0:44:30.386424]  batch: 20  d_loss: -268.752808  g_loss: 517.667419  kl_los: 81.902847\n",
            "Time taken for epoch: 15.564 secs\n",
            "\n",
            "Epoch: 16\n",
            "Elapsed [0:44:33.146165]  batch: 1  d_loss: -266.066620  g_loss: 551.945435  kl_los: 81.924362\n",
            "Elapsed [0:44:46.341967]  batch: 20  d_loss: -287.904297  g_loss: 574.654053  kl_los: 81.941772\n",
            "Time taken for epoch: 15.953 secs\n",
            "\n",
            "Epoch: 17\n",
            "Elapsed [0:44:49.158071]  batch: 1  d_loss: -259.476868  g_loss: 545.772461  kl_los: 81.948959\n",
            "Elapsed [0:45:02.466830]  batch: 20  d_loss: -247.263214  g_loss: 498.112030  kl_los: 81.899551\n",
            "Time taken for epoch: 16.120 secs\n",
            "\n",
            "Epoch: 18\n",
            "Elapsed [0:45:05.088966]  batch: 1  d_loss: -280.857117  g_loss: 564.560547  kl_los: 81.916672\n",
            "Elapsed [0:45:18.296796]  batch: 20  d_loss: -278.112335  g_loss: 554.274719  kl_los: 81.874039\n",
            "Time taken for epoch: 15.852 secs\n",
            "\n",
            "Epoch: 19\n",
            "Elapsed [0:45:21.005268]  batch: 1  d_loss: -280.749603  g_loss: 568.633850  kl_los: 81.936493\n",
            "Elapsed [0:45:34.249862]  batch: 20  d_loss: -273.822296  g_loss: 560.289490  kl_los: 81.911873\n",
            "Time taken for epoch: 15.923 secs\n",
            "\n",
            "Epoch: 20\n",
            "Elapsed [0:45:37.001290]  batch: 1  d_loss: -269.941406  g_loss: 533.232300  kl_los: 81.929428\n",
            "Elapsed [0:45:50.263049]  batch: 20  d_loss: -268.959747  g_loss: 528.659912  kl_los: 81.944839\n",
            "Time taken for epoch: 16.034 secs\n",
            "\n",
            "Epoch: 21\n",
            "Elapsed [0:45:53.179316]  batch: 1  d_loss: -275.251862  g_loss: 554.127197  kl_los: 81.990250\n",
            "Elapsed [0:46:06.485014]  batch: 20  d_loss: -269.346436  g_loss: 530.939941  kl_los: 81.906662\n",
            "Time taken for epoch: 16.027 secs\n",
            "\n",
            "Epoch: 22\n",
            "Elapsed [0:46:09.233453]  batch: 1  d_loss: -267.255127  g_loss: 544.227295  kl_los: 81.911392\n",
            "Elapsed [0:46:22.465921]  batch: 20  d_loss: -273.197144  g_loss: 534.859131  kl_los: 81.980225\n",
            "Time taken for epoch: 15.972 secs\n",
            "\n",
            "Epoch: 23\n",
            "Elapsed [0:46:25.292246]  batch: 1  d_loss: -278.612305  g_loss: 558.155334  kl_los: 81.983795\n",
            "Elapsed [0:46:38.495002]  batch: 20  d_loss: -253.064850  g_loss: 507.398132  kl_los: 81.912888\n",
            "Time taken for epoch: 16.022 secs\n",
            "\n",
            "Epoch: 24\n",
            "Elapsed [0:46:41.410661]  batch: 1  d_loss: -270.017639  g_loss: 547.891602  kl_los: 81.946358\n",
            "Elapsed [0:46:54.646332]  batch: 20  d_loss: -267.275330  g_loss: 516.285645  kl_los: 81.937035\n",
            "Time taken for epoch: 16.151 secs\n",
            "\n",
            "Epoch: 25\n",
            "Elapsed [0:46:57.433449]  batch: 1  d_loss: -277.258484  g_loss: 578.670227  kl_los: 81.888916\n",
            "Elapsed [0:47:10.690929]  batch: 20  d_loss: -284.283539  g_loss: 569.194763  kl_los: 81.956223\n",
            "Time taken for epoch: 16.073 secs\n",
            "\n",
            "Epoch: 26\n",
            "Elapsed [0:47:13.520402]  batch: 1  d_loss: -289.922028  g_loss: 670.710571  kl_los: 81.956932\n",
            "Elapsed [0:47:26.802246]  batch: 20  d_loss: -253.630219  g_loss: 500.802460  kl_los: 81.961754\n",
            "Time taken for epoch: 16.098 secs\n",
            "\n",
            "Epoch: 27\n",
            "Elapsed [0:47:29.678065]  batch: 1  d_loss: -274.281311  g_loss: 533.596680  kl_los: 81.955795\n",
            "Elapsed [0:47:42.991622]  batch: 20  d_loss: -267.888794  g_loss: 536.492493  kl_los: 82.115791\n",
            "Time taken for epoch: 16.158 secs\n",
            "\n",
            "Epoch: 28\n",
            "Elapsed [0:47:45.723174]  batch: 1  d_loss: -274.203064  g_loss: 623.058350  kl_los: 81.915298\n",
            "Elapsed [0:47:58.893396]  batch: 20  d_loss: -281.065247  g_loss: 582.050964  kl_los: 82.239433\n",
            "Time taken for epoch: 15.915 secs\n",
            "\n",
            "Epoch: 29\n",
            "Elapsed [0:48:01.202310]  batch: 1  d_loss: -267.022430  g_loss: 569.292480  kl_los: 81.973434\n",
            "Elapsed [0:48:14.408104]  batch: 20  d_loss: -273.839935  g_loss: 578.999084  kl_los: 81.924782\n",
            "Time taken for epoch: 15.586 secs\n",
            "\n",
            "Epoch: 30\n",
            "Elapsed [0:48:17.307565]  batch: 1  d_loss: -270.002838  g_loss: 522.935730  kl_los: 81.941559\n",
            "Elapsed [0:48:30.486559]  batch: 20  d_loss: -295.215759  g_loss: 579.352844  kl_los: 81.898529\n",
            "Time taken for epoch: 15.997 secs\n",
            "\n",
            "Epoch: 31\n",
            "Elapsed [0:48:33.550371]  batch: 1  d_loss: -269.125000  g_loss: 538.873108  kl_los: 81.937820\n",
            "Elapsed [0:48:46.672312]  batch: 20  d_loss: -300.323303  g_loss: 650.686646  kl_los: 81.902267\n",
            "Time taken for epoch: 15.967 secs\n",
            "\n",
            "Epoch: 32\n",
            "Elapsed [0:48:49.339462]  batch: 1  d_loss: -254.249725  g_loss: 569.618652  kl_los: 81.952759\n",
            "Elapsed [0:49:02.531146]  batch: 20  d_loss: -279.067444  g_loss: 527.153259  kl_los: 81.893806\n",
            "Time taken for epoch: 15.846 secs\n",
            "\n",
            "Epoch: 33\n",
            "Elapsed [0:49:05.626533]  batch: 1  d_loss: -274.222198  g_loss: 587.703979  kl_los: 81.922012\n",
            "Elapsed [0:49:18.754354]  batch: 20  d_loss: -255.647202  g_loss: 555.821228  kl_los: 81.926826\n",
            "Time taken for epoch: 16.239 secs\n",
            "\n",
            "Epoch: 34\n",
            "Elapsed [0:49:21.726155]  batch: 1  d_loss: -281.545776  g_loss: 576.404663  kl_los: 81.913490\n",
            "Elapsed [0:49:34.956120]  batch: 20  d_loss: -284.291687  g_loss: 534.661316  kl_los: 81.936592\n",
            "Time taken for epoch: 16.199 secs\n",
            "\n",
            "Epoch: 35\n",
            "Elapsed [0:49:37.539847]  batch: 1  d_loss: -274.519592  g_loss: 523.432373  kl_los: 81.900230\n",
            "Elapsed [0:49:50.748970]  batch: 20  d_loss: -272.129822  g_loss: 550.425781  kl_los: 82.221169\n",
            "Time taken for epoch: 15.813 secs\n",
            "\n",
            "Epoch: 36\n",
            "Elapsed [0:49:53.451505]  batch: 1  d_loss: -274.138062  g_loss: 546.344421  kl_los: 81.972824\n",
            "Elapsed [0:50:06.676472]  batch: 20  d_loss: -269.842255  g_loss: 571.337463  kl_los: 82.134392\n",
            "Time taken for epoch: 15.914 secs\n",
            "\n",
            "Epoch: 37\n",
            "Elapsed [0:50:09.660240]  batch: 1  d_loss: -279.291931  g_loss: 532.411865  kl_los: 81.946045\n",
            "Elapsed [0:50:22.884419]  batch: 20  d_loss: -266.763031  g_loss: 574.550964  kl_los: 82.156822\n",
            "Time taken for epoch: 16.193 secs\n",
            "\n",
            "Epoch: 38\n",
            "Elapsed [0:50:25.750772]  batch: 1  d_loss: -295.957245  g_loss: 763.041626  kl_los: 82.023422\n",
            "Elapsed [0:50:38.981519]  batch: 20  d_loss: -297.663025  g_loss: 658.267029  kl_los: 81.866653\n",
            "Time taken for epoch: 16.108 secs\n",
            "\n",
            "Epoch: 39\n",
            "Elapsed [0:50:41.677444]  batch: 1  d_loss: -265.055450  g_loss: 502.953735  kl_los: 81.882660\n",
            "Elapsed [0:50:54.934174]  batch: 20  d_loss: -275.577087  g_loss: 546.420776  kl_los: 81.945259\n",
            "Time taken for epoch: 15.958 secs\n",
            "\n",
            "Epoch: 40\n",
            "Elapsed [0:50:58.086178]  batch: 1  d_loss: -267.415192  g_loss: 540.091736  kl_los: 81.921242\n",
            "Elapsed [0:51:11.154273]  batch: 20  d_loss: -261.173218  g_loss: 566.388062  kl_los: 81.944130\n",
            "Time taken for epoch: 16.252 secs\n",
            "\n",
            "Epoch: 41\n",
            "Elapsed [0:51:14.115875]  batch: 1  d_loss: -282.037292  g_loss: 581.175232  kl_los: 81.944412\n",
            "Elapsed [0:51:27.282902]  batch: 20  d_loss: -275.518188  g_loss: 582.793884  kl_los: 81.934593\n",
            "Time taken for epoch: 15.831 secs\n",
            "\n",
            "Epoch: 42\n",
            "Elapsed [0:51:30.013237]  batch: 1  d_loss: -257.763153  g_loss: 554.972412  kl_los: 82.004654\n",
            "Elapsed [0:51:43.209323]  batch: 20  d_loss: -296.910095  g_loss: 572.796265  kl_los: 81.971764\n",
            "Time taken for epoch: 15.927 secs\n",
            "\n",
            "Epoch: 43\n",
            "Elapsed [0:51:45.823265]  batch: 1  d_loss: -270.278015  g_loss: 545.009827  kl_los: 82.008904\n",
            "Elapsed [0:51:59.135293]  batch: 20  d_loss: -264.877563  g_loss: 547.066223  kl_los: 82.001122\n",
            "Time taken for epoch: 15.918 secs\n",
            "\n",
            "Epoch: 44\n",
            "Elapsed [0:52:01.924277]  batch: 1  d_loss: -282.061096  g_loss: 545.041748  kl_los: 82.015076\n",
            "Elapsed [0:52:15.094550]  batch: 20  d_loss: -279.888733  g_loss: 583.492249  kl_los: 82.015656\n",
            "Time taken for epoch: 16.011 secs\n",
            "\n",
            "Epoch: 45\n",
            "Elapsed [0:52:17.808550]  batch: 1  d_loss: -269.796844  g_loss: 544.502563  kl_los: 82.014252\n",
            "Elapsed [0:52:31.119331]  batch: 20  d_loss: -251.929108  g_loss: 536.096863  kl_los: 82.044029\n",
            "Time taken for epoch: 15.978 secs\n",
            "\n",
            "Epoch: 46\n",
            "Elapsed [0:52:33.947858]  batch: 1  d_loss: -279.869110  g_loss: 572.579651  kl_los: 82.031090\n",
            "Elapsed [0:52:47.143294]  batch: 20  d_loss: -259.336517  g_loss: 546.180603  kl_los: 82.101097\n",
            "Time taken for epoch: 16.025 secs\n",
            "\n",
            "Epoch: 47\n",
            "Elapsed [0:52:49.980943]  batch: 1  d_loss: -284.713593  g_loss: 598.310425  kl_los: 82.243729\n",
            "Elapsed [0:53:03.089237]  batch: 20  d_loss: -280.672119  g_loss: 600.559387  kl_los: 82.259781\n",
            "Time taken for epoch: 15.953 secs\n",
            "\n",
            "Epoch: 48\n",
            "Elapsed [0:53:05.943788]  batch: 1  d_loss: -273.272766  g_loss: 526.434814  kl_los: 82.389252\n",
            "Elapsed [0:53:19.102153]  batch: 20  d_loss: -292.142334  g_loss: 559.538025  kl_los: 82.313026\n",
            "Time taken for epoch: 16.012 secs\n",
            "\n",
            "Epoch: 49\n",
            "Elapsed [0:53:21.915059]  batch: 1  d_loss: -271.138794  g_loss: 626.150024  kl_los: 82.308876\n",
            "Elapsed [0:53:35.151925]  batch: 20  d_loss: -267.292480  g_loss: 564.603882  kl_los: 82.222748\n",
            "Time taken for epoch: 16.105 secs\n",
            "\n",
            "Epoch: 50\n",
            "Elapsed [0:53:38.008067]  batch: 1  d_loss: -297.813538  g_loss: 667.947510  kl_los: 82.401566\n",
            "Elapsed [0:53:51.289433]  batch: 20  d_loss: -263.996613  g_loss: 575.047913  kl_los: 82.412720\n",
            "Time taken for epoch: 16.078 secs\n",
            "\n",
            "Epoch: 51\n",
            "Elapsed [0:53:54.463721]  batch: 1  d_loss: -306.310211  g_loss: 639.335205  kl_los: 82.290337\n",
            "Elapsed [0:54:07.648126]  batch: 20  d_loss: -287.804443  g_loss: 537.953430  kl_los: 82.327339\n",
            "Time taken for epoch: 16.151 secs\n",
            "\n",
            "Epoch: 52\n",
            "Elapsed [0:54:10.462441]  batch: 1  d_loss: -273.829041  g_loss: 569.465210  kl_los: 82.328293\n",
            "Elapsed [0:54:23.687752]  batch: 20  d_loss: -278.886932  g_loss: 590.154541  kl_los: 82.288147\n",
            "Time taken for epoch: 16.052 secs\n",
            "\n",
            "Epoch: 53\n",
            "Elapsed [0:54:26.501546]  batch: 1  d_loss: -272.281067  g_loss: 525.438416  kl_los: 82.247879\n",
            "Elapsed [0:54:39.704112]  batch: 20  d_loss: -266.672485  g_loss: 577.840027  kl_los: 82.335243\n",
            "Time taken for epoch: 16.036 secs\n",
            "\n",
            "Epoch: 54\n",
            "Elapsed [0:54:42.511380]  batch: 1  d_loss: -280.727844  g_loss: 579.205200  kl_los: 82.477219\n",
            "Elapsed [0:54:55.776875]  batch: 20  d_loss: -284.177124  g_loss: 616.632568  kl_los: 82.264915\n",
            "Time taken for epoch: 16.073 secs\n",
            "\n",
            "Epoch: 55\n",
            "Elapsed [0:54:58.565559]  batch: 1  d_loss: -292.807678  g_loss: 583.651733  kl_los: 82.446304\n",
            "Elapsed [0:55:11.825845]  batch: 20  d_loss: -297.190063  g_loss: 614.450745  kl_los: 82.292252\n",
            "Time taken for epoch: 16.033 secs\n",
            "\n",
            "Epoch: 56\n",
            "Elapsed [0:55:14.699276]  batch: 1  d_loss: -198.137390  g_loss: 676.579102  kl_los: 82.292702\n",
            "Elapsed [0:55:27.911397]  batch: 20  d_loss: -282.691620  g_loss: 680.536682  kl_los: 82.204613\n",
            "Time taken for epoch: 16.097 secs\n",
            "\n",
            "Epoch: 57\n",
            "Elapsed [0:55:30.800178]  batch: 1  d_loss: -266.557770  g_loss: 504.638275  kl_los: 82.183708\n",
            "Elapsed [0:55:44.028912]  batch: 20  d_loss: -292.040344  g_loss: 586.046997  kl_los: 82.245842\n",
            "Time taken for epoch: 16.107 secs\n",
            "\n",
            "Epoch: 58\n",
            "Elapsed [0:55:46.748553]  batch: 1  d_loss: -286.201660  g_loss: 617.532410  kl_los: 82.242218\n",
            "Elapsed [0:56:00.040920]  batch: 20  d_loss: -325.598450  g_loss: 649.105835  kl_los: 82.229515\n",
            "Time taken for epoch: 16.029 secs\n",
            "\n",
            "Epoch: 59\n",
            "Elapsed [0:56:02.956072]  batch: 1  d_loss: -310.213409  g_loss: 652.356873  kl_los: 82.318329\n",
            "Elapsed [0:56:16.106536]  batch: 20  d_loss: -307.966553  g_loss: 647.116699  kl_los: 82.222214\n",
            "Time taken for epoch: 16.068 secs\n",
            "\n",
            "Epoch: 60\n",
            "Elapsed [0:56:18.771072]  batch: 1  d_loss: -298.421600  g_loss: 642.981201  kl_los: 82.296944\n",
            "Elapsed [0:56:31.954082]  batch: 20  d_loss: -338.230011  g_loss: 709.148010  kl_los: 82.200645\n",
            "Time taken for epoch: 15.870 secs\n",
            "\n",
            "Epoch: 61\n",
            "Elapsed [0:56:35.024360]  batch: 1  d_loss: -299.805481  g_loss: 555.644897  kl_los: 82.288925\n",
            "Elapsed [0:56:48.243894]  batch: 20  d_loss: -314.045929  g_loss: 609.227661  kl_los: 82.335640\n",
            "Time taken for epoch: 16.041 secs\n",
            "\n",
            "Epoch: 62\n",
            "Elapsed [0:56:51.176410]  batch: 1  d_loss: -284.446350  g_loss: 573.487671  kl_los: 82.384583\n",
            "Elapsed [0:57:04.446430]  batch: 20  d_loss: -290.603821  g_loss: 587.580200  kl_los: 82.306458\n",
            "Time taken for epoch: 16.191 secs\n",
            "\n",
            "Epoch: 63\n",
            "Elapsed [0:57:07.114060]  batch: 1  d_loss: -299.984863  g_loss: 609.363708  kl_los: 82.371712\n",
            "Elapsed [0:57:20.277003]  batch: 20  d_loss: -264.524536  g_loss: 554.702698  kl_los: 82.225510\n",
            "Time taken for epoch: 15.866 secs\n",
            "\n",
            "Epoch: 64\n",
            "Elapsed [0:57:23.090740]  batch: 1  d_loss: -295.409271  g_loss: 631.717957  kl_los: 82.218521\n",
            "Elapsed [0:57:36.367772]  batch: 20  d_loss: -281.884827  g_loss: 648.068848  kl_los: 82.208954\n",
            "Time taken for epoch: 16.057 secs\n",
            "\n",
            "Epoch: 65\n",
            "Elapsed [0:57:39.084921]  batch: 1  d_loss: -290.284058  g_loss: 563.628418  kl_los: 82.226906\n",
            "Elapsed [0:57:52.428310]  batch: 20  d_loss: -303.098877  g_loss: 582.682373  kl_los: 82.174736\n",
            "Time taken for epoch: 16.065 secs\n",
            "\n",
            "Epoch: 66\n",
            "Elapsed [0:57:55.213432]  batch: 1  d_loss: -270.243042  g_loss: 617.404663  kl_los: 82.145874\n",
            "Elapsed [0:58:08.386272]  batch: 20  d_loss: -312.735840  g_loss: 629.035278  kl_los: 82.145676\n",
            "Time taken for epoch: 15.958 secs\n",
            "\n",
            "Epoch: 67\n",
            "Elapsed [0:58:11.146578]  batch: 1  d_loss: -294.089600  g_loss: 591.523376  kl_los: 82.240433\n",
            "Elapsed [0:58:24.469206]  batch: 20  d_loss: -288.145905  g_loss: 499.147980  kl_los: 82.216873\n",
            "Time taken for epoch: 16.070 secs\n",
            "\n",
            "Epoch: 68\n",
            "Elapsed [0:58:27.314505]  batch: 1  d_loss: -273.707031  g_loss: 648.504395  kl_los: 82.236961\n",
            "Elapsed [0:58:40.524073]  batch: 20  d_loss: -300.520874  g_loss: 642.090942  kl_los: 82.152657\n",
            "Time taken for epoch: 16.066 secs\n",
            "\n",
            "Epoch: 69\n",
            "Elapsed [0:58:43.368421]  batch: 1  d_loss: -285.459198  g_loss: 531.188721  kl_los: 82.132339\n",
            "Elapsed [0:58:56.528432]  batch: 20  d_loss: -276.858826  g_loss: 548.683594  kl_los: 82.251579\n",
            "Time taken for epoch: 16.011 secs\n",
            "\n",
            "Epoch: 70\n",
            "Elapsed [0:58:59.266688]  batch: 1  d_loss: -287.015717  g_loss: 660.914551  kl_los: 82.244049\n",
            "Elapsed [0:59:12.561691]  batch: 20  d_loss: -277.315491  g_loss: 578.989624  kl_los: 82.334389\n",
            "Time taken for epoch: 16.040 secs\n",
            "\n",
            "Epoch: 71\n",
            "Elapsed [0:59:15.686207]  batch: 1  d_loss: -294.349976  g_loss: 581.664307  kl_los: 82.314514\n",
            "Elapsed [0:59:28.991734]  batch: 20  d_loss: -288.700470  g_loss: 619.548889  kl_los: 82.692581\n",
            "Time taken for epoch: 16.211 secs\n",
            "\n",
            "Epoch: 72\n",
            "Elapsed [0:59:31.782063]  batch: 1  d_loss: -275.937225  g_loss: 570.854980  kl_los: 82.286736\n",
            "Elapsed [0:59:44.964141]  batch: 20  d_loss: -285.502228  g_loss: 560.511536  kl_los: 82.285240\n",
            "Time taken for epoch: 15.961 secs\n",
            "\n",
            "Epoch: 73\n",
            "Elapsed [0:59:47.581194]  batch: 1  d_loss: -289.013306  g_loss: 571.084534  kl_los: 82.317207\n",
            "Elapsed [1:00:00.884692]  batch: 20  d_loss: -279.770203  g_loss: 551.772888  kl_los: 82.323303\n",
            "Time taken for epoch: 15.933 secs\n",
            "\n",
            "Epoch: 74\n",
            "Elapsed [1:00:03.769358]  batch: 1  d_loss: -283.346252  g_loss: 594.165833  kl_los: 82.523911\n",
            "Elapsed [1:00:16.911390]  batch: 20  d_loss: -272.802551  g_loss: 512.944153  kl_los: 82.448639\n",
            "Time taken for epoch: 16.025 secs\n",
            "\n",
            "Epoch: 75\n",
            "Elapsed [1:00:19.673031]  batch: 1  d_loss: -291.731445  g_loss: 664.644897  kl_los: 82.420219\n",
            "Elapsed [1:00:32.911811]  batch: 20  d_loss: -288.065613  g_loss: 545.354431  kl_los: 82.420128\n",
            "Time taken for epoch: 16.005 secs\n",
            "\n",
            "Epoch: 76\n",
            "Elapsed [1:00:35.826619]  batch: 1  d_loss: -278.520874  g_loss: 593.716736  kl_los: 82.450424\n",
            "Elapsed [1:00:48.972792]  batch: 20  d_loss: -291.516815  g_loss: 535.595703  kl_los: 82.463875\n",
            "Time taken for epoch: 16.034 secs\n",
            "\n",
            "Epoch: 77\n",
            "Elapsed [1:00:51.764173]  batch: 1  d_loss: -269.135437  g_loss: 566.403076  kl_los: 82.751030\n",
            "Elapsed [1:01:04.989012]  batch: 20  d_loss: -296.740662  g_loss: 600.436890  kl_los: 82.552002\n",
            "Time taken for epoch: 16.035 secs\n",
            "\n",
            "Epoch: 78\n",
            "Elapsed [1:01:07.716503]  batch: 1  d_loss: -278.005951  g_loss: 547.016296  kl_los: 82.702766\n",
            "Elapsed [1:01:20.940248]  batch: 20  d_loss: -273.671997  g_loss: 572.340393  kl_los: 82.462418\n",
            "Time taken for epoch: 15.941 secs\n",
            "\n",
            "Epoch: 79\n",
            "Elapsed [1:01:23.337325]  batch: 1  d_loss: -284.269043  g_loss: 559.369873  kl_los: 82.513008\n",
            "Elapsed [1:01:36.532184]  batch: 20  d_loss: -289.051941  g_loss: 582.548950  kl_los: 82.509277\n",
            "Time taken for epoch: 15.598 secs\n",
            "\n",
            "Epoch: 80\n",
            "Elapsed [1:01:39.247321]  batch: 1  d_loss: -274.764221  g_loss: 528.027527  kl_los: 82.460648\n",
            "Elapsed [1:01:52.576643]  batch: 20  d_loss: -275.208496  g_loss: 608.033325  kl_los: 82.490860\n",
            "Time taken for epoch: 16.065 secs\n",
            "\n",
            "Epoch: 81\n",
            "Elapsed [1:01:55.559335]  batch: 1  d_loss: -279.408386  g_loss: 647.805847  kl_los: 82.420860\n",
            "Elapsed [1:02:08.753291]  batch: 20  d_loss: -274.545502  g_loss: 604.034302  kl_los: 82.348808\n",
            "Time taken for epoch: 15.979 secs\n",
            "\n",
            "Epoch: 82\n",
            "Elapsed [1:02:11.556116]  batch: 1  d_loss: -287.434082  g_loss: 564.507751  kl_los: 82.429443\n",
            "Elapsed [1:02:24.718270]  batch: 20  d_loss: -270.781525  g_loss: 553.107910  kl_los: 82.328156\n",
            "Time taken for epoch: 15.965 secs\n",
            "\n",
            "Epoch: 83\n",
            "Elapsed [1:02:27.491586]  batch: 1  d_loss: -284.820190  g_loss: 543.716675  kl_los: 82.296364\n",
            "Elapsed [1:02:40.742551]  batch: 20  d_loss: -255.026566  g_loss: 628.132568  kl_los: 82.266441\n",
            "Time taken for epoch: 16.043 secs\n",
            "\n",
            "Epoch: 84\n",
            "Elapsed [1:02:43.560843]  batch: 1  d_loss: -265.885773  g_loss: 498.489471  kl_los: 82.224747\n",
            "Elapsed [1:02:56.785611]  batch: 20  d_loss: -275.708130  g_loss: 604.032654  kl_los: 82.820663\n",
            "Time taken for epoch: 16.019 secs\n",
            "\n",
            "Epoch: 85\n",
            "Elapsed [1:02:59.628499]  batch: 1  d_loss: -270.568542  g_loss: 484.324280  kl_los: 82.256775\n",
            "Elapsed [1:03:12.885650]  batch: 20  d_loss: -288.388306  g_loss: 573.263977  kl_los: 82.126022\n",
            "Time taken for epoch: 16.100 secs\n",
            "\n",
            "Epoch: 86\n",
            "Elapsed [1:03:15.686625]  batch: 1  d_loss: -277.843323  g_loss: 569.109131  kl_los: 82.087479\n",
            "Elapsed [1:03:28.952061]  batch: 20  d_loss: -284.443115  g_loss: 626.694336  kl_los: 82.171051\n",
            "Time taken for epoch: 16.060 secs\n",
            "\n",
            "Epoch: 87\n",
            "Elapsed [1:03:31.775819]  batch: 1  d_loss: -266.477112  g_loss: 497.409363  kl_los: 82.189194\n",
            "Elapsed [1:03:44.945211]  batch: 20  d_loss: -284.350647  g_loss: 551.308350  kl_los: 82.113716\n",
            "Time taken for epoch: 15.993 secs\n",
            "\n",
            "Epoch: 88\n",
            "Elapsed [1:03:47.984081]  batch: 1  d_loss: -266.523712  g_loss: 553.997437  kl_los: 82.107964\n",
            "Elapsed [1:04:01.196564]  batch: 20  d_loss: -257.877258  g_loss: 591.606995  kl_los: 82.632881\n",
            "Time taken for epoch: 16.260 secs\n",
            "\n",
            "Epoch: 89\n",
            "Elapsed [1:04:03.961069]  batch: 1  d_loss: -265.713196  g_loss: 555.341553  kl_los: 82.296051\n",
            "Elapsed [1:04:17.177346]  batch: 20  d_loss: -276.736603  g_loss: 495.621857  kl_los: 82.214005\n",
            "Time taken for epoch: 15.958 secs\n",
            "\n",
            "Epoch: 90\n",
            "Elapsed [1:04:19.919582]  batch: 1  d_loss: -264.395294  g_loss: 619.745239  kl_los: 82.225876\n",
            "Elapsed [1:04:33.123330]  batch: 20  d_loss: -280.031128  g_loss: 529.093933  kl_los: 82.153435\n",
            "Time taken for epoch: 15.967 secs\n",
            "\n",
            "Epoch: 91\n",
            "Elapsed [1:04:36.074712]  batch: 1  d_loss: -266.954620  g_loss: 604.017700  kl_los: 82.319366\n",
            "Elapsed [1:04:49.231009]  batch: 20  d_loss: -251.340546  g_loss: 540.942322  kl_los: 82.126587\n",
            "Time taken for epoch: 15.894 secs\n",
            "\n",
            "Epoch: 92\n",
            "Elapsed [1:04:52.103632]  batch: 1  d_loss: -279.881195  g_loss: 557.593262  kl_los: 82.119110\n",
            "Elapsed [1:05:05.301846]  batch: 20  d_loss: -274.776886  g_loss: 538.367737  kl_los: 82.030464\n",
            "Time taken for epoch: 16.076 secs\n",
            "\n",
            "Epoch: 93\n",
            "Elapsed [1:05:08.067522]  batch: 1  d_loss: -266.505707  g_loss: 569.301758  kl_los: 82.143959\n",
            "Elapsed [1:05:21.335923]  batch: 20  d_loss: -275.840149  g_loss: 608.689148  kl_los: 82.024948\n",
            "Time taken for epoch: 16.035 secs\n",
            "\n",
            "Epoch: 94\n",
            "Elapsed [1:05:24.112860]  batch: 1  d_loss: -276.235107  g_loss: 517.890381  kl_los: 82.040543\n",
            "Elapsed [1:05:37.376568]  batch: 20  d_loss: -250.178131  g_loss: 463.333679  kl_los: 82.007195\n",
            "Time taken for epoch: 16.079 secs\n",
            "\n",
            "Epoch: 95\n",
            "Elapsed [1:05:40.251842]  batch: 1  d_loss: -244.158249  g_loss: 622.386414  kl_los: 82.052673\n",
            "Elapsed [1:05:53.479424]  batch: 20  d_loss: -276.571594  g_loss: 554.931885  kl_los: 81.996132\n",
            "Time taken for epoch: 16.067 secs\n",
            "\n",
            "Epoch: 96\n",
            "Elapsed [1:05:56.120267]  batch: 1  d_loss: -264.854126  g_loss: 577.888184  kl_los: 81.973038\n",
            "Elapsed [1:06:09.333423]  batch: 20  d_loss: -266.102356  g_loss: 583.391846  kl_los: 81.963043\n",
            "Time taken for epoch: 15.847 secs\n",
            "\n",
            "Epoch: 97\n",
            "Elapsed [1:06:12.305733]  batch: 1  d_loss: -279.335907  g_loss: 560.436951  kl_los: 81.965729\n",
            "Elapsed [1:06:25.474598]  batch: 20  d_loss: -270.877808  g_loss: 557.972473  kl_los: 81.928169\n",
            "Time taken for epoch: 16.156 secs\n",
            "\n",
            "Epoch: 98\n",
            "Elapsed [1:06:28.219695]  batch: 1  d_loss: -282.080505  g_loss: 569.218628  kl_los: 81.930786\n",
            "Elapsed [1:06:41.375660]  batch: 20  d_loss: -272.062622  g_loss: 537.324524  kl_los: 81.926788\n",
            "Time taken for epoch: 15.895 secs\n",
            "\n",
            "Epoch: 99\n",
            "Elapsed [1:06:44.160082]  batch: 1  d_loss: -280.322357  g_loss: 593.258301  kl_los: 81.941566\n",
            "Elapsed [1:06:57.322024]  batch: 20  d_loss: -267.049072  g_loss: 623.683350  kl_los: 81.944893\n",
            "Time taken for epoch: 15.946 secs\n",
            "\n",
            "Epoch: 100\n",
            "Elapsed [1:07:00.107053]  batch: 1  d_loss: -264.579681  g_loss: 517.698608  kl_los: 82.092850\n",
            "Elapsed [1:07:13.333380]  batch: 20  d_loss: -279.206024  g_loss: 600.849182  kl_los: 81.888214\n",
            "Time taken for epoch: 15.994 secs\n",
            "\n",
            "Epoch: 101\n",
            "Elapsed [1:07:16.335848]  batch: 1  d_loss: -235.043091  g_loss: 471.033630  kl_los: 81.905991\n",
            "Elapsed [1:07:29.505864]  batch: 20  d_loss: -266.522705  g_loss: 543.601746  kl_los: 81.892563\n",
            "Time taken for epoch: 15.979 secs\n",
            "\n",
            "Epoch: 102\n",
            "Elapsed [1:07:32.331455]  batch: 1  d_loss: -278.383911  g_loss: 583.905457  kl_los: 81.911301\n",
            "Elapsed [1:07:45.560544]  batch: 20  d_loss: -268.264740  g_loss: 534.680908  kl_los: 81.902824\n",
            "Time taken for epoch: 16.045 secs\n",
            "\n",
            "Epoch: 103\n",
            "Elapsed [1:07:48.337181]  batch: 1  d_loss: -264.696411  g_loss: 567.055481  kl_los: 81.889694\n",
            "Elapsed [1:08:01.567786]  batch: 20  d_loss: -291.246979  g_loss: 596.607117  kl_los: 81.892151\n",
            "Time taken for epoch: 16.012 secs\n",
            "\n",
            "Epoch: 104\n",
            "Elapsed [1:08:04.229236]  batch: 1  d_loss: -258.018066  g_loss: 519.944763  kl_los: 81.927055\n",
            "Elapsed [1:08:17.405711]  batch: 20  d_loss: -289.046875  g_loss: 591.399109  kl_los: 81.888809\n",
            "Time taken for epoch: 15.831 secs\n",
            "\n",
            "Epoch: 105\n",
            "Elapsed [1:08:20.141979]  batch: 1  d_loss: -263.445862  g_loss: 515.430603  kl_los: 81.889084\n",
            "Elapsed [1:08:33.390883]  batch: 20  d_loss: -281.160675  g_loss: 490.366211  kl_los: 81.837318\n",
            "Time taken for epoch: 16.012 secs\n",
            "\n",
            "Epoch: 106\n",
            "Elapsed [1:08:36.112494]  batch: 1  d_loss: -275.349915  g_loss: 634.550049  kl_los: 81.865654\n",
            "Elapsed [1:08:49.310819]  batch: 20  d_loss: -291.135162  g_loss: 529.095886  kl_los: 81.895592\n",
            "Time taken for epoch: 15.937 secs\n",
            "\n",
            "Epoch: 107\n",
            "Elapsed [1:08:52.225025]  batch: 1  d_loss: -262.209595  g_loss: 546.880249  kl_los: 81.889626\n",
            "Elapsed [1:09:05.285176]  batch: 20  d_loss: -272.333618  g_loss: 554.007935  kl_los: 81.915703\n",
            "Time taken for epoch: 15.918 secs\n",
            "\n",
            "Epoch: 108\n",
            "Elapsed [1:09:08.102038]  batch: 1  d_loss: -279.473267  g_loss: 557.875000  kl_los: 81.923843\n",
            "Elapsed [1:09:21.264681]  batch: 20  d_loss: -267.026611  g_loss: 570.595337  kl_los: 81.925545\n",
            "Time taken for epoch: 15.996 secs\n",
            "\n",
            "Epoch: 109\n",
            "Elapsed [1:09:24.089364]  batch: 1  d_loss: -273.937988  g_loss: 510.380676  kl_los: 81.935074\n",
            "Elapsed [1:09:37.221178]  batch: 20  d_loss: -258.745758  g_loss: 504.121277  kl_los: 81.967979\n",
            "Time taken for epoch: 15.947 secs\n",
            "\n",
            "Epoch: 110\n",
            "Elapsed [1:09:39.896253]  batch: 1  d_loss: -266.067810  g_loss: 608.640869  kl_los: 81.985153\n",
            "Elapsed [1:09:52.949706]  batch: 20  d_loss: -261.363647  g_loss: 600.944641  kl_los: 81.983521\n",
            "Time taken for epoch: 15.760 secs\n",
            "\n",
            "Epoch: 111\n",
            "Elapsed [1:09:55.796199]  batch: 1  d_loss: -256.324615  g_loss: 517.249878  kl_los: 82.012817\n",
            "Elapsed [1:10:09.043027]  batch: 20  d_loss: -273.050720  g_loss: 570.045959  kl_los: 82.008522\n",
            "Time taken for epoch: 15.763 secs\n",
            "\n",
            "Epoch: 112\n",
            "Elapsed [1:10:11.820886]  batch: 1  d_loss: -272.482483  g_loss: 542.586548  kl_los: 82.006500\n",
            "Elapsed [1:10:25.041422]  batch: 20  d_loss: -276.716980  g_loss: 646.377319  kl_los: 82.320709\n",
            "Time taken for epoch: 15.968 secs\n",
            "\n",
            "Epoch: 113\n",
            "Elapsed [1:10:27.828765]  batch: 1  d_loss: -257.019348  g_loss: 493.095642  kl_los: 82.126175\n",
            "Elapsed [1:10:41.086256]  batch: 20  d_loss: -274.025116  g_loss: 526.608398  kl_los: 81.889832\n",
            "Time taken for epoch: 16.088 secs\n",
            "\n",
            "Epoch: 114\n",
            "Elapsed [1:10:43.818797]  batch: 1  d_loss: -256.653015  g_loss: 583.470947  kl_los: 81.914871\n",
            "Elapsed [1:10:57.020102]  batch: 20  d_loss: -281.878021  g_loss: 518.581604  kl_los: 82.039574\n",
            "Time taken for epoch: 15.945 secs\n",
            "\n",
            "Epoch: 115\n",
            "Elapsed [1:10:59.865624]  batch: 1  d_loss: -262.233643  g_loss: 555.740479  kl_los: 82.037338\n",
            "Elapsed [1:11:13.035502]  batch: 20  d_loss: -279.736511  g_loss: 484.484558  kl_los: 81.998375\n",
            "Time taken for epoch: 15.987 secs\n",
            "\n",
            "Epoch: 116\n",
            "Elapsed [1:11:15.892814]  batch: 1  d_loss: -238.350433  g_loss: 558.773193  kl_los: 82.066628\n",
            "Elapsed [1:11:29.034250]  batch: 20  d_loss: -266.221222  g_loss: 491.442535  kl_los: 81.992645\n",
            "Time taken for epoch: 15.970 secs\n",
            "\n",
            "Epoch: 117\n",
            "Elapsed [1:11:31.726181]  batch: 1  d_loss: -260.472351  g_loss: 544.181030  kl_los: 81.996819\n",
            "Elapsed [1:11:44.921677]  batch: 20  d_loss: -260.133911  g_loss: 520.679382  kl_los: 81.961571\n",
            "Time taken for epoch: 15.922 secs\n",
            "\n",
            "Epoch: 118\n",
            "Elapsed [1:11:47.602013]  batch: 1  d_loss: -270.545746  g_loss: 559.235718  kl_los: 81.975464\n",
            "Elapsed [1:12:00.801050]  batch: 20  d_loss: -258.237885  g_loss: 585.370667  kl_los: 81.994911\n",
            "Time taken for epoch: 15.889 secs\n",
            "\n",
            "Epoch: 119\n",
            "Elapsed [1:12:03.690179]  batch: 1  d_loss: -266.139343  g_loss: 564.550171  kl_los: 82.039612\n",
            "Elapsed [1:12:16.847543]  batch: 20  d_loss: -275.775024  g_loss: 590.243530  kl_los: 82.241234\n",
            "Time taken for epoch: 16.024 secs\n",
            "\n",
            "Epoch: 120\n",
            "Elapsed [1:12:19.935548]  batch: 1  d_loss: -278.721466  g_loss: 506.230164  kl_los: 81.995598\n",
            "Elapsed [1:12:33.064627]  batch: 20  d_loss: -275.617676  g_loss: 570.934998  kl_los: 82.031540\n",
            "Time taken for epoch: 16.281 secs\n",
            "\n",
            "\n",
            "Currently working on Depth:  3\n",
            "Current resolution: 32 x 32\n",
            "\n",
            "Epoch: 1\n",
            "Elapsed [1:12:39.786627]  batch: 1  d_loss: -275.197571  g_loss: 528.411987  kl_los: 81.995728\n",
            "Elapsed [1:13:11.499709]  batch: 20  d_loss: -294.693787  g_loss: 615.130981  kl_los: 82.071983\n",
            "Time taken for epoch: 38.238 secs\n",
            "\n",
            "Epoch: 2\n",
            "Elapsed [1:13:15.242600]  batch: 1  d_loss: -271.683899  g_loss: 632.047729  kl_los: 82.089111\n",
            "Elapsed [1:13:45.129629]  batch: 20  d_loss: -360.729950  g_loss: 845.178284  kl_los: 82.158623\n",
            "Time taken for epoch: 33.601 secs\n",
            "\n",
            "Epoch: 3\n",
            "Elapsed [1:13:49.088068]  batch: 1  d_loss: -252.494598  g_loss: 534.445190  kl_los: 82.140839\n",
            "Elapsed [1:14:19.153909]  batch: 20  d_loss: -497.490295  g_loss: 1103.376465  kl_los: 82.310280\n",
            "Time taken for epoch: 34.031 secs\n",
            "\n",
            "Epoch: 4\n",
            "Elapsed [1:14:23.120153]  batch: 1  d_loss: -265.506439  g_loss: 503.706665  kl_los: 82.385162\n",
            "Elapsed [1:14:52.996324]  batch: 20  d_loss: -304.530670  g_loss: 764.728210  kl_los: 82.534027\n",
            "Time taken for epoch: 33.844 secs\n",
            "\n",
            "Epoch: 5\n",
            "Elapsed [1:14:56.855614]  batch: 1  d_loss: -398.679077  g_loss: 949.143677  kl_los: 82.561020\n",
            "Elapsed [1:15:26.948999]  batch: 20  d_loss: -291.033203  g_loss: 738.295715  kl_los: 83.295044\n",
            "Time taken for epoch: 33.976 secs\n",
            "\n",
            "Epoch: 6\n",
            "Elapsed [1:15:30.842934]  batch: 1  d_loss: -357.990387  g_loss: 821.207275  kl_los: 82.558365\n",
            "Elapsed [1:16:01.258632]  batch: 20  d_loss: -332.664795  g_loss: 713.753906  kl_los: 82.769196\n",
            "Time taken for epoch: 34.286 secs\n",
            "\n",
            "Epoch: 7\n",
            "Elapsed [1:16:05.231024]  batch: 1  d_loss: -321.447571  g_loss: 707.620178  kl_los: 82.734634\n",
            "Elapsed [1:16:35.606944]  batch: 20  d_loss: -294.354370  g_loss: 621.223389  kl_los: 82.613129\n",
            "Time taken for epoch: 34.374 secs\n",
            "\n",
            "Epoch: 8\n",
            "Elapsed [1:16:39.325851]  batch: 1  d_loss: -320.613647  g_loss: 653.184448  kl_los: 82.805084\n",
            "Elapsed [1:17:09.625104]  batch: 20  d_loss: -314.347168  g_loss: 743.343689  kl_los: 82.429085\n",
            "Time taken for epoch: 34.001 secs\n",
            "\n",
            "Epoch: 9\n",
            "Elapsed [1:17:13.506409]  batch: 1  d_loss: -320.920715  g_loss: 666.398804  kl_los: 82.435646\n",
            "Elapsed [1:17:43.999103]  batch: 20  d_loss: -373.129303  g_loss: 753.417908  kl_los: 82.489494\n",
            "Time taken for epoch: 34.413 secs\n",
            "\n",
            "Epoch: 10\n",
            "Elapsed [1:17:47.889315]  batch: 1  d_loss: -306.741089  g_loss: 745.704468  kl_los: 82.525894\n",
            "Elapsed [1:18:18.260481]  batch: 20  d_loss: -312.457245  g_loss: 634.540161  kl_los: 82.383171\n",
            "Time taken for epoch: 34.284 secs\n",
            "\n",
            "Epoch: 11\n",
            "Elapsed [1:18:22.247268]  batch: 1  d_loss: -290.267670  g_loss: 715.254761  kl_los: 82.459999\n",
            "Elapsed [1:18:52.497256]  batch: 20  d_loss: -353.754333  g_loss: 782.879089  kl_los: 82.387886\n",
            "Time taken for epoch: 34.036 secs\n",
            "\n",
            "Epoch: 12\n",
            "Elapsed [1:18:56.181884]  batch: 1  d_loss: -318.894379  g_loss: 711.963013  kl_los: 82.399231\n",
            "Elapsed [1:19:26.382155]  batch: 20  d_loss: -280.000885  g_loss: 595.600342  kl_los: 82.419037\n",
            "Time taken for epoch: 33.864 secs\n",
            "\n",
            "Epoch: 13\n",
            "Elapsed [1:19:30.196516]  batch: 1  d_loss: -334.237427  g_loss: 727.217407  kl_los: 82.342972\n",
            "Elapsed [1:20:00.520866]  batch: 20  d_loss: -308.495422  g_loss: 654.241089  kl_los: 82.321869\n",
            "Time taken for epoch: 34.148 secs\n",
            "\n",
            "Epoch: 14\n",
            "Elapsed [1:20:04.140048]  batch: 1  d_loss: -269.168701  g_loss: 656.857056  kl_los: 82.515961\n",
            "Elapsed [1:20:34.392739]  batch: 20  d_loss: -321.205261  g_loss: 673.244141  kl_los: 82.286285\n",
            "Time taken for epoch: 33.889 secs\n",
            "\n",
            "Epoch: 15\n",
            "Elapsed [1:20:38.113369]  batch: 1  d_loss: -229.299438  g_loss: 497.828064  kl_los: 82.287834\n",
            "Elapsed [1:21:08.359771]  batch: 20  d_loss: -329.822571  g_loss: 764.781921  kl_los: 82.268684\n",
            "Time taken for epoch: 33.937 secs\n",
            "\n",
            "Epoch: 16\n",
            "Elapsed [1:21:12.432042]  batch: 1  d_loss: -382.158142  g_loss: 719.669495  kl_los: 82.640503\n",
            "Elapsed [1:21:42.738475]  batch: 20  d_loss: -166.212250  g_loss: 595.728760  kl_los: 82.308769\n",
            "Time taken for epoch: 34.380 secs\n",
            "\n",
            "Epoch: 17\n",
            "Elapsed [1:21:46.398894]  batch: 1  d_loss: -385.372772  g_loss: 908.712769  kl_los: 82.337181\n",
            "Elapsed [1:22:16.756531]  batch: 20  d_loss: -321.320618  g_loss: 720.411682  kl_los: 82.382576\n",
            "Time taken for epoch: 34.031 secs\n",
            "\n",
            "Epoch: 18\n",
            "Elapsed [1:22:20.594906]  batch: 1  d_loss: -272.787903  g_loss: 745.553467  kl_los: 82.405121\n",
            "Elapsed [1:22:50.894665]  batch: 20  d_loss: -324.767120  g_loss: 675.959656  kl_los: 82.464218\n",
            "Time taken for epoch: 34.160 secs\n",
            "\n",
            "Epoch: 19\n",
            "Elapsed [1:22:54.822796]  batch: 1  d_loss: -318.105804  g_loss: 623.555664  kl_los: 82.467628\n",
            "Elapsed [1:23:25.115551]  batch: 20  d_loss: -334.713654  g_loss: 588.804138  kl_los: 82.431541\n",
            "Time taken for epoch: 34.215 secs\n",
            "\n",
            "Epoch: 20\n",
            "Elapsed [1:23:28.795315]  batch: 1  d_loss: -317.770874  g_loss: 581.124146  kl_los: 82.385071\n",
            "Elapsed [1:23:58.979332]  batch: 20  d_loss: -336.421387  g_loss: 662.518433  kl_los: 82.431076\n",
            "Time taken for epoch: 33.856 secs\n",
            "\n",
            "Epoch: 21\n",
            "Elapsed [1:24:02.917481]  batch: 1  d_loss: -283.033386  g_loss: 463.201050  kl_los: 82.389854\n",
            "Elapsed [1:24:33.364295]  batch: 20  d_loss: -330.847504  g_loss: 779.137085  kl_los: 82.280670\n",
            "Time taken for epoch: 34.161 secs\n",
            "\n",
            "Epoch: 22\n",
            "Elapsed [1:24:37.105224]  batch: 1  d_loss: -323.904663  g_loss: 730.940430  kl_los: 82.341721\n",
            "Elapsed [1:25:07.406320]  batch: 20  d_loss: -328.019226  g_loss: 747.490540  kl_los: 82.299576\n",
            "Time taken for epoch: 34.043 secs\n",
            "\n",
            "Epoch: 23\n",
            "Elapsed [1:25:11.155332]  batch: 1  d_loss: -428.011444  g_loss: 860.385559  kl_los: 82.322540\n",
            "Elapsed [1:25:41.598310]  batch: 20  d_loss: -301.479126  g_loss: 496.598694  kl_los: 82.339043\n",
            "Time taken for epoch: 34.198 secs\n",
            "\n",
            "Epoch: 24\n",
            "Elapsed [1:25:45.312916]  batch: 1  d_loss: -339.273773  g_loss: 985.494690  kl_los: 82.353432\n",
            "Elapsed [1:26:15.669202]  batch: 20  d_loss: -289.237671  g_loss: 644.028381  kl_los: 82.241646\n",
            "Time taken for epoch: 34.067 secs\n",
            "\n",
            "Epoch: 25\n",
            "Elapsed [1:26:19.477056]  batch: 1  d_loss: -305.128052  g_loss: 558.749146  kl_los: 82.188873\n",
            "Elapsed [1:26:49.806739]  batch: 20  d_loss: -299.958710  g_loss: 508.605103  kl_los: 82.143623\n",
            "Time taken for epoch: 34.139 secs\n",
            "\n",
            "Epoch: 26\n",
            "Elapsed [1:26:53.592029]  batch: 1  d_loss: -315.923950  g_loss: 763.603271  kl_los: 82.150986\n",
            "Elapsed [1:27:23.902522]  batch: 20  d_loss: -437.819000  g_loss: 889.034424  kl_los: 82.150909\n",
            "Time taken for epoch: 34.100 secs\n",
            "\n",
            "Epoch: 27\n",
            "Elapsed [1:27:27.579704]  batch: 1  d_loss: -173.336670  g_loss: 632.154968  kl_los: 82.385620\n",
            "Elapsed [1:27:57.853287]  batch: 20  d_loss: -295.354156  g_loss: 579.367004  kl_los: 82.118210\n",
            "Time taken for epoch: 33.947 secs\n",
            "\n",
            "Epoch: 28\n",
            "Elapsed [1:28:01.583604]  batch: 1  d_loss: -411.376373  g_loss: 1095.137939  kl_los: 82.104919\n",
            "Elapsed [1:28:31.738059]  batch: 20  d_loss: -289.422852  g_loss: 543.608948  kl_los: 82.236702\n",
            "Time taken for epoch: 33.935 secs\n",
            "\n",
            "Epoch: 29\n",
            "Elapsed [1:28:35.063863]  batch: 1  d_loss: -328.530792  g_loss: 822.687012  kl_los: 82.219398\n",
            "Elapsed [1:29:05.351499]  batch: 20  d_loss: -446.032440  g_loss: 1076.571289  kl_los: 82.308556\n",
            "Time taken for epoch: 33.587 secs\n",
            "\n",
            "Epoch: 30\n",
            "Elapsed [1:29:09.257928]  batch: 1  d_loss: -250.906219  g_loss: 512.548584  kl_los: 82.306808\n",
            "Elapsed [1:29:39.563706]  batch: 20  d_loss: -343.857330  g_loss: 760.455017  kl_los: 82.395767\n",
            "Time taken for epoch: 34.200 secs\n",
            "\n",
            "Epoch: 31\n",
            "Elapsed [1:29:43.574083]  batch: 1  d_loss: -475.866821  g_loss: 1028.677734  kl_los: 82.499466\n",
            "Elapsed [1:30:13.890765]  batch: 20  d_loss: -316.292786  g_loss: 709.763428  kl_los: 82.329430\n",
            "Time taken for epoch: 34.116 secs\n",
            "\n",
            "Epoch: 32\n",
            "Elapsed [1:30:17.738906]  batch: 1  d_loss: -315.076782  g_loss: 804.419312  kl_los: 82.408958\n",
            "Elapsed [1:30:47.955187]  batch: 20  d_loss: -288.054321  g_loss: 570.841187  kl_los: 82.452393\n",
            "Time taken for epoch: 34.109 secs\n",
            "\n",
            "Epoch: 33\n",
            "Elapsed [1:30:51.817382]  batch: 1  d_loss: -341.534637  g_loss: 746.154175  kl_los: 82.677910\n",
            "Elapsed [1:31:22.074722]  batch: 20  d_loss: -350.569153  g_loss: 679.191223  kl_los: 82.627243\n",
            "Time taken for epoch: 34.094 secs\n",
            "\n",
            "Epoch: 34\n",
            "Elapsed [1:31:25.914274]  batch: 1  d_loss: -254.993240  g_loss: 610.733154  kl_los: 82.864639\n",
            "Elapsed [1:31:56.114536]  batch: 20  d_loss: -307.510193  g_loss: 867.570862  kl_los: 82.460052\n",
            "Time taken for epoch: 34.036 secs\n",
            "\n",
            "Epoch: 35\n",
            "Elapsed [1:31:59.938706]  batch: 1  d_loss: -271.188934  g_loss: 499.054199  kl_los: 82.516983\n",
            "Elapsed [1:32:30.195220]  batch: 20  d_loss: -274.586670  g_loss: 668.137390  kl_los: 82.398262\n",
            "Time taken for epoch: 34.066 secs\n",
            "\n",
            "Epoch: 36\n",
            "Elapsed [1:32:34.064766]  batch: 1  d_loss: -242.580139  g_loss: 459.801575  kl_los: 82.420044\n",
            "Elapsed [1:33:04.367316]  batch: 20  d_loss: -367.854004  g_loss: 647.500549  kl_los: 82.353020\n",
            "Time taken for epoch: 34.176 secs\n",
            "\n",
            "Epoch: 37\n",
            "Elapsed [1:33:08.071856]  batch: 1  d_loss: -258.644897  g_loss: 687.001221  kl_los: 82.390442\n",
            "Elapsed [1:33:38.350311]  batch: 20  d_loss: -360.947205  g_loss: 825.970520  kl_los: 82.269371\n",
            "Time taken for epoch: 34.018 secs\n",
            "\n",
            "Epoch: 38\n",
            "Elapsed [1:33:42.118762]  batch: 1  d_loss: -282.109680  g_loss: 669.863281  kl_los: 82.388138\n",
            "Elapsed [1:34:12.403721]  batch: 20  d_loss: -357.449860  g_loss: 801.620911  kl_los: 82.226974\n",
            "Time taken for epoch: 34.075 secs\n",
            "\n",
            "Epoch: 39\n",
            "Elapsed [1:34:15.812368]  batch: 1  d_loss: -331.351135  g_loss: 600.336670  kl_los: 82.309265\n",
            "Elapsed [1:34:46.155388]  batch: 20  d_loss: -347.687378  g_loss: 571.651306  kl_los: 82.309105\n",
            "Time taken for epoch: 33.699 secs\n",
            "\n",
            "Epoch: 40\n",
            "Elapsed [1:34:49.968651]  batch: 1  d_loss: -315.791901  g_loss: 857.582153  kl_los: 82.421082\n",
            "Elapsed [1:35:20.258720]  batch: 20  d_loss: -295.188110  g_loss: 625.211121  kl_los: 82.413170\n",
            "Time taken for epoch: 34.106 secs\n",
            "\n",
            "Epoch: 41\n",
            "Elapsed [1:35:24.176285]  batch: 1  d_loss: -312.766418  g_loss: 618.109375  kl_los: 82.441490\n",
            "Elapsed [1:35:54.464275]  batch: 20  d_loss: -290.076355  g_loss: 634.763977  kl_los: 82.359802\n",
            "Time taken for epoch: 33.989 secs\n",
            "\n",
            "Epoch: 42\n",
            "Elapsed [1:35:58.077172]  batch: 1  d_loss: -304.179321  g_loss: 540.146973  kl_los: 82.450470\n",
            "Elapsed [1:36:28.336779]  batch: 20  d_loss: -310.154022  g_loss: 656.504211  kl_los: 82.372963\n",
            "Time taken for epoch: 33.879 secs\n",
            "\n",
            "Epoch: 43\n",
            "Elapsed [1:36:32.103921]  batch: 1  d_loss: -297.220551  g_loss: 559.349731  kl_los: 82.328613\n",
            "Elapsed [1:37:02.454218]  batch: 20  d_loss: -334.324768  g_loss: 584.956177  kl_los: 82.407974\n",
            "Time taken for epoch: 34.145 secs\n",
            "\n",
            "Epoch: 44\n",
            "Elapsed [1:37:06.203856]  batch: 1  d_loss: -305.636047  g_loss: 673.920654  kl_los: 82.415558\n",
            "Elapsed [1:37:36.407470]  batch: 20  d_loss: -273.632141  g_loss: 495.031342  kl_los: 82.282051\n",
            "Time taken for epoch: 33.958 secs\n",
            "\n",
            "Epoch: 45\n",
            "Elapsed [1:37:40.331066]  batch: 1  d_loss: -298.529419  g_loss: 662.195557  kl_los: 82.315208\n",
            "Elapsed [1:38:10.460294]  batch: 20  d_loss: -303.304535  g_loss: 636.118591  kl_los: 82.956795\n",
            "Time taken for epoch: 34.021 secs\n",
            "\n",
            "Epoch: 46\n",
            "Elapsed [1:38:14.162782]  batch: 1  d_loss: -292.453339  g_loss: 543.901001  kl_los: 82.348221\n",
            "Elapsed [1:38:44.488190]  batch: 20  d_loss: -336.167114  g_loss: 748.814941  kl_los: 82.469261\n",
            "Time taken for epoch: 34.027 secs\n",
            "\n",
            "Epoch: 47\n",
            "Elapsed [1:38:48.080824]  batch: 1  d_loss: -310.429565  g_loss: 717.922424  kl_los: 82.399338\n",
            "Elapsed [1:39:18.405262]  batch: 20  d_loss: -275.956543  g_loss: 807.715576  kl_los: 82.495407\n",
            "Time taken for epoch: 33.956 secs\n",
            "\n",
            "Epoch: 48\n",
            "Elapsed [1:39:22.159337]  batch: 1  d_loss: -290.368591  g_loss: 788.138916  kl_los: 82.434196\n",
            "Elapsed [1:39:52.444722]  batch: 20  d_loss: -201.058868  g_loss: 513.946594  kl_los: 82.515846\n",
            "Time taken for epoch: 34.031 secs\n",
            "\n",
            "Epoch: 49\n",
            "Elapsed [1:39:56.536765]  batch: 1  d_loss: -303.409851  g_loss: 849.587952  kl_los: 82.509148\n",
            "Elapsed [1:40:26.877113]  batch: 20  d_loss: -250.270294  g_loss: 456.929230  kl_los: 82.395554\n",
            "Time taken for epoch: 34.406 secs\n",
            "\n",
            "Epoch: 50\n",
            "Elapsed [1:40:30.736169]  batch: 1  d_loss: -295.328094  g_loss: 719.591858  kl_los: 82.424240\n",
            "Elapsed [1:41:01.019707]  batch: 20  d_loss: -282.233185  g_loss: 492.524689  kl_los: 82.212410\n",
            "Time taken for epoch: 34.143 secs\n",
            "\n",
            "Epoch: 51\n",
            "Elapsed [1:41:05.049159]  batch: 1  d_loss: -308.060852  g_loss: 749.374146  kl_los: 82.272018\n",
            "Elapsed [1:41:35.348150]  batch: 20  d_loss: -260.572052  g_loss: 485.192291  kl_los: 82.229980\n",
            "Time taken for epoch: 34.164 secs\n",
            "\n",
            "Epoch: 52\n",
            "Elapsed [1:41:39.183547]  batch: 1  d_loss: -274.507446  g_loss: 723.941345  kl_los: 82.211876\n",
            "Elapsed [1:42:09.536816]  batch: 20  d_loss: -300.058746  g_loss: 478.013489  kl_los: 82.159752\n",
            "Time taken for epoch: 34.172 secs\n",
            "\n",
            "Epoch: 53\n",
            "Elapsed [1:42:13.401732]  batch: 1  d_loss: -283.693024  g_loss: 884.589783  kl_los: 82.136650\n",
            "Elapsed [1:42:43.716603]  batch: 20  d_loss: -363.576080  g_loss: 814.953491  kl_los: 82.201996\n",
            "Time taken for epoch: 34.145 secs\n",
            "\n",
            "Epoch: 54\n",
            "Elapsed [1:42:47.601874]  batch: 1  d_loss: -319.097443  g_loss: 749.113525  kl_los: 82.253784\n",
            "Elapsed [1:43:18.003551]  batch: 20  d_loss: -178.560760  g_loss: 405.930664  kl_los: 82.317131\n",
            "Time taken for epoch: 34.301 secs\n",
            "\n",
            "Epoch: 55\n",
            "Elapsed [1:43:21.680751]  batch: 1  d_loss: -225.081955  g_loss: 646.777222  kl_los: 82.468155\n",
            "Elapsed [1:43:52.093203]  batch: 20  d_loss: -343.436310  g_loss: 973.934326  kl_los: 82.399887\n",
            "Time taken for epoch: 34.085 secs\n",
            "\n",
            "Epoch: 56\n",
            "Elapsed [1:43:55.819314]  batch: 1  d_loss: -425.843872  g_loss: 921.246277  kl_los: 82.454712\n",
            "Elapsed [1:44:26.141419]  batch: 20  d_loss: -299.778259  g_loss: 655.818054  kl_los: 82.624886\n",
            "Time taken for epoch: 34.043 secs\n",
            "\n",
            "Epoch: 57\n",
            "Elapsed [1:44:30.071773]  batch: 1  d_loss: -308.684540  g_loss: 576.430847  kl_los: 82.656433\n",
            "Elapsed [1:45:00.235611]  batch: 20  d_loss: -341.307495  g_loss: 720.791931  kl_los: 82.529518\n",
            "Time taken for epoch: 34.108 secs\n",
            "\n",
            "Epoch: 58\n",
            "Elapsed [1:45:03.993572]  batch: 1  d_loss: -333.013000  g_loss: 754.910522  kl_los: 82.520676\n",
            "Elapsed [1:45:34.317287]  batch: 20  d_loss: -165.475098  g_loss: 869.902649  kl_los: 82.507637\n",
            "Time taken for epoch: 34.106 secs\n",
            "\n",
            "Epoch: 59\n",
            "Elapsed [1:45:38.269806]  batch: 1  d_loss: -270.430115  g_loss: 409.169403  kl_los: 82.724258\n",
            "Elapsed [1:46:08.596400]  batch: 20  d_loss: -290.841095  g_loss: 366.725677  kl_los: 82.370697\n",
            "Time taken for epoch: 34.241 secs\n",
            "\n",
            "Epoch: 60\n",
            "Elapsed [1:46:12.395293]  batch: 1  d_loss: -242.722717  g_loss: 786.125977  kl_los: 82.423790\n",
            "Elapsed [1:46:42.703216]  batch: 20  d_loss: -218.847549  g_loss: 829.242737  kl_los: 82.439911\n",
            "Time taken for epoch: 34.124 secs\n",
            "\n",
            "Epoch: 61\n",
            "Elapsed [1:46:47.020728]  batch: 1  d_loss: -364.131287  g_loss: 688.552734  kl_los: 82.436310\n",
            "Elapsed [1:47:17.376800]  batch: 20  d_loss: -381.357666  g_loss: 758.138977  kl_los: 82.541504\n",
            "Time taken for epoch: 34.474 secs\n",
            "\n",
            "Epoch: 62\n",
            "Elapsed [1:47:21.240571]  batch: 1  d_loss: -344.122711  g_loss: 629.326050  kl_los: 82.534912\n",
            "Elapsed [1:47:51.565207]  batch: 20  d_loss: -372.773468  g_loss: 711.485046  kl_los: 82.645348\n",
            "Time taken for epoch: 34.201 secs\n",
            "\n",
            "Epoch: 63\n",
            "Elapsed [1:47:55.361849]  batch: 1  d_loss: -347.188385  g_loss: 706.287720  kl_los: 82.581863\n",
            "Elapsed [1:48:25.741296]  batch: 20  d_loss: -259.696228  g_loss: 563.916748  kl_los: 82.649055\n",
            "Time taken for epoch: 34.123 secs\n",
            "\n",
            "Epoch: 64\n",
            "Elapsed [1:48:29.577209]  batch: 1  d_loss: -218.169052  g_loss: 736.849915  kl_los: 82.568298\n",
            "Elapsed [1:48:59.938720]  batch: 20  d_loss: -362.531921  g_loss: 795.882812  kl_los: 82.670540\n",
            "Time taken for epoch: 34.194 secs\n",
            "\n",
            "Epoch: 65\n",
            "Elapsed [1:49:03.731205]  batch: 1  d_loss: -310.382111  g_loss: 493.379974  kl_los: 82.688644\n",
            "Elapsed [1:49:34.042875]  batch: 20  d_loss: -343.154938  g_loss: 714.564270  kl_los: 82.628242\n",
            "Time taken for epoch: 34.117 secs\n",
            "\n",
            "Epoch: 66\n",
            "Elapsed [1:49:37.682830]  batch: 1  d_loss: -333.863770  g_loss: 538.496277  kl_los: 82.614670\n",
            "Elapsed [1:50:07.994365]  batch: 20  d_loss: -362.695618  g_loss: 851.941040  kl_los: 82.550911\n",
            "Time taken for epoch: 33.950 secs\n",
            "\n",
            "Epoch: 67\n",
            "Elapsed [1:50:11.655317]  batch: 1  d_loss: -320.697510  g_loss: 811.807190  kl_los: 82.650269\n",
            "Elapsed [1:50:42.008056]  batch: 20  d_loss: -135.630585  g_loss: 462.069214  kl_los: 82.769958\n",
            "Time taken for epoch: 34.001 secs\n",
            "\n",
            "Epoch: 68\n",
            "Elapsed [1:50:45.746221]  batch: 1  d_loss: -310.022644  g_loss: 839.079041  kl_los: 82.876343\n",
            "Elapsed [1:51:16.057036]  batch: 20  d_loss: -290.823547  g_loss: 693.203247  kl_los: 82.953148\n",
            "Time taken for epoch: 34.080 secs\n",
            "\n",
            "Epoch: 69\n",
            "Elapsed [1:51:19.801273]  batch: 1  d_loss: -323.916870  g_loss: 900.270264  kl_los: 82.990059\n",
            "Elapsed [1:51:50.112576]  batch: 20  d_loss: -360.132019  g_loss: 690.776245  kl_los: 82.940979\n",
            "Time taken for epoch: 34.040 secs\n",
            "\n",
            "Epoch: 70\n",
            "Elapsed [1:51:53.957021]  batch: 1  d_loss: -323.183777  g_loss: 720.934509  kl_los: 82.773994\n",
            "Elapsed [1:52:24.294603]  batch: 20  d_loss: -383.949768  g_loss: 716.293335  kl_los: 82.761215\n",
            "Time taken for epoch: 34.195 secs\n",
            "\n",
            "Epoch: 71\n",
            "Elapsed [1:52:28.439724]  batch: 1  d_loss: -378.797119  g_loss: 689.887817  kl_los: 82.821991\n",
            "Elapsed [1:52:58.768050]  batch: 20  d_loss: -347.968018  g_loss: 833.502441  kl_los: 83.527473\n",
            "Time taken for epoch: 34.237 secs\n",
            "\n",
            "Epoch: 72\n",
            "Elapsed [1:53:02.683122]  batch: 1  d_loss: -301.981079  g_loss: 437.904633  kl_los: 82.773849\n",
            "Elapsed [1:53:32.961655]  batch: 20  d_loss: -222.252380  g_loss: 234.692368  kl_los: 82.745583\n",
            "Time taken for epoch: 34.193 secs\n",
            "\n",
            "Epoch: 73\n",
            "Elapsed [1:53:36.694434]  batch: 1  d_loss: -163.537552  g_loss: 635.480469  kl_los: 82.749489\n",
            "Elapsed [1:54:07.078491]  batch: 20  d_loss: -341.985596  g_loss: 517.609924  kl_los: 82.750366\n",
            "Time taken for epoch: 34.154 secs\n",
            "\n",
            "Epoch: 74\n",
            "Elapsed [1:54:10.852098]  batch: 1  d_loss: -348.053711  g_loss: 854.976624  kl_los: 82.691086\n",
            "Elapsed [1:54:41.224401]  batch: 20  d_loss: -346.790833  g_loss: 595.261902  kl_los: 82.645279\n",
            "Time taken for epoch: 34.106 secs\n",
            "\n",
            "Epoch: 75\n",
            "Elapsed [1:54:45.124203]  batch: 1  d_loss: -354.377380  g_loss: 741.200073  kl_los: 82.724617\n",
            "Elapsed [1:55:15.362324]  batch: 20  d_loss: -377.181213  g_loss: 601.164612  kl_los: 82.698128\n",
            "Time taken for epoch: 34.167 secs\n",
            "\n",
            "Epoch: 76\n",
            "Elapsed [1:55:19.238375]  batch: 1  d_loss: -278.309265  g_loss: 777.535645  kl_los: 82.753479\n",
            "Elapsed [1:55:49.623657]  batch: 20  d_loss: -342.836121  g_loss: 847.977905  kl_los: 82.718231\n",
            "Time taken for epoch: 34.260 secs\n",
            "\n",
            "Epoch: 77\n",
            "Elapsed [1:55:53.479738]  batch: 1  d_loss: -348.146942  g_loss: 547.249390  kl_los: 82.752014\n",
            "Elapsed [1:56:23.800616]  batch: 20  d_loss: -357.858337  g_loss: 969.386902  kl_los: 82.788322\n",
            "Time taken for epoch: 34.172 secs\n",
            "\n",
            "Epoch: 78\n",
            "Elapsed [1:56:27.598180]  batch: 1  d_loss: -261.112244  g_loss: 493.759827  kl_los: 82.706886\n",
            "Elapsed [1:56:57.858642]  batch: 20  d_loss: -294.474365  g_loss: 379.420349  kl_los: 82.667740\n",
            "Time taken for epoch: 34.036 secs\n",
            "\n",
            "Epoch: 79\n",
            "Elapsed [1:57:01.686575]  batch: 1  d_loss: -267.169891  g_loss: 917.433350  kl_los: 82.882416\n",
            "Elapsed [1:57:32.103007]  batch: 20  d_loss: -312.375153  g_loss: 886.336914  kl_los: 83.021690\n",
            "Time taken for epoch: 34.244 secs\n",
            "\n",
            "Epoch: 80\n",
            "Elapsed [1:57:35.861327]  batch: 1  d_loss: -399.971466  g_loss: 778.347351  kl_los: 82.938858\n",
            "Elapsed [1:58:06.183353]  batch: 20  d_loss: -391.660034  g_loss: 750.297546  kl_los: 83.999504\n",
            "Time taken for epoch: 34.098 secs\n",
            "\n",
            "Epoch: 81\n",
            "Elapsed [1:58:10.328608]  batch: 1  d_loss: -344.403931  g_loss: 667.074036  kl_los: 83.082001\n",
            "Elapsed [1:58:40.643718]  batch: 20  d_loss: -340.013794  g_loss: 799.519714  kl_los: 83.197395\n",
            "Time taken for epoch: 34.220 secs\n",
            "\n",
            "Epoch: 82\n",
            "Elapsed [1:58:44.490712]  batch: 1  d_loss: -414.511719  g_loss: 851.609253  kl_los: 83.050735\n",
            "Elapsed [1:59:14.813557]  batch: 20  d_loss: -285.197357  g_loss: 868.384033  kl_los: 83.212051\n",
            "Time taken for epoch: 34.169 secs\n",
            "\n",
            "Epoch: 83\n",
            "Elapsed [1:59:18.529150]  batch: 1  d_loss: -345.345490  g_loss: 543.728760  kl_los: 83.218170\n",
            "Elapsed [1:59:48.861648]  batch: 20  d_loss: -352.338257  g_loss: 410.235321  kl_los: 83.047623\n",
            "Time taken for epoch: 34.047 secs\n",
            "\n",
            "Epoch: 84\n",
            "Elapsed [1:59:52.794249]  batch: 1  d_loss: -275.920410  g_loss: 867.368652  kl_los: 83.085197\n",
            "Elapsed [2:00:23.078230]  batch: 20  d_loss: -354.726959  g_loss: 594.713257  kl_los: 83.138313\n",
            "Time taken for epoch: 34.286 secs\n",
            "\n",
            "Epoch: 85\n",
            "Elapsed [2:00:26.789119]  batch: 1  d_loss: -375.837250  g_loss: 811.946533  kl_los: 83.113510\n",
            "Elapsed [2:00:57.190695]  batch: 20  d_loss: -367.457275  g_loss: 716.100037  kl_los: 83.052650\n",
            "Time taken for epoch: 34.041 secs\n",
            "\n",
            "Epoch: 86\n",
            "Elapsed [2:01:01.028308]  batch: 1  d_loss: -293.186340  g_loss: 727.274658  kl_los: 83.221642\n",
            "Elapsed [2:01:31.403286]  batch: 20  d_loss: -286.798737  g_loss: 852.215393  kl_los: 83.239098\n",
            "Time taken for epoch: 34.211 secs\n",
            "\n",
            "Epoch: 87\n",
            "Elapsed [2:01:35.189234]  batch: 1  d_loss: -331.597626  g_loss: 533.586670  kl_los: 83.266068\n",
            "Elapsed [2:02:05.547043]  batch: 20  d_loss: -325.946228  g_loss: 742.587463  kl_los: 83.317139\n",
            "Time taken for epoch: 34.146 secs\n",
            "\n",
            "Epoch: 88\n",
            "Elapsed [2:02:09.494378]  batch: 1  d_loss: -342.544189  g_loss: 655.982056  kl_los: 83.358917\n",
            "Elapsed [2:02:39.845554]  batch: 20  d_loss: -306.334595  g_loss: 908.780518  kl_los: 83.566795\n",
            "Time taken for epoch: 34.343 secs\n",
            "\n",
            "Epoch: 89\n",
            "Elapsed [2:02:43.760986]  batch: 1  d_loss: -405.345642  g_loss: 775.968201  kl_los: 83.582504\n",
            "Elapsed [2:03:14.060307]  batch: 20  d_loss: -217.071838  g_loss: 827.625000  kl_los: 83.501411\n",
            "Time taken for epoch: 34.176 secs\n",
            "\n",
            "Epoch: 90\n",
            "Elapsed [2:03:17.801630]  batch: 1  d_loss: -312.125244  g_loss: 503.950287  kl_los: 83.560516\n",
            "Elapsed [2:03:48.179470]  batch: 20  d_loss: -339.271851  g_loss: 689.829102  kl_los: 83.489761\n",
            "Time taken for epoch: 34.136 secs\n",
            "\n",
            "Epoch: 91\n",
            "Elapsed [2:03:52.207850]  batch: 1  d_loss: -296.036072  g_loss: 725.539795  kl_los: 83.473755\n",
            "Elapsed [2:04:22.536468]  batch: 20  d_loss: -321.189484  g_loss: 575.965027  kl_los: 83.626144\n",
            "Time taken for epoch: 34.134 secs\n",
            "\n",
            "Epoch: 92\n",
            "Elapsed [2:04:26.475399]  batch: 1  d_loss: -327.261017  g_loss: 757.008911  kl_los: 83.503357\n",
            "Elapsed [2:04:56.808293]  batch: 20  d_loss: -336.436462  g_loss: 564.311401  kl_los: 83.824257\n",
            "Time taken for epoch: 34.260 secs\n",
            "\n",
            "Epoch: 93\n",
            "Elapsed [2:05:00.685735]  batch: 1  d_loss: -271.314941  g_loss: 703.488403  kl_los: 83.618828\n",
            "Elapsed [2:05:30.961794]  batch: 20  d_loss: -277.237946  g_loss: 481.609283  kl_los: 83.572975\n",
            "Time taken for epoch: 34.151 secs\n",
            "\n",
            "Epoch: 94\n",
            "Elapsed [2:05:34.730642]  batch: 1  d_loss: -294.990723  g_loss: 849.771362  kl_los: 83.539436\n",
            "Elapsed [2:06:05.075283]  batch: 20  d_loss: -346.061554  g_loss: 784.684143  kl_los: 83.456024\n",
            "Time taken for epoch: 34.101 secs\n",
            "\n",
            "Epoch: 95\n",
            "Elapsed [2:06:08.758683]  batch: 1  d_loss: -309.633270  g_loss: 562.606689  kl_los: 83.466682\n",
            "Elapsed [2:06:39.121057]  batch: 20  d_loss: -360.488770  g_loss: 747.160278  kl_los: 83.667557\n",
            "Time taken for epoch: 34.039 secs\n",
            "\n",
            "Epoch: 96\n",
            "Elapsed [2:06:42.883902]  batch: 1  d_loss: -312.619568  g_loss: 687.531616  kl_los: 83.628868\n",
            "Elapsed [2:07:13.211082]  batch: 20  d_loss: -345.451019  g_loss: 663.751404  kl_los: 83.389595\n",
            "Time taken for epoch: 34.124 secs\n",
            "\n",
            "Epoch: 97\n",
            "Elapsed [2:07:16.999747]  batch: 1  d_loss: -288.695129  g_loss: 647.669189  kl_los: 83.384460\n",
            "Elapsed [2:07:47.307732]  batch: 20  d_loss: -324.021454  g_loss: 790.430908  kl_los: 83.509071\n",
            "Time taken for epoch: 34.117 secs\n",
            "\n",
            "Epoch: 98\n",
            "Elapsed [2:07:51.080275]  batch: 1  d_loss: -280.846375  g_loss: 647.644409  kl_los: 83.496216\n",
            "Elapsed [2:08:21.412663]  batch: 20  d_loss: -356.302490  g_loss: 648.575378  kl_los: 83.501961\n",
            "Time taken for epoch: 34.083 secs\n",
            "\n",
            "Epoch: 99\n",
            "Elapsed [2:08:25.325849]  batch: 1  d_loss: -307.995850  g_loss: 673.141418  kl_los: 83.491455\n",
            "Elapsed [2:08:55.671984]  batch: 20  d_loss: -210.046387  g_loss: 754.471252  kl_los: 83.350510\n",
            "Time taken for epoch: 34.232 secs\n",
            "\n",
            "Epoch: 100\n",
            "Elapsed [2:08:59.499703]  batch: 1  d_loss: -311.184113  g_loss: 566.904907  kl_los: 83.347473\n",
            "Elapsed [2:09:29.819827]  batch: 20  d_loss: -263.165588  g_loss: 619.023132  kl_los: 83.251831\n",
            "Time taken for epoch: 34.186 secs\n",
            "\n",
            "Epoch: 101\n",
            "Elapsed [2:09:33.708738]  batch: 1  d_loss: -372.380371  g_loss: 787.077515  kl_los: 83.382530\n",
            "Elapsed [2:10:04.047069]  batch: 20  d_loss: -323.971588  g_loss: 711.341187  kl_los: 83.488701\n",
            "Time taken for epoch: 34.044 secs\n",
            "\n",
            "Epoch: 102\n",
            "Elapsed [2:10:07.775871]  batch: 1  d_loss: -240.232758  g_loss: 670.937256  kl_los: 83.371307\n",
            "Elapsed [2:10:38.118162]  batch: 20  d_loss: -315.910004  g_loss: 570.601440  kl_los: 83.239388\n",
            "Time taken for epoch: 34.016 secs\n",
            "\n",
            "Epoch: 103\n",
            "Elapsed [2:10:42.032776]  batch: 1  d_loss: -283.981720  g_loss: 789.837524  kl_los: 83.605537\n",
            "Elapsed [2:11:12.377274]  batch: 20  d_loss: -242.499283  g_loss: 816.364624  kl_los: 83.444427\n",
            "Time taken for epoch: 34.297 secs\n",
            "\n",
            "Epoch: 104\n",
            "Elapsed [2:11:16.141085]  batch: 1  d_loss: -330.658569  g_loss: 544.652954  kl_los: 83.403572\n",
            "Elapsed [2:11:46.478498]  batch: 20  d_loss: -332.280273  g_loss: 695.983948  kl_los: 83.288666\n",
            "Time taken for epoch: 34.062 secs\n",
            "\n",
            "Epoch: 105\n",
            "Elapsed [2:11:50.202782]  batch: 1  d_loss: -277.196716  g_loss: 567.197815  kl_los: 83.323746\n",
            "Elapsed [2:12:20.507300]  batch: 20  d_loss: -302.851288  g_loss: 684.052185  kl_los: 83.152878\n",
            "Time taken for epoch: 34.065 secs\n",
            "\n",
            "Epoch: 106\n",
            "Elapsed [2:12:24.235834]  batch: 1  d_loss: -335.214111  g_loss: 629.477295  kl_los: 83.339813\n",
            "Elapsed [2:12:54.583737]  batch: 20  d_loss: -340.153320  g_loss: 654.097778  kl_los: 83.204651\n",
            "Time taken for epoch: 34.046 secs\n",
            "\n",
            "Epoch: 107\n",
            "Elapsed [2:12:57.844175]  batch: 1  d_loss: -350.654083  g_loss: 836.860107  kl_los: 83.320145\n",
            "Elapsed [2:13:28.190992]  batch: 20  d_loss: -318.833344  g_loss: 584.962280  kl_los: 83.200943\n",
            "Time taken for epoch: 33.645 secs\n",
            "\n",
            "Epoch: 108\n",
            "Elapsed [2:13:32.023738]  batch: 1  d_loss: -327.999573  g_loss: 705.447388  kl_los: 83.298141\n",
            "Elapsed [2:14:02.312764]  batch: 20  d_loss: -330.778046  g_loss: 750.070435  kl_los: 83.351784\n",
            "Time taken for epoch: 34.123 secs\n",
            "\n",
            "Epoch: 109\n",
            "Elapsed [2:14:06.320451]  batch: 1  d_loss: -343.279907  g_loss: 680.540161  kl_los: 83.329391\n",
            "Elapsed [2:14:36.703173]  batch: 20  d_loss: -333.185974  g_loss: 639.993286  kl_los: 83.424316\n",
            "Time taken for epoch: 34.348 secs\n",
            "\n",
            "Epoch: 110\n",
            "Elapsed [2:14:40.553329]  batch: 1  d_loss: -317.434387  g_loss: 700.485107  kl_los: 83.336609\n",
            "Elapsed [2:15:10.968865]  batch: 20  d_loss: -297.886658  g_loss: 784.791321  kl_los: 83.406120\n",
            "Time taken for epoch: 34.284 secs\n",
            "\n",
            "Epoch: 111\n",
            "Elapsed [2:15:14.975681]  batch: 1  d_loss: -301.167358  g_loss: 588.477539  kl_los: 83.530128\n",
            "Elapsed [2:15:45.294593]  batch: 20  d_loss: -316.134125  g_loss: 525.799683  kl_los: 83.189545\n",
            "Time taken for epoch: 34.107 secs\n",
            "\n",
            "Epoch: 112\n",
            "Elapsed [2:15:48.959804]  batch: 1  d_loss: -284.166138  g_loss: 797.777893  kl_los: 83.508385\n",
            "Elapsed [2:16:19.228232]  batch: 20  d_loss: -292.339752  g_loss: 483.021301  kl_los: 83.188148\n",
            "Time taken for epoch: 33.966 secs\n",
            "\n",
            "Epoch: 113\n",
            "Elapsed [2:16:23.014812]  batch: 1  d_loss: -295.932739  g_loss: 763.459656  kl_los: 83.248688\n",
            "Elapsed [2:16:53.400429]  batch: 20  d_loss: -322.155731  g_loss: 530.486267  kl_los: 83.060318\n",
            "Time taken for epoch: 34.158 secs\n",
            "\n",
            "Epoch: 114\n",
            "Elapsed [2:16:57.171514]  batch: 1  d_loss: -315.189484  g_loss: 734.503235  kl_los: 83.122902\n",
            "Elapsed [2:17:27.482337]  batch: 20  d_loss: -384.113342  g_loss: 635.635193  kl_los: 83.168854\n",
            "Time taken for epoch: 34.105 secs\n",
            "\n",
            "Epoch: 115\n",
            "Elapsed [2:17:31.426363]  batch: 1  d_loss: -333.238281  g_loss: 624.965637  kl_los: 83.107986\n",
            "Elapsed [2:18:01.758387]  batch: 20  d_loss: -246.325409  g_loss: 507.493439  kl_los: 83.237610\n",
            "Time taken for epoch: 34.286 secs\n",
            "\n",
            "Epoch: 116\n",
            "Elapsed [2:18:05.854737]  batch: 1  d_loss: -205.426224  g_loss: 676.134827  kl_los: 83.488464\n",
            "Elapsed [2:18:36.043222]  batch: 20  d_loss: -261.236938  g_loss: 450.564178  kl_los: 83.053886\n",
            "Time taken for epoch: 34.246 secs\n",
            "\n",
            "Epoch: 117\n",
            "Elapsed [2:18:39.790825]  batch: 1  d_loss: -211.071899  g_loss: 812.450317  kl_los: 83.463303\n",
            "Elapsed [2:19:10.082254]  batch: 20  d_loss: -352.131042  g_loss: 822.311462  kl_los: 83.178291\n",
            "Time taken for epoch: 34.053 secs\n",
            "\n",
            "Epoch: 118\n",
            "Elapsed [2:19:13.958769]  batch: 1  d_loss: -307.229645  g_loss: 459.153595  kl_los: 83.224510\n",
            "Elapsed [2:19:44.271429]  batch: 20  d_loss: -339.078766  g_loss: 899.803040  kl_los: 83.263893\n",
            "Time taken for epoch: 34.172 secs\n",
            "\n",
            "Epoch: 119\n",
            "Elapsed [2:19:48.192880]  batch: 1  d_loss: -271.514709  g_loss: 418.975250  kl_los: 83.211319\n",
            "Elapsed [2:20:18.473843]  batch: 20  d_loss: -327.880676  g_loss: 797.511475  kl_los: 83.340332\n",
            "Time taken for epoch: 34.228 secs\n",
            "\n",
            "Epoch: 120\n",
            "Elapsed [2:20:22.149127]  batch: 1  d_loss: -306.934784  g_loss: 525.791748  kl_los: 83.303383\n",
            "Elapsed [2:20:52.501720]  batch: 20  d_loss: -271.647980  g_loss: 703.581665  kl_los: 83.210358\n",
            "Time taken for epoch: 33.999 secs\n",
            "\n",
            "\n",
            "Currently working on Depth:  4\n",
            "Current resolution: 64 x 64\n",
            "\n",
            "Epoch: 1\n",
            "Elapsed [2:21:07.792002]  batch: 1  d_loss: -337.397217  g_loss: 590.981567  kl_los: 83.184708\n",
            "Elapsed [2:22:31.571186]  batch: 39  d_loss: -333.479584  g_loss: 562.743713  kl_los: 83.544548\n",
            "Time taken for epoch: 98.988 secs\n",
            "\n",
            "Epoch: 2\n",
            "Elapsed [2:22:35.257226]  batch: 1  d_loss: -428.418518  g_loss: 981.321838  kl_los: 83.458923\n",
            "Elapsed [2:23:49.195498]  batch: 39  d_loss: -377.588013  g_loss: 708.671631  kl_los: 83.820450\n",
            "Time taken for epoch: 77.602 secs\n",
            "\n",
            "Epoch: 3\n",
            "Elapsed [2:23:52.946836]  batch: 1  d_loss: -493.355133  g_loss: 1229.449707  kl_los: 83.734955\n",
            "Elapsed [2:25:06.773632]  batch: 39  d_loss: -374.318359  g_loss: 714.333801  kl_los: 83.993874\n",
            "Time taken for epoch: 77.631 secs\n",
            "\n",
            "Epoch: 4\n",
            "Elapsed [2:25:10.477366]  batch: 1  d_loss: -422.629944  g_loss: 848.080872  kl_los: 83.885727\n",
            "Elapsed [2:26:24.304696]  batch: 39  d_loss: -345.384064  g_loss: 584.183289  kl_los: 83.846008\n",
            "Time taken for epoch: 77.513 secs\n",
            "\n",
            "Epoch: 5\n",
            "Elapsed [2:26:28.125097]  batch: 1  d_loss: -335.383911  g_loss: 775.436768  kl_los: 84.026016\n",
            "Elapsed [2:27:41.931314]  batch: 39  d_loss: -425.675690  g_loss: 1041.153320  kl_los: 83.740677\n",
            "Time taken for epoch: 77.629 secs\n",
            "\n",
            "Epoch: 6\n",
            "Elapsed [2:27:45.544581]  batch: 1  d_loss: -364.500183  g_loss: 746.009094  kl_los: 83.684814\n",
            "Elapsed [2:28:59.396990]  batch: 39  d_loss: -261.339691  g_loss: 616.690186  kl_los: 84.188934\n",
            "Time taken for epoch: 77.460 secs\n",
            "\n",
            "Epoch: 7\n",
            "Elapsed [2:29:03.068837]  batch: 1  d_loss: -530.585022  g_loss: 1350.037354  kl_los: 84.112236\n",
            "Elapsed [2:30:16.867051]  batch: 39  d_loss: -397.655640  g_loss: 1055.521973  kl_los: 84.008492\n",
            "Time taken for epoch: 77.470 secs\n",
            "\n",
            "Epoch: 8\n",
            "Elapsed [2:30:20.432760]  batch: 1  d_loss: -394.196930  g_loss: 519.734253  kl_los: 83.768036\n",
            "Elapsed [2:31:34.399328]  batch: 39  d_loss: -344.947174  g_loss: 957.421875  kl_los: 83.662918\n",
            "Time taken for epoch: 77.531 secs\n",
            "\n",
            "Epoch: 9\n",
            "Elapsed [2:31:38.171452]  batch: 1  d_loss: -722.754517  g_loss: 1349.330688  kl_los: 83.818748\n",
            "Elapsed [2:32:51.986712]  batch: 39  d_loss: -394.029846  g_loss: 913.414551  kl_los: 83.935715\n",
            "Time taken for epoch: 77.588 secs\n",
            "\n",
            "Epoch: 10\n",
            "Elapsed [2:32:55.710394]  batch: 1  d_loss: -416.091644  g_loss: 572.811890  kl_los: 83.909576\n",
            "Elapsed [2:34:09.481470]  batch: 39  d_loss: -303.253082  g_loss: 842.493103  kl_los: 83.914719\n",
            "Time taken for epoch: 77.497 secs\n",
            "\n",
            "Epoch: 11\n",
            "Elapsed [2:34:13.419516]  batch: 1  d_loss: -428.372009  g_loss: 945.579224  kl_los: 84.007599\n",
            "Elapsed [2:35:27.356342]  batch: 39  d_loss: -433.419067  g_loss: 1141.067749  kl_los: 84.116692\n",
            "Time taken for epoch: 77.653 secs\n",
            "\n",
            "Epoch: 12\n",
            "Elapsed [2:35:31.137026]  batch: 1  d_loss: -556.846680  g_loss: 750.691406  kl_los: 84.078979\n",
            "Elapsed [2:36:45.002373]  batch: 39  d_loss: -449.098145  g_loss: 621.230591  kl_los: 84.105194\n",
            "Time taken for epoch: 77.649 secs\n",
            "\n",
            "Epoch: 13\n",
            "Elapsed [2:36:48.688677]  batch: 1  d_loss: -391.980652  g_loss: 1396.176025  kl_los: 84.148514\n",
            "Elapsed [2:38:02.589083]  batch: 39  d_loss: -383.393921  g_loss: 590.816345  kl_los: 84.454048\n",
            "Time taken for epoch: 77.604 secs\n",
            "\n",
            "Epoch: 14\n",
            "Elapsed [2:38:06.281124]  batch: 1  d_loss: -187.274460  g_loss: 837.204895  kl_los: 84.616623\n",
            "Elapsed [2:39:20.078756]  batch: 39  d_loss: -396.515991  g_loss: 664.373962  kl_los: 84.486832\n",
            "Time taken for epoch: 77.475 secs\n",
            "\n",
            "Epoch: 15\n",
            "Elapsed [2:39:23.817862]  batch: 1  d_loss: -374.318451  g_loss: 972.902832  kl_los: 84.419479\n",
            "Elapsed [2:40:37.625051]  batch: 39  d_loss: -426.113342  g_loss: 800.902893  kl_los: 84.501045\n",
            "Time taken for epoch: 77.549 secs\n",
            "\n",
            "Epoch: 16\n",
            "Elapsed [2:40:41.201758]  batch: 1  d_loss: -410.809631  g_loss: 946.736694  kl_los: 84.491501\n",
            "Elapsed [2:41:55.062637]  batch: 39  d_loss: -461.441833  g_loss: 1123.185669  kl_los: 84.810417\n",
            "Time taken for epoch: 77.477 secs\n",
            "\n",
            "Epoch: 17\n",
            "Elapsed [2:41:58.871691]  batch: 1  d_loss: -686.728210  g_loss: 1266.172729  kl_los: 84.628098\n",
            "Elapsed [2:43:13.075125]  batch: 39  d_loss: -576.697021  g_loss: 1519.625732  kl_los: 84.772812\n",
            "Time taken for epoch: 78.005 secs\n",
            "\n",
            "Epoch: 18\n",
            "Elapsed [2:43:16.908062]  batch: 1  d_loss: -499.470978  g_loss: 965.239746  kl_los: 84.970718\n",
            "Elapsed [2:44:30.974860]  batch: 39  d_loss: -359.403381  g_loss: 635.941406  kl_los: 84.807953\n",
            "Time taken for epoch: 77.879 secs\n",
            "\n",
            "Epoch: 19\n",
            "Elapsed [2:44:34.678319]  batch: 1  d_loss: -492.423645  g_loss: 1163.259033  kl_los: 84.747360\n",
            "Elapsed [2:45:48.415858]  batch: 39  d_loss: -472.550049  g_loss: 1237.853760  kl_los: 85.053207\n",
            "Time taken for epoch: 77.443 secs\n",
            "\n",
            "Epoch: 20\n",
            "Elapsed [2:45:52.229533]  batch: 1  d_loss: -474.424530  g_loss: 630.263062  kl_los: 85.155449\n",
            "Elapsed [2:47:06.010252]  batch: 39  d_loss: -486.205536  g_loss: 952.961304  kl_los: 84.924431\n",
            "Time taken for epoch: 77.580 secs\n",
            "\n",
            "Epoch: 21\n",
            "Elapsed [2:47:09.946999]  batch: 1  d_loss: -560.260498  g_loss: 1512.019531  kl_los: 84.559875\n",
            "Elapsed [2:48:23.968595]  batch: 39  d_loss: -681.748413  g_loss: 937.114441  kl_los: 84.648926\n",
            "Time taken for epoch: 77.768 secs\n",
            "\n",
            "Epoch: 22\n",
            "Elapsed [2:48:27.750071]  batch: 1  d_loss: -421.059052  g_loss: 1043.616699  kl_los: 87.055031\n",
            "Elapsed [2:49:41.638367]  batch: 39  d_loss: -460.988678  g_loss: 1328.836060  kl_los: 85.106575\n",
            "Time taken for epoch: 77.645 secs\n",
            "\n",
            "Epoch: 23\n",
            "Elapsed [2:49:45.328641]  batch: 1  d_loss: -396.798920  g_loss: 556.214478  kl_los: 85.233444\n",
            "Elapsed [2:50:59.245174]  batch: 39  d_loss: -641.454346  g_loss: 1081.335938  kl_los: 85.097298\n",
            "Time taken for epoch: 77.620 secs\n",
            "\n",
            "Epoch: 24\n",
            "Elapsed [2:51:02.976208]  batch: 1  d_loss: -778.949463  g_loss: 1298.121094  kl_los: 85.202438\n",
            "Elapsed [2:52:16.939089]  batch: 39  d_loss: -446.154419  g_loss: 574.577271  kl_los: 85.617294\n",
            "Time taken for epoch: 77.693 secs\n",
            "\n",
            "Epoch: 25\n",
            "Elapsed [2:52:20.580594]  batch: 1  d_loss: -371.107239  g_loss: 1502.009033  kl_los: 85.266495\n",
            "Elapsed [2:53:34.489249]  batch: 39  d_loss: -103.954102  g_loss: 1040.269409  kl_los: 85.745148\n",
            "Time taken for epoch: 77.543 secs\n",
            "\n",
            "Epoch: 26\n",
            "Elapsed [2:53:38.196357]  batch: 1  d_loss: -567.889404  g_loss: 1559.586914  kl_los: 87.142639\n",
            "Elapsed [2:54:51.700811]  batch: 39  d_loss: -467.945984  g_loss: 1018.884338  kl_los: 85.823517\n",
            "Time taken for epoch: 77.220 secs\n",
            "\n",
            "Epoch: 27\n",
            "Elapsed [2:54:55.224767]  batch: 1  d_loss: -510.727966  g_loss: 1090.281250  kl_los: 85.619644\n",
            "Elapsed [2:56:09.373534]  batch: 39  d_loss: -420.292542  g_loss: 1571.419312  kl_los: 85.715240\n",
            "Time taken for epoch: 77.677 secs\n",
            "\n",
            "Epoch: 28\n",
            "Elapsed [2:56:13.058013]  batch: 1  d_loss: -408.547913  g_loss: 621.366943  kl_los: 88.174095\n",
            "Elapsed [2:57:27.190368]  batch: 39  d_loss: -554.630127  g_loss: 827.213440  kl_los: 85.772026\n",
            "Time taken for epoch: 77.801 secs\n",
            "\n",
            "Epoch: 29\n",
            "Elapsed [2:57:30.853798]  batch: 1  d_loss: -479.076874  g_loss: 1364.904663  kl_los: 88.315254\n",
            "Elapsed [2:58:44.767140]  batch: 39  d_loss: -550.598267  g_loss: 1634.165527  kl_los: 85.834854\n",
            "Time taken for epoch: 77.569 secs\n",
            "\n",
            "Epoch: 30\n",
            "Elapsed [2:58:48.456890]  batch: 1  d_loss: -386.816650  g_loss: 848.380859  kl_los: 85.814926\n",
            "Elapsed [3:00:02.307418]  batch: 39  d_loss: -462.803223  g_loss: 1356.401489  kl_los: 85.813957\n",
            "Time taken for epoch: 77.545 secs\n",
            "\n",
            "Epoch: 31\n",
            "Elapsed [3:00:06.171820]  batch: 1  d_loss: -448.123779  g_loss: 684.564209  kl_los: 86.210724\n",
            "Elapsed [3:01:20.026266]  batch: 39  d_loss: -700.715271  g_loss: 2026.737793  kl_los: 86.406006\n",
            "Time taken for epoch: 77.541 secs\n",
            "\n",
            "Epoch: 32\n",
            "Elapsed [3:01:23.750805]  batch: 1  d_loss: -490.131409  g_loss: 666.312012  kl_los: 86.469734\n",
            "Elapsed [3:02:37.508493]  batch: 39  d_loss: -317.206482  g_loss: 522.384888  kl_los: 86.865448\n",
            "Time taken for epoch: 77.464 secs\n",
            "\n",
            "Epoch: 33\n",
            "Elapsed [3:02:41.198632]  batch: 1  d_loss: -324.696838  g_loss: 1328.156006  kl_los: 86.821541\n",
            "Elapsed [3:03:55.005413]  batch: 39  d_loss: -554.881775  g_loss: 1037.633057  kl_los: 86.850204\n",
            "Time taken for epoch: 77.506 secs\n",
            "\n",
            "Epoch: 34\n",
            "Elapsed [3:03:58.753710]  batch: 1  d_loss: -399.919250  g_loss: 1247.541992  kl_los: 86.869270\n",
            "Elapsed [3:05:12.555324]  batch: 39  d_loss: -432.684387  g_loss: 1188.788574  kl_los: 86.462891\n",
            "Time taken for epoch: 77.536 secs\n",
            "\n",
            "Epoch: 35\n",
            "Elapsed [3:05:16.233610]  batch: 1  d_loss: -737.275391  g_loss: 1221.308350  kl_los: 87.272720\n",
            "Elapsed [3:06:29.952555]  batch: 39  d_loss: -538.714783  g_loss: 1140.817871  kl_los: 92.238686\n",
            "Time taken for epoch: 77.404 secs\n",
            "\n",
            "Epoch: 36\n",
            "Elapsed [3:06:33.691649]  batch: 1  d_loss: -509.995544  g_loss: 774.974976  kl_los: 87.074890\n",
            "Elapsed [3:07:47.519456]  batch: 39  d_loss: -710.778931  g_loss: 1421.910767  kl_los: 86.902969\n",
            "Time taken for epoch: 77.561 secs\n",
            "\n",
            "Epoch: 37\n",
            "Elapsed [3:07:51.256794]  batch: 1  d_loss: -564.764282  g_loss: 998.502869  kl_los: 87.374344\n",
            "Elapsed [3:09:05.047772]  batch: 39  d_loss: -788.087097  g_loss: 1109.432739  kl_los: 87.700897\n",
            "Time taken for epoch: 77.530 secs\n",
            "\n",
            "Epoch: 38\n",
            "Elapsed [3:09:08.671824]  batch: 1  d_loss: -681.544617  g_loss: 2051.006592  kl_los: 86.822655\n",
            "Elapsed [3:10:22.885225]  batch: 39  d_loss: -827.827393  g_loss: 1695.103882  kl_los: 87.203255\n",
            "Time taken for epoch: 77.833 secs\n",
            "\n",
            "Epoch: 39\n",
            "Elapsed [3:10:26.366222]  batch: 1  d_loss: -801.108887  g_loss: 1491.993896  kl_los: 87.505112\n",
            "Elapsed [3:11:40.622429]  batch: 39  d_loss: -420.647095  g_loss: 780.985718  kl_los: 87.295876\n",
            "Time taken for epoch: 77.729 secs\n",
            "\n",
            "Epoch: 40\n",
            "Elapsed [3:11:44.461083]  batch: 1  d_loss: -560.526855  g_loss: 1446.833496  kl_los: 87.513008\n",
            "Elapsed [3:12:58.336451]  batch: 39  d_loss: -735.261597  g_loss: 1377.964355  kl_los: 91.514351\n",
            "Time taken for epoch: 77.705 secs\n",
            "\n",
            "Epoch: 41\n",
            "Elapsed [3:13:02.155074]  batch: 1  d_loss: -585.452942  g_loss: 1192.338013  kl_los: 87.510513\n",
            "Elapsed [3:14:16.103869]  batch: 39  d_loss: -789.452271  g_loss: 1506.799194  kl_los: 87.421761\n",
            "Time taken for epoch: 77.582 secs\n",
            "\n",
            "Epoch: 42\n",
            "Elapsed [3:14:19.755257]  batch: 1  d_loss: -705.087646  g_loss: 1269.738525  kl_los: 87.430374\n",
            "Elapsed [3:15:33.606692]  batch: 39  d_loss: -190.568054  g_loss: 1404.411621  kl_los: 87.712616\n",
            "Time taken for epoch: 77.461 secs\n",
            "\n",
            "Epoch: 43\n",
            "Elapsed [3:15:37.279760]  batch: 1  d_loss: -389.902374  g_loss: 878.681274  kl_los: 87.730118\n",
            "Elapsed [3:16:50.865479]  batch: 39  d_loss: -716.621155  g_loss: 849.573792  kl_los: 87.635735\n",
            "Time taken for epoch: 77.258 secs\n",
            "\n",
            "Epoch: 44\n",
            "Elapsed [3:16:54.536204]  batch: 1  d_loss: -426.148987  g_loss: 1289.814697  kl_los: 87.606972\n",
            "Elapsed [3:18:08.477049]  batch: 39  d_loss: -477.253204  g_loss: 1068.623779  kl_los: 87.600502\n",
            "Time taken for epoch: 77.636 secs\n",
            "\n",
            "Epoch: 45\n",
            "Elapsed [3:18:12.151196]  batch: 1  d_loss: -651.423035  g_loss: 1058.519165  kl_los: 87.641678\n",
            "Elapsed [3:19:26.104065]  batch: 39  d_loss: -422.436157  g_loss: 860.117004  kl_los: 87.956299\n",
            "Time taken for epoch: 77.592 secs\n",
            "\n",
            "Epoch: 46\n",
            "Elapsed [3:19:29.856885]  batch: 1  d_loss: -574.016663  g_loss: 1201.083252  kl_los: 88.056938\n",
            "Elapsed [3:20:43.806710]  batch: 39  d_loss: -540.785217  g_loss: 930.194397  kl_los: 88.247360\n",
            "Time taken for epoch: 77.765 secs\n",
            "\n",
            "Epoch: 47\n",
            "Elapsed [3:20:47.540552]  batch: 1  d_loss: -560.711426  g_loss: 1507.467407  kl_los: 88.212654\n",
            "Elapsed [3:22:01.448607]  batch: 39  d_loss: -572.856201  g_loss: 1950.261719  kl_los: 88.212250\n",
            "Time taken for epoch: 77.609 secs\n",
            "\n",
            "Epoch: 48\n",
            "Elapsed [3:22:05.261398]  batch: 1  d_loss: -324.089294  g_loss: 757.707336  kl_los: 88.743607\n",
            "Elapsed [3:23:19.109189]  batch: 39  d_loss: -785.743896  g_loss: 1274.067627  kl_los: 96.453720\n",
            "Time taken for epoch: 77.648 secs\n",
            "\n",
            "Epoch: 49\n",
            "Elapsed [3:23:22.899420]  batch: 1  d_loss: -580.375183  g_loss: 1697.932373  kl_los: 88.985237\n",
            "Elapsed [3:24:36.711810]  batch: 39  d_loss: -720.030701  g_loss: 1461.594116  kl_los: 88.588715\n",
            "Time taken for epoch: 77.602 secs\n",
            "\n",
            "Epoch: 50\n",
            "Elapsed [3:24:40.456628]  batch: 1  d_loss: -932.848572  g_loss: 2108.473633  kl_los: 88.583344\n",
            "Elapsed [3:25:54.275176]  batch: 39  d_loss: -216.325714  g_loss: 1247.427979  kl_los: 88.779602\n",
            "Time taken for epoch: 77.554 secs\n",
            "\n",
            "Epoch: 51\n",
            "Elapsed [3:25:58.226060]  batch: 1  d_loss: -680.287537  g_loss: 1195.601562  kl_los: 88.816673\n",
            "Elapsed [3:27:12.173834]  batch: 39  d_loss: -423.890533  g_loss: 1428.503052  kl_los: 88.038734\n",
            "Time taken for epoch: 77.678 secs\n",
            "\n",
            "Epoch: 52\n",
            "Elapsed [3:27:15.938904]  batch: 1  d_loss: -621.152710  g_loss: 1090.293945  kl_los: 88.678238\n",
            "Elapsed [3:28:29.811973]  batch: 39  d_loss: -431.955566  g_loss: 1321.374756  kl_los: 88.530418\n",
            "Time taken for epoch: 77.665 secs\n",
            "\n",
            "Epoch: 53\n",
            "Elapsed [3:28:33.479179]  batch: 1  d_loss: -750.298950  g_loss: 1330.510742  kl_los: 88.179337\n",
            "Elapsed [3:29:47.307322]  batch: 39  d_loss: -803.913025  g_loss: 2156.913086  kl_los: 88.111259\n",
            "Time taken for epoch: 77.464 secs\n",
            "\n",
            "Epoch: 54\n",
            "Elapsed [3:29:50.994488]  batch: 1  d_loss: -682.760925  g_loss: 1489.897461  kl_los: 88.977509\n",
            "Elapsed [3:31:04.848802]  batch: 39  d_loss: -587.313232  g_loss: 487.699036  kl_los: 89.122894\n",
            "Time taken for epoch: 77.574 secs\n",
            "\n",
            "Epoch: 55\n",
            "Elapsed [3:31:08.775289]  batch: 1  d_loss: -190.909790  g_loss: 1193.426514  kl_los: 88.565102\n",
            "Elapsed [3:32:22.013211]  batch: 39  d_loss: -947.059875  g_loss: 1778.662231  kl_los: 88.824532\n",
            "Time taken for epoch: 77.140 secs\n",
            "\n",
            "Epoch: 56\n",
            "Elapsed [3:32:25.595693]  batch: 1  d_loss: -485.033020  g_loss: 1588.676025  kl_los: 88.858650\n",
            "Elapsed [3:33:39.428125]  batch: 39  d_loss: -462.309357  g_loss: 1776.047119  kl_los: 89.689377\n",
            "Time taken for epoch: 77.413 secs\n",
            "\n",
            "Epoch: 57\n",
            "Elapsed [3:33:43.085739]  batch: 1  d_loss: -889.816406  g_loss: 1648.101074  kl_los: 92.592743\n",
            "Elapsed [3:34:56.991133]  batch: 39  d_loss: -571.858643  g_loss: 1506.732666  kl_los: 89.040771\n",
            "Time taken for epoch: 77.627 secs\n",
            "\n",
            "Epoch: 58\n",
            "Elapsed [3:35:00.764082]  batch: 1  d_loss: -608.593567  g_loss: 973.074036  kl_los: 88.784088\n",
            "Elapsed [3:36:14.590056]  batch: 39  d_loss: -845.644653  g_loss: 1163.103149  kl_los: 88.984177\n",
            "Time taken for epoch: 77.541 secs\n",
            "\n",
            "Epoch: 59\n",
            "Elapsed [3:36:18.305236]  batch: 1  d_loss: -390.907013  g_loss: 1196.438721  kl_los: 89.299042\n",
            "Elapsed [3:37:32.244889]  batch: 39  d_loss: -422.934143  g_loss: 1164.099243  kl_los: 89.248024\n",
            "Time taken for epoch: 77.656 secs\n",
            "\n",
            "Epoch: 60\n",
            "Elapsed [3:37:35.904768]  batch: 1  d_loss: -640.668701  g_loss: 1314.503906  kl_los: 89.065453\n",
            "Elapsed [3:38:49.688242]  batch: 39  d_loss: -415.519287  g_loss: 1212.337280  kl_los: 89.386017\n",
            "Time taken for epoch: 77.446 secs\n",
            "\n",
            "Epoch: 61\n",
            "Elapsed [3:38:53.585883]  batch: 1  d_loss: -647.072388  g_loss: 1386.488037  kl_los: 89.005096\n",
            "Elapsed [3:40:07.422937]  batch: 39  d_loss: -585.083130  g_loss: 598.778198  kl_los: 89.496658\n",
            "Time taken for epoch: 77.526 secs\n",
            "\n",
            "Epoch: 62\n",
            "Elapsed [3:40:11.191007]  batch: 1  d_loss: -216.970001  g_loss: 1241.905518  kl_los: 89.922447\n",
            "Elapsed [3:41:24.680943]  batch: 39  d_loss: -331.872986  g_loss: 1117.609375  kl_los: 90.199074\n",
            "Time taken for epoch: 77.295 secs\n",
            "\n",
            "Epoch: 63\n",
            "Elapsed [3:41:28.386311]  batch: 1  d_loss: -642.661072  g_loss: 1630.541748  kl_los: 90.330414\n",
            "Elapsed [3:42:41.727561]  batch: 39  d_loss: -603.082153  g_loss: 1124.968994  kl_los: 90.423042\n",
            "Time taken for epoch: 76.999 secs\n",
            "\n",
            "Epoch: 64\n",
            "Elapsed [3:42:45.287838]  batch: 1  d_loss: -699.115967  g_loss: 1459.468994  kl_los: 96.989563\n",
            "Elapsed [3:43:58.165700]  batch: 39  d_loss: -749.527832  g_loss: 1726.595215  kl_los: 90.898521\n",
            "Time taken for epoch: 76.447 secs\n",
            "\n",
            "Epoch: 65\n",
            "Elapsed [3:44:01.923164]  batch: 1  d_loss: -570.864563  g_loss: 1248.041016  kl_los: 90.486656\n",
            "Elapsed [3:45:14.762130]  batch: 39  d_loss: -552.655884  g_loss: 1466.690918  kl_los: 93.592720\n",
            "Time taken for epoch: 76.617 secs\n",
            "\n",
            "Epoch: 66\n",
            "Elapsed [3:45:18.378691]  batch: 1  d_loss: -726.580933  g_loss: 1312.598877  kl_los: 90.579315\n",
            "Elapsed [3:46:31.322998]  batch: 39  d_loss: -197.796677  g_loss: 782.221558  kl_los: 90.278725\n",
            "Time taken for epoch: 76.581 secs\n",
            "\n",
            "Epoch: 67\n",
            "Elapsed [3:46:35.017938]  batch: 1  d_loss: -211.761688  g_loss: 773.879089  kl_los: 90.624969\n",
            "Elapsed [3:47:47.920441]  batch: 39  d_loss: -123.940247  g_loss: 884.075562  kl_los: 90.393333\n",
            "Time taken for epoch: 76.552 secs\n",
            "\n",
            "Epoch: 68\n",
            "Elapsed [3:47:51.565625]  batch: 1  d_loss: -525.791870  g_loss: 1295.977783  kl_los: 90.807953\n",
            "Elapsed [3:49:04.593513]  batch: 39  d_loss: -898.363037  g_loss: 1404.014771  kl_los: 90.767448\n",
            "Time taken for epoch: 76.690 secs\n",
            "\n",
            "Epoch: 69\n",
            "Elapsed [3:49:08.270973]  batch: 1  d_loss: -460.244934  g_loss: 1007.497192  kl_los: 91.441849\n",
            "Elapsed [3:50:20.992280]  batch: 39  d_loss: -594.041992  g_loss: 990.534790  kl_los: 91.249809\n",
            "Time taken for epoch: 76.404 secs\n",
            "\n",
            "Epoch: 70\n",
            "Elapsed [3:50:24.700279]  batch: 1  d_loss: -538.447815  g_loss: 1973.270630  kl_los: 91.370125\n",
            "Elapsed [3:51:37.995296]  batch: 39  d_loss: -499.480469  g_loss: 1307.668701  kl_los: 91.561592\n",
            "Time taken for epoch: 76.993 secs\n",
            "\n",
            "Epoch: 71\n",
            "Elapsed [3:51:41.877774]  batch: 1  d_loss: -624.023926  g_loss: 1116.147217  kl_los: 91.101028\n",
            "Elapsed [3:52:55.103121]  batch: 39  d_loss: -169.227661  g_loss: 1051.109131  kl_los: 92.312477\n",
            "Time taken for epoch: 76.907 secs\n",
            "\n",
            "Epoch: 72\n",
            "Elapsed [3:52:58.713753]  batch: 1  d_loss: -507.655579  g_loss: 1333.164307  kl_los: 91.959152\n",
            "Elapsed [3:54:11.869025]  batch: 39  d_loss: -740.794373  g_loss: 1556.468994  kl_los: 92.139160\n",
            "Time taken for epoch: 76.787 secs\n",
            "\n",
            "Epoch: 73\n",
            "Elapsed [3:54:15.509209]  batch: 1  d_loss: -790.172852  g_loss: 1829.808105  kl_los: 92.487091\n",
            "Elapsed [3:55:28.699865]  batch: 39  d_loss: -625.207336  g_loss: 940.442932  kl_los: 91.841347\n",
            "Time taken for epoch: 76.817 secs\n",
            "\n",
            "Epoch: 74\n",
            "Elapsed [3:55:32.208730]  batch: 1  d_loss: -550.235107  g_loss: 1199.016235  kl_los: 92.076630\n",
            "Elapsed [3:56:45.431125]  batch: 39  d_loss: -264.478973  g_loss: 1529.124512  kl_los: 93.546005\n",
            "Time taken for epoch: 76.748 secs\n",
            "\n",
            "Epoch: 75\n",
            "Elapsed [3:56:49.145148]  batch: 1  d_loss: -546.737488  g_loss: 1420.240234  kl_los: 92.674202\n",
            "Elapsed [3:58:02.434359]  batch: 39  d_loss: -462.721924  g_loss: 1214.407471  kl_los: 93.293274\n",
            "Time taken for epoch: 76.970 secs\n",
            "\n",
            "Epoch: 76\n",
            "Elapsed [3:58:06.094170]  batch: 1  d_loss: -708.500854  g_loss: 1488.769043  kl_los: 92.673889\n",
            "Elapsed [3:59:19.368721]  batch: 39  d_loss: -537.651123  g_loss: 1113.686523  kl_los: 101.218651\n",
            "Time taken for epoch: 76.971 secs\n",
            "\n",
            "Epoch: 77\n",
            "Elapsed [3:59:23.149039]  batch: 1  d_loss: -709.528809  g_loss: 1692.405029  kl_los: 98.024239\n",
            "Elapsed [4:00:36.331935]  batch: 39  d_loss: -403.994659  g_loss: 770.315613  kl_los: 92.355049\n",
            "Time taken for epoch: 76.935 secs\n",
            "\n",
            "Epoch: 78\n",
            "Elapsed [4:00:39.934512]  batch: 1  d_loss: -418.420959  g_loss: 1086.350342  kl_los: 92.103935\n",
            "Elapsed [4:01:53.207875]  batch: 39  d_loss: -993.827393  g_loss: 1562.127319  kl_los: 92.447273\n",
            "Time taken for epoch: 76.879 secs\n",
            "\n",
            "Epoch: 79\n",
            "Elapsed [4:01:56.903305]  batch: 1  d_loss: -135.450134  g_loss: 677.530212  kl_los: 93.171204\n",
            "Elapsed [4:03:10.211805]  batch: 39  d_loss: -967.310181  g_loss: 2528.165527  kl_los: 93.256737\n",
            "Time taken for epoch: 77.018 secs\n",
            "\n",
            "Epoch: 80\n",
            "Elapsed [4:03:13.906117]  batch: 1  d_loss: -923.608643  g_loss: 2025.105835  kl_los: 92.979263\n",
            "Elapsed [4:04:27.125027]  batch: 39  d_loss: -628.446777  g_loss: 1147.541748  kl_los: 92.889465\n",
            "Time taken for epoch: 76.883 secs\n",
            "\n",
            "Epoch: 81\n",
            "Elapsed [4:04:31.076464]  batch: 1  d_loss: -401.433289  g_loss: 1583.603027  kl_los: 93.381332\n",
            "Elapsed [4:05:44.332510]  batch: 39  d_loss: -510.510956  g_loss: 1124.040527  kl_los: 93.830856\n",
            "Time taken for epoch: 77.012 secs\n",
            "\n",
            "Epoch: 82\n",
            "Elapsed [4:05:48.099535]  batch: 1  d_loss: -540.339844  g_loss: 1903.992920  kl_los: 93.707603\n",
            "Elapsed [4:07:01.319808]  batch: 39  d_loss: -575.666138  g_loss: 729.638428  kl_los: 92.224319\n",
            "Time taken for epoch: 77.014 secs\n",
            "\n",
            "Epoch: 83\n",
            "Elapsed [4:07:05.035890]  batch: 1  d_loss: -346.007080  g_loss: 1843.747070  kl_los: 93.390327\n",
            "Elapsed [4:08:18.203156]  batch: 39  d_loss: -434.030823  g_loss: 1160.485474  kl_los: 93.178268\n",
            "Time taken for epoch: 76.864 secs\n",
            "\n",
            "Epoch: 84\n",
            "Elapsed [4:08:21.905394]  batch: 1  d_loss: -528.402527  g_loss: 1939.595825  kl_los: 92.603828\n",
            "Elapsed [4:09:35.165971]  batch: 39  d_loss: -367.486237  g_loss: 1180.265259  kl_los: 93.201256\n",
            "Time taken for epoch: 76.948 secs\n",
            "\n",
            "Epoch: 85\n",
            "Elapsed [4:09:38.924116]  batch: 1  d_loss: -622.056885  g_loss: 1820.750854  kl_los: 93.023712\n",
            "Elapsed [4:10:52.253376]  batch: 39  d_loss: -451.450378  g_loss: 1577.658081  kl_los: 93.975052\n",
            "Time taken for epoch: 77.090 secs\n",
            "\n",
            "Epoch: 86\n",
            "Elapsed [4:10:56.002743]  batch: 1  d_loss: -499.389496  g_loss: 1259.998413  kl_los: 94.650330\n",
            "Elapsed [4:12:09.268888]  batch: 39  d_loss: -620.278809  g_loss: 1652.748535  kl_los: 93.855988\n",
            "Time taken for epoch: 77.022 secs\n",
            "\n",
            "Epoch: 87\n",
            "Elapsed [4:12:12.971057]  batch: 1  d_loss: -618.391907  g_loss: 1139.551270  kl_los: 93.586342\n",
            "Elapsed [4:13:26.191372]  batch: 39  d_loss: -509.857483  g_loss: 2073.211914  kl_los: 94.815399\n",
            "Time taken for epoch: 76.916 secs\n",
            "\n",
            "Epoch: 88\n",
            "Elapsed [4:13:29.900796]  batch: 1  d_loss: -881.610107  g_loss: 774.257751  kl_los: 94.458946\n",
            "Elapsed [4:14:43.064506]  batch: 39  d_loss: -967.721985  g_loss: 1560.455200  kl_los: 93.524628\n",
            "Time taken for epoch: 76.870 secs\n",
            "\n",
            "Epoch: 89\n",
            "Elapsed [4:14:46.691786]  batch: 1  d_loss: -885.490540  g_loss: 2477.082031  kl_los: 94.105309\n",
            "Elapsed [4:15:59.878548]  batch: 39  d_loss: -295.876160  g_loss: 1176.370728  kl_los: 93.989433\n",
            "Time taken for epoch: 76.822 secs\n",
            "\n",
            "Epoch: 90\n",
            "Elapsed [4:16:03.546721]  batch: 1  d_loss: -322.548889  g_loss: 786.084106  kl_los: 93.495186\n",
            "Elapsed [4:17:16.765117]  batch: 39  d_loss: -504.724945  g_loss: 1584.994507  kl_los: 93.626854\n",
            "Time taken for epoch: 76.889 secs\n",
            "\n",
            "Epoch: 91\n",
            "Elapsed [4:17:20.878878]  batch: 1  d_loss: -685.209656  g_loss: 1191.934326  kl_los: 94.445503\n",
            "Elapsed [4:18:34.069838]  batch: 39  d_loss: -375.016235  g_loss: 348.047455  kl_los: 94.182617\n",
            "Time taken for epoch: 77.000 secs\n",
            "\n",
            "Epoch: 92\n",
            "Elapsed [4:18:37.822870]  batch: 1  d_loss: -88.161636  g_loss: 1075.030029  kl_los: 93.432259\n",
            "Elapsed [4:19:51.109065]  batch: 39  d_loss: -602.368225  g_loss: 1605.479980  kl_los: 94.468826\n",
            "Time taken for epoch: 77.043 secs\n",
            "\n",
            "Epoch: 93\n",
            "Elapsed [4:19:54.861059]  batch: 1  d_loss: -815.111816  g_loss: 1281.013428  kl_los: 94.200882\n",
            "Elapsed [4:21:08.105760]  batch: 39  d_loss: -410.363312  g_loss: 942.957397  kl_los: 93.760475\n",
            "Time taken for epoch: 76.997 secs\n",
            "\n",
            "Epoch: 94\n",
            "Elapsed [4:21:11.776157]  batch: 1  d_loss: -457.427521  g_loss: 1446.196777  kl_los: 93.892906\n",
            "Elapsed [4:22:25.030611]  batch: 39  d_loss: -940.736084  g_loss: 1724.485840  kl_los: 94.402611\n",
            "Time taken for epoch: 76.924 secs\n",
            "\n",
            "Epoch: 95\n",
            "Elapsed [4:22:28.776564]  batch: 1  d_loss: -742.872986  g_loss: 1795.198975  kl_los: 94.341537\n",
            "Elapsed [4:23:41.999576]  batch: 39  d_loss: -971.543274  g_loss: 1522.138306  kl_los: 94.162895\n",
            "Time taken for epoch: 76.975 secs\n",
            "\n",
            "Epoch: 96\n",
            "Elapsed [4:23:45.775707]  batch: 1  d_loss: -762.173157  g_loss: 1280.746582  kl_los: 94.762878\n",
            "Elapsed [4:24:59.023017]  batch: 39  d_loss: -877.617310  g_loss: 2242.546631  kl_los: 94.669502\n",
            "Time taken for epoch: 77.019 secs\n",
            "\n",
            "Epoch: 97\n",
            "Elapsed [4:25:02.710839]  batch: 1  d_loss: -344.672974  g_loss: 430.413177  kl_los: 94.897942\n",
            "Elapsed [4:26:16.320670]  batch: 39  d_loss: -925.077332  g_loss: 1134.145508  kl_los: 93.360229\n",
            "Time taken for epoch: 77.313 secs\n",
            "\n",
            "Epoch: 98\n",
            "Elapsed [4:26:19.846448]  batch: 1  d_loss: -586.533569  g_loss: 1933.486450  kl_los: 94.162949\n",
            "Elapsed [4:27:33.877820]  batch: 39  d_loss: -507.253937  g_loss: 1295.213501  kl_los: 94.352417\n",
            "Time taken for epoch: 77.536 secs\n",
            "\n",
            "Epoch: 99\n",
            "Elapsed [4:27:37.619156]  batch: 1  d_loss: -414.402039  g_loss: 1521.690674  kl_los: 94.833595\n",
            "Elapsed [4:28:51.660754]  batch: 39  d_loss: -1270.821045  g_loss: 2137.820801  kl_los: 94.374817\n",
            "Time taken for epoch: 77.782 secs\n",
            "\n",
            "Epoch: 100\n",
            "Elapsed [4:28:55.360097]  batch: 1  d_loss: -358.339783  g_loss: 787.645569  kl_los: 94.648933\n",
            "Elapsed [4:30:08.934388]  batch: 39  d_loss: -534.879517  g_loss: 2042.367920  kl_los: 94.589523\n",
            "Time taken for epoch: 77.285 secs\n",
            "\n",
            "Epoch: 101\n",
            "Elapsed [4:30:12.879321]  batch: 1  d_loss: -469.039490  g_loss: 917.511719  kl_los: 94.879486\n",
            "Elapsed [4:31:26.730770]  batch: 39  d_loss: -499.167511  g_loss: 1097.869629  kl_los: 95.467804\n",
            "Time taken for epoch: 77.572 secs\n",
            "\n",
            "Epoch: 102\n",
            "Elapsed [4:31:30.383965]  batch: 1  d_loss: -639.092346  g_loss: 1746.501221  kl_los: 94.350769\n",
            "Elapsed [4:32:44.337168]  batch: 39  d_loss: -397.958557  g_loss: 1356.069092  kl_los: 94.434402\n",
            "Time taken for epoch: 77.611 secs\n",
            "\n",
            "Epoch: 103\n",
            "Elapsed [4:32:47.968331]  batch: 1  d_loss: -799.765137  g_loss: 1696.491699  kl_los: 94.121475\n",
            "Elapsed [4:34:01.877295]  batch: 39  d_loss: -575.036011  g_loss: 1189.115845  kl_los: 94.677071\n",
            "Time taken for epoch: 77.556 secs\n",
            "\n",
            "Epoch: 104\n",
            "Elapsed [4:34:05.673529]  batch: 1  d_loss: -924.794922  g_loss: 2989.638672  kl_los: 94.791817\n",
            "Elapsed [4:35:19.538944]  batch: 39  d_loss: -829.878601  g_loss: 963.006714  kl_los: 93.807838\n",
            "Time taken for epoch: 77.651 secs\n",
            "\n",
            "Epoch: 105\n",
            "Elapsed [4:35:23.151696]  batch: 1  d_loss: -158.735321  g_loss: 895.260193  kl_los: 94.709732\n",
            "Elapsed [4:36:37.031280]  batch: 39  d_loss: -834.829529  g_loss: 2149.898438  kl_los: 95.123604\n",
            "Time taken for epoch: 77.511 secs\n",
            "\n",
            "Epoch: 106\n",
            "Elapsed [4:36:40.780661]  batch: 1  d_loss: -533.728699  g_loss: 1557.183594  kl_los: 94.991791\n",
            "Elapsed [4:37:54.639007]  batch: 39  d_loss: -976.444397  g_loss: 2027.649780  kl_los: 95.427689\n",
            "Time taken for epoch: 77.586 secs\n",
            "\n",
            "Epoch: 107\n",
            "Elapsed [4:37:58.085129]  batch: 1  d_loss: -801.328064  g_loss: 1990.200806  kl_los: 94.878151\n",
            "Elapsed [4:39:12.024411]  batch: 39  d_loss: -1099.548950  g_loss: 1767.804199  kl_los: 95.384422\n",
            "Time taken for epoch: 77.382 secs\n",
            "\n",
            "Epoch: 108\n",
            "Elapsed [4:39:15.765585]  batch: 1  d_loss: -609.832642  g_loss: 1681.951416  kl_los: 94.927284\n",
            "Elapsed [4:40:29.686454]  batch: 39  d_loss: -605.210754  g_loss: 1847.503174  kl_los: 95.568848\n",
            "Time taken for epoch: 77.707 secs\n",
            "\n",
            "Epoch: 109\n",
            "Elapsed [4:40:33.415535]  batch: 1  d_loss: -1020.783264  g_loss: 2206.618896  kl_los: 94.832657\n",
            "Elapsed [4:41:47.293798]  batch: 39  d_loss: -606.482117  g_loss: 1958.935303  kl_los: 94.484718\n",
            "Time taken for epoch: 77.558 secs\n",
            "\n",
            "Epoch: 110\n",
            "Elapsed [4:41:51.000879]  batch: 1  d_loss: -860.995117  g_loss: 1592.164673  kl_los: 94.729523\n",
            "Elapsed [4:43:04.917025]  batch: 39  d_loss: -925.845093  g_loss: 1846.407715  kl_los: 95.477264\n",
            "Time taken for epoch: 77.626 secs\n",
            "\n",
            "Epoch: 111\n",
            "Elapsed [4:43:08.636815]  batch: 1  d_loss: -744.294067  g_loss: 1816.579834  kl_los: 93.754715\n",
            "Elapsed [4:44:22.561559]  batch: 39  d_loss: -807.593262  g_loss: 1620.052246  kl_los: 94.272240\n",
            "Time taken for epoch: 77.432 secs\n",
            "\n",
            "Epoch: 112\n",
            "Elapsed [4:44:26.178068]  batch: 1  d_loss: -892.759033  g_loss: 1644.567627  kl_los: 94.089745\n",
            "Elapsed [4:45:40.053179]  batch: 39  d_loss: -922.862549  g_loss: 1927.257812  kl_los: 99.666901\n",
            "Time taken for epoch: 77.517 secs\n",
            "\n",
            "Epoch: 113\n",
            "Elapsed [4:45:43.707745]  batch: 1  d_loss: -1118.511230  g_loss: 1890.855469  kl_los: 94.744751\n",
            "Elapsed [4:46:57.575866]  batch: 39  d_loss: -169.696930  g_loss: 949.944763  kl_los: 93.932724\n",
            "Time taken for epoch: 77.512 secs\n",
            "\n",
            "Epoch: 114\n",
            "Elapsed [4:47:01.278937]  batch: 1  d_loss: -644.453247  g_loss: 1444.723145  kl_los: 94.273155\n",
            "Elapsed [4:48:15.097773]  batch: 39  d_loss: -765.046814  g_loss: 1442.135132  kl_los: 94.142105\n",
            "Time taken for epoch: 77.539 secs\n",
            "\n",
            "Epoch: 115\n",
            "Elapsed [4:48:18.816913]  batch: 1  d_loss: -912.980530  g_loss: 2165.545410  kl_los: 94.444656\n",
            "Elapsed [4:49:32.711668]  batch: 39  d_loss: -886.072876  g_loss: 2382.115723  kl_los: 94.386520\n",
            "Time taken for epoch: 77.643 secs\n",
            "\n",
            "Epoch: 116\n",
            "Elapsed [4:49:36.538729]  batch: 1  d_loss: -705.599609  g_loss: 630.780579  kl_los: 98.115570\n",
            "Elapsed [4:50:50.302803]  batch: 39  d_loss: -324.316895  g_loss: 766.549927  kl_los: 94.926605\n",
            "Time taken for epoch: 77.573 secs\n",
            "\n",
            "Epoch: 117\n",
            "Elapsed [4:50:54.072599]  batch: 1  d_loss: -242.735931  g_loss: 1419.367432  kl_los: 94.494232\n",
            "Elapsed [4:52:07.851039]  batch: 39  d_loss: -687.003052  g_loss: 2149.175293  kl_los: 94.883659\n",
            "Time taken for epoch: 77.519 secs\n",
            "\n",
            "Epoch: 118\n",
            "Elapsed [4:52:11.533919]  batch: 1  d_loss: -915.032959  g_loss: 1927.336914  kl_los: 94.797485\n",
            "Elapsed [4:53:25.397224]  batch: 39  d_loss: -314.217926  g_loss: 1205.878296  kl_los: 94.455650\n",
            "Time taken for epoch: 77.552 secs\n",
            "\n",
            "Epoch: 119\n",
            "Elapsed [4:53:29.107921]  batch: 1  d_loss: -127.573669  g_loss: 1782.436279  kl_los: 94.778702\n",
            "Elapsed [4:54:42.913515]  batch: 39  d_loss: -976.497681  g_loss: 1897.772217  kl_los: 94.904289\n",
            "Time taken for epoch: 77.521 secs\n",
            "\n",
            "Epoch: 120\n",
            "Elapsed [4:54:46.613847]  batch: 1  d_loss: -951.832336  g_loss: 1694.686768  kl_los: 95.363182\n",
            "Elapsed [4:56:00.356531]  batch: 39  d_loss: -364.748444  g_loss: 1627.488159  kl_los: 95.362511\n",
            "Time taken for epoch: 77.472 secs\n",
            "Training completed ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fhZNglyW0EMm",
        "colab_type": "code",
        "outputId": "492a99e5-9bda-4081-99dc-26bd71d73563",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "for i in range(4, 5):\n",
        "  log = pd.read_csv('/content/gdrive/My Drive/T2F/training_runs/2/losses/loss_{}.log'.format(i), delimiter='\\t', header=None, names=['d_loss', 'g_loss', 'kl_loss'])\n",
        "  n = len(log.d_loss)\n",
        "  xs = list(range(n*i, n*(i + 1)))\n",
        "  plt.plot(xs, log.d_loss)\n",
        "  plt.plot(xs, log.g_loss)\n",
        "  plt.plot(xs, log.kl_loss)\n",
        "  plt.legend(log.columns)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAD8CAYAAACCRVh7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\naDQajaYiWkhoNBqNpiJaSGg0Go2mIv8fbXpefrVJx18AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "REKbyce70FJs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from networks.ConditionAugmentation import ConditionAugmentor\n",
        "from pro_gan_pytorch.PRO_GAN import ConditionalProGAN\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def create_grid(samples, scale_factor, img_file, real_imgs=False):\n",
        "    \"\"\"\n",
        "    utility function to create a grid of GAN samples\n",
        "    :param samples: generated samples for storing\n",
        "    :param scale_factor: factor for upscaling the image\n",
        "    :param img_file: name of file to write\n",
        "    :param real_imgs: turn off the scaling of images\n",
        "    :return: None (saves a file)\n",
        "    \"\"\"\n",
        "    from torchvision.utils import save_image\n",
        "    from torch.nn.functional import interpolate\n",
        "\n",
        "    samples = th.clamp((samples / 2) + 0.5, min=0, max=1)\n",
        "\n",
        "    # upsample the image\n",
        "    if not real_imgs and scale_factor > 1:\n",
        "        samples = interpolate(samples,\n",
        "                              scale_factor=scale_factor)\n",
        "\n",
        "    # save the images:\n",
        "    save_image(samples, img_file, nrow=int(np.sqrt(len(samples))))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31_Q1Spa0FjN",
        "colab_type": "code",
        "outputId": "fd56965f-2534-450c-eb58-e18dc8abe099",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "# create the networks\n",
        "\n",
        "condition_augmenter = ConditionAugmentor(\n",
        "    input_size=config.hidden_size,\n",
        "    latent_size=config.ca_out_size,\n",
        "    use_eql=config.use_eql,\n",
        "    device=device\n",
        ")\n",
        "\n",
        "ca_file = '/content/gdrive/My Drive/T2F/training_runs/2/saved_models/Condition_Augmentor_4.pth'\n",
        "\n",
        "print(\"Loading conditioning augmenter from:\", ca_file)\n",
        "condition_augmenter.load_state_dict(th.load(ca_file))\n",
        "\n",
        "c_pro_gan = ConditionalProGAN(\n",
        "    embedding_size=config.hidden_size,\n",
        "    depth=config.depth,\n",
        "    latent_size=config.latent_size,\n",
        "    compressed_latent_size=config.compressed_latent_size,\n",
        "    learning_rate=config.learning_rate,\n",
        "    beta_1=config.beta_1,\n",
        "    beta_2=config.beta_2,\n",
        "    eps=config.eps,\n",
        "    drift=config.drift,\n",
        "    n_critic=config.n_critic,\n",
        "    use_eql=config.use_eql,\n",
        "    loss=config.loss_function,\n",
        "    use_ema=config.use_ema,\n",
        "    ema_decay=config.ema_decay,\n",
        "    device=device\n",
        ")\n",
        "\n",
        "generator_file = '/content/gdrive/My Drive/T2F/training_runs/2/saved_models/GAN_GEN_4.pth'\n",
        "print(\"Loading generator from:\", generator_file)\n",
        "c_pro_gan.gen.load_state_dict(th.load(generator_file))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading conditioning augmenter from: /content/gdrive/My Drive/T2F/training_runs/2/saved_models/Condition_Augmentor_4.pth\n",
            "Loading generator from: /content/gdrive/My Drive/T2F/training_runs/2/saved_models/GAN_GEN_4.pth\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbMb3Mcf0F-N",
        "colab_type": "code",
        "outputId": "a52f17fc-eb74-4026-def5-794bbdd91247",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "condition_augmenter.train(False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ConditionAugmentor(\n",
              "  (transformer): _equalized_linear()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ik3TqhRQ0qmx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "temp_data = dl.get_data_loader(dataset, 1, num_workers=3)\n",
        "fixed_captions, fixed_real_images = iter(temp_data).next()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMKY-iiE_J7a",
        "colab_type": "code",
        "outputId": "38242d31-48c5-428e-e9b5-900cfe361d3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "str = input('Enter your caption : ')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter your caption : a male in his 3 0 s , white and clean shaven with dar k hair and eyebrows . \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Wsyz9mqASzM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fixed_caption = (str,)\n",
        "fixed_captions = fixed_caption"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f76JVNWK0rJX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fixed_embeddings = text_encoder(fixed_captions)\n",
        "fixed_embeddings = th.from_numpy(fixed_embeddings).to(device)\n",
        "\n",
        "fixed_c_not_hats, mus, _ = condition_augmenter(fixed_embeddings)\n",
        "\n",
        "fixed_noise = th.zeros(len(fixed_captions),\n",
        "                       c_pro_gan.latent_size - fixed_c_not_hats.shape[-1]).to(device)\n",
        "\n",
        "fixed_gan_input = th.cat((fixed_c_not_hats, fixed_noise), dim=-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRw5LLWg0rk3",
        "colab_type": "code",
        "outputId": "53029a84-d341-42a1-ab82-80a7c1cdb773",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 344
        }
      },
      "source": [
        "create_grid(\n",
        "    samples=c_pro_gan.gen(\n",
        "        fixed_gan_input,\n",
        "        4,\n",
        "        1.0\n",
        "    ),\n",
        "    scale_factor=1,\n",
        "    img_file='output.png')\n",
        "\n",
        "img = plt.imread('output.png')\n",
        "plt.figure()\n",
        "plt.imshow(img)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/upsampling.py:129: UserWarning: nn.Upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.{} is deprecated. Use nn.functional.interpolate instead.\".format(self.name))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fde284e5668>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nX/gOxwLi/wdSYM5BfZvZFgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OrdAmD6S0r-t",
        "colab_type": "code",
        "outputId": "ee93d8e4-726f-4d34-d835-ce6418dc7272",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "fixed_captions"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('he is an old man with wrinkled face , gray hair and no beard . he has dark eyes and seems happy about something',)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bnxsOZy-y6A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}